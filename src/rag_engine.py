"""
RAG (Retrieval-Augmented Generation) engine with LangChain
"""

import logging
import os
import base64
from typing import Dict, Any, List, Optional
from pathlib import Path

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

import google.generativeai as genai

from .prompt_templates import RAG_PROMPT_TEMPLATE
from .reranker import Reranker

logger = logging.getLogger(__name__)

# Langfuseçµ±åˆ
try:
    from langfuse.callback import CallbackHandler as LangfuseCallbackHandler
    LANGFUSE_AVAILABLE = True
except ImportError:
    LANGFUSE_AVAILABLE = False


class RAGEngine:
    """RAGã‚¨ãƒ³ã‚¸ãƒ³ - LangChainçµ±åˆç‰ˆï¼ˆOpenAI & Geminiå¯¾å¿œï¼‰"""

    def __init__(self, config: dict, vector_store, embedder):
        """
        åˆæœŸåŒ–

        Args:
            config: è¨­å®šè¾æ›¸
            vector_store: VectorStoreã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            embedder: TextEmbedderã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.config = config
        self.vector_store = vector_store
        self.embedder = embedder

        self.openai_config = config.get("openai", {})
        self.gemini_config = config.get("gemini", {})
        self.search_config = config.get("search", {})
        self.langfuse_config = config.get("langfuse", {})
        self.chat_config = config.get("chat", {})
        self.rag_config = config.get("rag", {})
        self.reranking_config = config.get("reranking", {})

        # Langfuseæœ‰åŠ¹åŒ–ãƒã‚§ãƒƒã‚¯
        langfuse_available = LANGFUSE_AVAILABLE
        config_enabled = self.langfuse_config.get("enabled", True)
        has_public_key = bool(os.getenv("LANGFUSE_PUBLIC_KEY"))
        has_secret_key = bool(os.getenv("LANGFUSE_SECRET_KEY"))

        self.langfuse_enabled = langfuse_available and config_enabled and has_public_key and has_secret_key

        if self.langfuse_enabled:
            self.langfuse_handler = LangfuseCallbackHandler()
            logger.info("Langfuse tracing enabled")
        else:
            self.langfuse_handler = None
            logger.info(
                f"Langfuse tracing disabled (available={langfuse_available}, config={config_enabled}, public_key={has_public_key}, secret_key={has_secret_key})"
            )

        # LangChain LLMåˆæœŸåŒ–
        self._init_llms()

        # RerankeråˆæœŸåŒ–ï¼ˆæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
        self.reranker = None
        if self.rag_config.get("enable_reranking", False):
            try:
                model_name = self.reranking_config.get("model", "cross-encoder/ms-marco-MiniLM-L-6-v2")
                self.reranker = Reranker(model_name=model_name)
                logger.info(f"Reranker initialized: {model_name}")
            except Exception as e:
                logger.error(f"Failed to initialize Reranker: {e}")
                logger.warning("Continuing without reranking")

        # ä¼šè©±å±¥æ­´ç®¡ç†ã®è¨­å®š
        self.max_history_messages = self.chat_config.get("max_history_messages", 10)
        self.include_images_in_history = self.chat_config.get("include_images_in_history", False)

        logger.info(f"RAGEngine initialized with max_history_messages={self.max_history_messages}")

    def _init_llms(self):
        """LLMã®åˆæœŸåŒ– (OpenAI: LangChain, Gemini: Native SDK)"""
        # OpenAI (LangChain)
        openai_kwargs = {
            "model": self.openai_config.get("model_chat", "gpt-4o-mini"),
            "temperature": self.openai_config.get("temperature", 0.7),
            "max_tokens": self.openai_config.get("max_tokens", 16000),
            "streaming": True,
        }
        if self.langfuse_enabled:
            openai_kwargs["callbacks"] = [self.langfuse_handler]

        self.openai_llm = ChatOpenAI(**openai_kwargs)

        # Gemini (Native SDK - API Keyæ–¹å¼)
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        if gemini_api_key:
            genai.configure(api_key=gemini_api_key)
            self.gemini_model = genai.GenerativeModel(
                model_name=self.gemini_config.get("model_chat", "gemini-2.5-flash")
            )
            logger.info(f"Gemini initialized with model: {self.gemini_config.get('model_chat', 'gemini-2.5-flash')}")
        else:
            self.gemini_model = None
            logger.warning("GEMINI_API_KEY not set - Gemini will be unavailable")

        logger.info("LLMs initialized (OpenAI: LangChain, Gemini: Native SDK)")

    def _encode_image_to_base64(self, image_path: str) -> str:
        """
        ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯Supabase Storage URLï¼‰

        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã¾ãŸã¯Storage URL

        Returns:
            str: base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
        """
        try:
            from pathlib import Path
            import io

            # Supabase Storage URLã®å ´åˆï¼ˆcategory/filenameå½¢å¼ï¼‰
            logger.info(f"ğŸ“¸ _encode_image_to_base64: image_path={image_path}, exists={Path(image_path).exists()}, has_slash={'/' in image_path}")
            if not Path(image_path).exists() and '/' in image_path:
                # Supabase Storageã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                try:
                    logger.info(f"ğŸ“¸ _encode_image_to_base64: Downloading from Supabase Storage: {image_path}")
                    storage_bucket = self.config.get('vector_store', {}).get('supabase', {}).get('storage_bucket', 'pdf-images')

                    # vector_storeã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆæ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®ã¯ãšï¼‰
                    if hasattr(self, 'vector_store') and hasattr(self.vector_store, 'client'):
                        response = self.vector_store.client.storage.from_(storage_bucket).download(image_path)
                        logger.info(f"ğŸ“¸ _encode_image_to_base64: Successfully downloaded and encoded image from Storage")
                        return base64.b64encode(response).decode("utf-8")
                    else:
                        logger.error(f"Vector store client not available for Storage download")
                        raise ValueError("Cannot download from Storage: vector_store not initialized")

                except Exception as download_error:
                    logger.error(f"Failed to download image from Storage {image_path}: {download_error}")
                    raise

            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
            else:
                with open(image_path, "rb") as image_file:
                    return base64.b64encode(image_file.read()).decode("utf-8")

        except Exception as e:
            logger.error(f"Error encoding image {image_path}: {e}")
            raise

    def _limit_chat_history(self, chat_history: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        ä¼šè©±å±¥æ­´ã‚’æœ€å¤§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ã«åˆ¶é™

        Args:
            chat_history: ä¼šè©±å±¥æ­´

        Returns:
            list: åˆ¶é™å¾Œã®ä¼šè©±å±¥æ­´
        """
        if not chat_history or len(chat_history) <= self.max_history_messages:
            return chat_history

        # æœ€æ–°ã®max_history_messagesä»¶ã®ã¿ä¿æŒ
        limited = chat_history[-self.max_history_messages:]
        logger.info(f"Chat history limited: {len(chat_history)} -> {len(limited)} messages")
        return limited

    def _convert_history_to_messages(self, chat_history: List[Dict[str, str]]) -> List:
        """
        è¾æ›¸å½¢å¼ã®ä¼šè©±å±¥æ­´ã‚’LangChainãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›

        Args:
            chat_history: ä¼šè©±å±¥æ­´

        Returns:
            list: LangChainãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
        """
        messages = []
        for msg in chat_history:
            role = msg.get("role")
            content = msg.get("content", "")

            # ç”»åƒã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿æŠ½å‡º
            if not self.include_images_in_history and isinstance(content, list):
                # contentãŒãƒªã‚¹ãƒˆã®å ´åˆã€textãƒ‘ãƒ¼ãƒˆã®ã¿æŠ½å‡º
                text_parts = [part.get("text", "") for part in content if isinstance(part, dict) and part.get("type") == "text"]
                content = " ".join(text_parts)

            if role == "user":
                messages.append(HumanMessage(content=content))
            elif role == "assistant":
                messages.append(AIMessage(content=content))

        return messages

    def _rerank_results(self, query: str, results: List[Dict[str, Any]], top_k: int) -> List[Dict[str, Any]]:
        """
        Rerankingã‚’ä½¿ç”¨ã—ã¦æ¤œç´¢çµæœã‚’å†é †ä½ä»˜ã‘

        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            results: æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
            top_k: è¿”å´ã™ã‚‹çµæœæ•°

        Returns:
            list: Rerankingå¾Œã®æ¤œç´¢çµæœ
        """
        if not self.reranker or not results:
            return results[:top_k]

        try:
            # æ¤œç´¢çµæœã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            documents = [result.get("content", "") for result in results]

            # Rerankingã‚’å®Ÿè¡Œ
            logger.debug(f"Reranking {len(documents)} documents with query: {query[:50]}...")
            reranked_indices_scores = self.reranker.rerank(query, documents, top_k=top_k)

            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åŸºã¥ã„ã¦çµæœã‚’ä¸¦ã³æ›¿ãˆ
            reranked_results = []
            for idx, score in reranked_indices_scores:
                result = results[idx].copy()
                result["rerank_score"] = score  # Rerankingã‚¹ã‚³ã‚¢ã‚’è¿½åŠ 
                reranked_results.append(result)

            logger.info(
                f"Reranking completed: {len(results)} -> {len(reranked_results)} results",
                extra={"top_rerank_scores": [s for _, s in reranked_indices_scores[:3]]}
            )

            return reranked_results

        except Exception as e:
            logger.error(f"Reranking failed: {e}", exc_info=True)
            logger.warning("Falling back to original results")
            return results[:top_k]

    def query(self, question: str, category: Optional[str] = None, model_type: str = "openai", chat_history: Optional[List[Dict[str, str]]] = None, uploaded_images: Optional[List] = None) -> Dict[str, Any]:
        """
        è³ªå•ã«å¯¾ã—ã¦å›ç­”ã‚’ç”Ÿæˆ

        Args:
            question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
            category: æ¤œç´¢å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆNoneã®å ´åˆã¯å…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼‰
            model_type: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("openai" or "gemini")
            chat_history: ä¼šè©±å±¥æ­´ï¼ˆNoneã®å ´åˆã¯ä¼šè©±å±¥æ­´ãªã—ï¼‰
            uploaded_images: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã®ãƒªã‚¹ãƒˆï¼ˆBytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰

        Returns:
            dict: å›ç­”ã¨é–¢é€£æƒ…å ±
        """
        try:
            # ä¼šè©±å±¥æ­´ã®åˆ¶é™
            if chat_history:
                chat_history = self._limit_chat_history(chat_history)
                logger.info(f"Using {len(chat_history)} messages from chat history")

            # 1. è³ªå•ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—
            query_embedding = self.embedder.embed_query(question)

            # 2. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆRerankingæœ‰åŠ¹æ™‚ã¯ã‚ˆã‚Šå¤šãå–å¾—ï¼‰
            top_k_text = self.search_config.get("top_k_text", 5)
            if self.reranker:
                top_k_initial = self.reranking_config.get("top_k_initial", 10)
                logger.debug(f"Reranking enabled: fetching {top_k_initial} results for reranking")
            else:
                top_k_initial = top_k_text

            search_results = self.vector_store.search(
                query_embedding=query_embedding,
                category=category,
                top_k=top_k_initial,
                search_type="both",
                query_text=question  # BM25ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç”¨
            )

            # 3. Rerankingï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.reranker and search_results.get("text"):
                top_k_final = self.reranking_config.get("top_k_final", 5)
                search_results["text"] = self._rerank_results(
                    query=question,
                    results=search_results["text"],
                    top_k=top_k_final
                )

            # 4. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰
            context_parts = []
            image_data_list = []

            # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            for result in search_results.get("text", []):
                doc = result.get("content", "")
                source_file = result.get("source_file", "")
                page_number = result.get("page_number", "")
                context_parts.append(f"[{source_file} - Page {page_number}]\n{doc}")

            # ç”»åƒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            for result in search_results.get("images", []):
                image_path = result.get("path", "")
                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯Supabase Storageãƒ‘ã‚¹ã®ä¸¡æ–¹ã‚’è¨±å¯
                if image_path:
                    image_data_list.append({
                        "path": image_path,
                        "description": result.get("description", ""),
                        "source": result.get("source_file", ""),
                        "page": result.get("page_number", ""),
                    })
                    logger.debug(f"Added image to image_data_list: {image_path}")

            context_text = "\n\n".join(context_parts)
            logger.info(f"ğŸ“¸ image_data_list contains {len(image_data_list)} images")

            # 5. LLMã§å›ç­”ç”Ÿæˆ
            if model_type == "openai":
                answer = self._generate_answer_openai(question, context_text, image_data_list, chat_history, uploaded_images)
            else:
                answer = self._generate_answer_gemini(question, context_text, image_data_list, chat_history, uploaded_images)

            return {
                "answer": answer,
                "sources": search_results,
                "context": context_text,
                "images": image_data_list,
            }

        except Exception as e:
            logger.error(f"Error in query: {e}")
            raise

    def _generate_answer_openai(self, question: str, context: str, image_data_list: List[Dict], chat_history: Optional[List[Dict[str, str]]] = None, uploaded_images: Optional[List] = None) -> str:
        """
        OpenAIã§å›ç­”ã‚’ç”Ÿæˆ

        Args:
            question: è³ªå•
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            image_data_list: ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœï¼‰
            chat_history: ä¼šè©±å±¥æ­´
            uploaded_images: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã®ãƒªã‚¹ãƒˆï¼ˆBytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰

        Returns:
            str: å›ç­”
        """
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt_text = RAG_PROMPT_TEMPLATE.format(context=context, question=question)

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
        messages = [SystemMessage(content="ã‚ãªãŸã¯è³‡æ–™ã‚’ç†è§£ã—ã€æ­£ç¢ºã«å›ç­”ã™ã‚‹å°‚é–€å®¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")]

        # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ 
        if chat_history:
            history_messages = self._convert_history_to_messages(chat_history)
            messages.extend(history_messages)

        # ç”»åƒã‚’å«ã‚€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ§‹ç¯‰
        content_parts = [{"type": "text", "text": prompt_text}]

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’è¿½åŠ ï¼ˆå½¹å‰²ã‚’æ˜ç¤ºï¼‰
        if uploaded_images:
            content_parts.append({
                "type": "text",
                "text": f"\n\nâ”â”â” ä»¥ä¸‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè³ªå•ã®ãŸã‚ã«æ·»ä»˜ã—ãŸç”»åƒï¼ˆ{len(uploaded_images[:5])}æšï¼‰â”â”â”"
            })
            for uploaded_img in uploaded_images[:5]:  # æœ€å¤§5æš
                # BytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                uploaded_img.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
                img_bytes = uploaded_img.read()
                base64_image = base64.b64encode(img_bytes).decode("utf-8")
                content_parts.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                })

        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§å–å¾—ã—ãŸç”»åƒã‚’è¿½åŠ ï¼ˆå½¹å‰²ã‚’æ˜ç¤ºï¼‰
        remaining_slots = 5 - len(uploaded_images) if uploaded_images else 5
        if image_data_list and remaining_slots > 0:
            content_parts.append({
                "type": "text",
                "text": "\n\nâ”â”â” ä»¥ä¸‹ã€å‚è€ƒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ¤œç´¢ã•ã‚ŒãŸè³‡æ–™ã®ç”»åƒ â”â”â”"
            })
            for img_data in image_data_list[:remaining_slots]:
                base64_image = self._encode_image_to_base64(img_data["path"])
                content_parts.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                })

        messages.append(HumanMessage(content=content_parts))

        # LLMå‘¼ã³å‡ºã—
        response = self.openai_llm.invoke(messages)
        return response.content

    def _generate_answer_gemini(self, question: str, context: str, image_data_list: List[Dict], chat_history: Optional[List[Dict[str, str]]] = None, uploaded_images: Optional[List] = None) -> str:
        """
        Geminiã§å›ç­”ã‚’ç”Ÿæˆ (Native SDKä½¿ç”¨)

        Args:
            question: è³ªå•
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            image_data_list: ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœï¼‰
            chat_history: ä¼šè©±å±¥æ­´
            uploaded_images: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã®ãƒªã‚¹ãƒˆï¼ˆBytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰

        Returns:
            str: å›ç­”
        """
        if not self.gemini_model:
            raise ValueError("Gemini model is not initialized. Please set GEMINI_API_KEY.")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt_text = RAG_PROMPT_TEMPLATE.format(context=context, question=question)

        # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if chat_history:
            history_text = "\n\nã€ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã€‘\n"
            for msg in chat_history:
                role_label = "ãƒ¦ãƒ¼ã‚¶ãƒ¼" if msg["role"] == "user" else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
                content = msg.get("content", "")
                # ç”»åƒã‚’å«ã‚€å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿æŠ½å‡º
                if isinstance(content, list):
                    text_parts = [part.get("text", "") for part in content if isinstance(part, dict) and part.get("type") == "text"]
                    content = " ".join(text_parts)
                history_text += f"{role_label}: {content}\n\n"
            prompt_text = history_text + "\n" + prompt_text

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆã«ç”»åƒã®èª¬æ˜ã‚’è¿½åŠ 
        if uploaded_images:
            prompt_text += f"\n\nâ”â”â” ä»¥ä¸‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè³ªå•ã®ãŸã‚ã«æ·»ä»˜ã—ãŸç”»åƒï¼ˆ{len(uploaded_images[:5])}æšï¼‰â”â”â”"

        remaining_slots = 5 - len(uploaded_images) if uploaded_images else 5
        if image_data_list and remaining_slots > 0:
            prompt_text += "\n\nâ”â”â” ä»¥ä¸‹ã€å‚è€ƒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ¤œç´¢ã•ã‚ŒãŸè³‡æ–™ã®ç”»åƒ â”â”â”"

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ§‹ç¯‰ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‚’å…ˆã«ã€ç”»åƒã‚’å¾Œã«ï¼‰
        content_parts = [prompt_text]

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’è¿½åŠ 
        from PIL import Image
        if uploaded_images:
            for uploaded_img in uploaded_images[:5]:  # æœ€å¤§5æš
                # BytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’PIL Imageã«å¤‰æ›
                uploaded_img.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
                image = Image.open(uploaded_img)
                content_parts.append(image)

        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§å–å¾—ã—ãŸç”»åƒã‚’è¿½åŠ 
        logger.info(f"ğŸ“¸ Gemini: Processing {len(image_data_list)} images (remaining_slots={remaining_slots})")
        if image_data_list and remaining_slots > 0:
            for img_data in image_data_list[:remaining_slots]:
                img_path_str = img_data["path"]
                img_path = Path(img_path_str)
                logger.debug(f"ğŸ“¸ Gemini: Processing image {img_path_str}")

                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
                if img_path.exists():
                    logger.info(f"ğŸ“¸ Gemini: Loading local image: {img_path_str}")
                    image = Image.open(img_path)
                    content_parts.append(image)
                # Supabase Storage URLã®å ´åˆ
                elif '/' in img_path_str:
                    try:
                        # Storageã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        logger.info(f"ğŸ“¸ Gemini: Downloading image from Storage: {img_path_str}")
                        storage_bucket = self.config.get('vector_store', {}).get('supabase', {}).get('storage_bucket', 'pdf-images')

                        if hasattr(self, 'vector_store') and hasattr(self.vector_store, 'client'):
                            image_bytes = self.vector_store.client.storage.from_(storage_bucket).download(img_path_str)
                            from io import BytesIO
                            image = Image.open(BytesIO(image_bytes))
                            content_parts.append(image)
                            logger.info(f"ğŸ“¸ Gemini: Successfully added image from Storage")
                        else:
                            logger.warning(f"Cannot download image from Storage: vector_store not initialized")
                    except Exception as e:
                        logger.error(f"Failed to download/open image from Storage {img_path_str}: {e}", exc_info=True)
                else:
                    logger.warning(f"Image path does not exist and is not a Storage URL: {img_path_str}")

        # Gemini APIå‘¼ã³å‡ºã—
        response = self.gemini_model.generate_content(content_parts)
        return response.text

    def query_stream(self, question: str, category: Optional[str] = None, model_type: str = "openai", chat_history: Optional[List[Dict[str, str]]] = None, uploaded_images: Optional[List] = None):
        """
        è³ªå•ã«å¯¾ã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å›ç­”ã‚’ç”Ÿæˆ

        Args:
            question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
            category: æ¤œç´¢å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆNoneã®å ´åˆã¯å…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼‰
            model_type: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("openai" or "gemini")
            chat_history: ä¼šè©±å±¥æ­´ï¼ˆNoneã®å ´åˆã¯ä¼šè©±å±¥æ­´ãªã—ï¼‰
            uploaded_images: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã®ãƒªã‚¹ãƒˆï¼ˆBytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰

        Yields:
            dict: å›ç­”ã®æ–­ç‰‡ã¨é–¢é€£æƒ…å ±
        """
        try:
            # ä¼šè©±å±¥æ­´ã®åˆ¶é™
            if chat_history:
                chat_history = self._limit_chat_history(chat_history)
                logger.info(f"Using {len(chat_history)} messages from chat history (streaming)")

            # 1. è³ªå•ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—
            query_embedding = self.embedder.embed_query(question)

            # 2. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆRerankingæœ‰åŠ¹æ™‚ã¯ã‚ˆã‚Šå¤šãå–å¾—ï¼‰
            top_k_text = self.search_config.get("top_k_text", 5)
            if self.reranker:
                top_k_initial = self.reranking_config.get("top_k_initial", 10)
                logger.debug(f"Reranking enabled (streaming): fetching {top_k_initial} results for reranking")
            else:
                top_k_initial = top_k_text

            search_results = self.vector_store.search(
                query_embedding=query_embedding,
                category=category,
                top_k=top_k_initial,
                search_type="both",
                query_text=question  # BM25ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç”¨
            )

            # 3. Rerankingï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.reranker and search_results.get("text"):
                top_k_final = self.reranking_config.get("top_k_final", 5)
                search_results["text"] = self._rerank_results(
                    query=question,
                    results=search_results["text"],
                    top_k=top_k_final
                )

            # 4. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰
            context_parts = []
            image_data_list = []

            # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            for result in search_results.get("text", []):
                doc = result.get("content", "")
                source_file = result.get("source_file", "")
                page_number = result.get("page_number", "")
                context_parts.append(f"[{source_file} - Page {page_number}]\n{doc}")

            # ç”»åƒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            for result in search_results.get("images", []):
                image_path = result.get("path", "")
                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯Supabase Storageãƒ‘ã‚¹ã®ä¸¡æ–¹ã‚’è¨±å¯
                if image_path:
                    image_data_list.append({
                        "path": image_path,
                        "description": result.get("description", ""),
                        "source": result.get("source_file", ""),
                        "page": result.get("page_number", ""),
                    })
                    logger.debug(f"Added image to image_data_list: {image_path}")

            context_text = "\n\n".join(context_parts)
            logger.info(f"ğŸ“¸ image_data_list contains {len(image_data_list)} images")

            # æœ€åˆã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿”ã™
            yield {
                "type": "context",
                "sources": search_results,
                "context": context_text,
                "images": image_data_list,
            }

            # 5. LLMã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å›ç­”ç”Ÿæˆ
            if model_type == "openai":
                yield from self._stream_answer_openai(question, context_text, image_data_list, chat_history, uploaded_images)
            else:
                yield from self._stream_answer_gemini(question, context_text, image_data_list, chat_history, uploaded_images)

        except Exception as e:
            logger.error(f"Error in query_stream: {e}")
            raise

    def _stream_answer_openai(self, question: str, context: str, image_data_list: List[Dict], chat_history: Optional[List[Dict[str, str]]] = None, uploaded_images: Optional[List] = None):
        """
        OpenAIã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å›ç­”ã‚’ç”Ÿæˆ

        Args:
            question: è³ªå•
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            image_data_list: ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœï¼‰
            chat_history: ä¼šè©±å±¥æ­´
            uploaded_images: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã®ãƒªã‚¹ãƒˆï¼ˆBytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰

        Yields:
            dict: å›ç­”ã®æ–­ç‰‡
        """
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt_text = RAG_PROMPT_TEMPLATE.format(context=context, question=question)

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
        messages = [SystemMessage(content="ã‚ãªãŸã¯è³‡æ–™ã‚’ç†è§£ã—ã€æ­£ç¢ºã«å›ç­”ã™ã‚‹å°‚é–€å®¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")]

        # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ 
        if chat_history:
            history_messages = self._convert_history_to_messages(chat_history)
            messages.extend(history_messages)

        # ç”»åƒã‚’å«ã‚€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ§‹ç¯‰
        content_parts = [{"type": "text", "text": prompt_text}]

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’è¿½åŠ ï¼ˆå½¹å‰²ã‚’æ˜ç¤ºï¼‰
        if uploaded_images:
            content_parts.append({
                "type": "text",
                "text": f"\n\nâ”â”â” ä»¥ä¸‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè³ªå•ã®ãŸã‚ã«æ·»ä»˜ã—ãŸç”»åƒï¼ˆ{len(uploaded_images[:5])}æšï¼‰â”â”â”"
            })
            for uploaded_img in uploaded_images[:5]:  # æœ€å¤§5æš
                # BytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                uploaded_img.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
                img_bytes = uploaded_img.read()
                base64_image = base64.b64encode(img_bytes).decode("utf-8")
                content_parts.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                })

        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§å–å¾—ã—ãŸç”»åƒã‚’è¿½åŠ ï¼ˆå½¹å‰²ã‚’æ˜ç¤ºï¼‰
        remaining_slots = 5 - len(uploaded_images) if uploaded_images else 5
        logger.info(f"ğŸ“¸ OpenAI: Processing {len(image_data_list)} images (remaining_slots={remaining_slots})")
        if image_data_list and remaining_slots > 0:
            content_parts.append({
                "type": "text",
                "text": "\n\nâ”â”â” ä»¥ä¸‹ã€å‚è€ƒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ¤œç´¢ã•ã‚ŒãŸè³‡æ–™ã®ç”»åƒ â”â”â”"
            })
            for img_data in image_data_list[:remaining_slots]:
                img_path = img_data["path"]
                logger.info(f"ğŸ“¸ OpenAI: Encoding image: {img_path}")
                try:
                    base64_image = self._encode_image_to_base64(img_path)
                    content_parts.append({
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                    })
                    logger.info(f"ğŸ“¸ OpenAI: Successfully added image")
                except Exception as e:
                    logger.error(f"ğŸ“¸ OpenAI: Failed to encode image {img_path}: {e}", exc_info=True)

        messages.append(HumanMessage(content=content_parts))

        # LLMã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‘¼ã³å‡ºã—
        logger.debug("Starting OpenAI streaming...")
        for chunk in self.openai_llm.stream(messages):
            if chunk.content:
                yield {
                    "type": "chunk",
                    "content": chunk.content,
                }
        logger.debug("OpenAI streaming completed")

    def _stream_answer_gemini(self, question: str, context: str, image_data_list: List[Dict], chat_history: Optional[List[Dict[str, str]]] = None, uploaded_images: Optional[List] = None):
        """
        Geminiã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å›ç­”ã‚’ç”Ÿæˆ (Native SDKä½¿ç”¨)

        Args:
            question: è³ªå•
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            image_data_list: ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœï¼‰
            chat_history: ä¼šè©±å±¥æ­´
            uploaded_images: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã®ãƒªã‚¹ãƒˆï¼ˆBytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰

        Yields:
            dict: å›ç­”ã®æ–­ç‰‡
        """
        if not self.gemini_model:
            raise ValueError("Gemini model is not initialized. Please set GEMINI_API_KEY.")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt_text = RAG_PROMPT_TEMPLATE.format(context=context, question=question)

        # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if chat_history:
            history_text = "\n\nã€ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã€‘\n"
            for msg in chat_history:
                role_label = "ãƒ¦ãƒ¼ã‚¶ãƒ¼" if msg["role"] == "user" else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
                content = msg.get("content", "")
                # ç”»åƒã‚’å«ã‚€å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿æŠ½å‡º
                if isinstance(content, list):
                    text_parts = [part.get("text", "") for part in content if isinstance(part, dict) and part.get("type") == "text"]
                    content = " ".join(text_parts)
                history_text += f"{role_label}: {content}\n\n"
            prompt_text = history_text + "\n" + prompt_text

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆã«ç”»åƒã®èª¬æ˜ã‚’è¿½åŠ 
        if uploaded_images:
            prompt_text += f"\n\nâ”â”â” ä»¥ä¸‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè³ªå•ã®ãŸã‚ã«æ·»ä»˜ã—ãŸç”»åƒï¼ˆ{len(uploaded_images[:5])}æšï¼‰â”â”â”"

        remaining_slots = 5 - len(uploaded_images) if uploaded_images else 5
        if image_data_list and remaining_slots > 0:
            prompt_text += "\n\nâ”â”â” ä»¥ä¸‹ã€å‚è€ƒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ¤œç´¢ã•ã‚ŒãŸè³‡æ–™ã®ç”»åƒ â”â”â”"

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ§‹ç¯‰ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‚’å…ˆã«ã€ç”»åƒã‚’å¾Œã«ï¼‰
        content_parts = [prompt_text]

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’è¿½åŠ 
        from PIL import Image
        if uploaded_images:
            for uploaded_img in uploaded_images[:5]:  # æœ€å¤§5æš
                # BytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’PIL Imageã«å¤‰æ›
                uploaded_img.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
                image = Image.open(uploaded_img)
                content_parts.append(image)

        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§å–å¾—ã—ãŸç”»åƒã‚’è¿½åŠ 
        logger.info(f"ğŸ“¸ Gemini (streaming): Processing {len(image_data_list)} images (remaining_slots={remaining_slots})")
        if image_data_list and remaining_slots > 0:
            for img_data in image_data_list[:remaining_slots]:
                img_path_str = img_data["path"]
                img_path = Path(img_path_str)
                logger.debug(f"ğŸ“¸ Gemini (streaming): Processing image {img_path_str}")

                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
                if img_path.exists():
                    logger.info(f"ğŸ“¸ Gemini (streaming): Loading local image: {img_path_str}")
                    image = Image.open(img_path)
                    content_parts.append(image)
                # Supabase Storage URLã®å ´åˆ
                elif '/' in img_path_str:
                    try:
                        # Storageã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        logger.info(f"ğŸ“¸ Gemini (streaming): Downloading image from Storage: {img_path_str}")
                        storage_bucket = self.config.get('vector_store', {}).get('supabase', {}).get('storage_bucket', 'pdf-images')

                        if hasattr(self, 'vector_store') and hasattr(self.vector_store, 'client'):
                            image_bytes = self.vector_store.client.storage.from_(storage_bucket).download(img_path_str)
                            from io import BytesIO
                            image = Image.open(BytesIO(image_bytes))
                            content_parts.append(image)
                            logger.info(f"ğŸ“¸ Gemini (streaming): Successfully added image from Storage")
                        else:
                            logger.warning(f"Cannot download image from Storage: vector_store not initialized")
                    except Exception as e:
                        logger.error(f"Failed to download/open image from Storage {img_path_str}: {e}", exc_info=True)
                else:
                    logger.warning(f"Image path does not exist and is not a Storage URL: {img_path_str}")

        # Gemini APIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‘¼ã³å‡ºã—
        logger.debug("Starting Gemini streaming...")
        response = self.gemini_model.generate_content(content_parts, stream=True)
        for chunk in response:
            if chunk.text:
                yield {
                    "type": "chunk",
                    "content": chunk.text,
                }
        logger.debug("Gemini streaming completed")

    def get_top_reference_pages(
        self,
        search_results: Dict[str, Any],
        top_n: int = 5,
    ) -> List[Dict[str, Any]]:
        """
        æ¤œç´¢çµæœã‹ã‚‰é–¢é€£åº¦ã®é«˜ã„ãƒˆãƒƒãƒ—Nãƒšãƒ¼ã‚¸ã‚’æŠ½å‡º

        Args:
            search_results: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœï¼ˆrerankingã‚¹ã‚³ã‚¢å«ã‚€ï¼‰
            top_n: æŠ½å‡ºã™ã‚‹ãƒšãƒ¼ã‚¸æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰

        Returns:
            list: ãƒˆãƒƒãƒ—Nãƒšãƒ¼ã‚¸ã®æƒ…å ±
                [{
                    "source_file": str,
                    "page_number": int,
                    "score": float,  # rerankã‚¹ã‚³ã‚¢ï¼ˆãªã‘ã‚Œã°Noneï¼‰
                    "content_preview": str,  # å†…å®¹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®100æ–‡å­—ï¼‰
                    "file_extension": str,  # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ï¼ˆä¾‹: ".xlsx", ".pdf"ï¼‰
                }]
        """
        top_pages = []
        seen_pages = set()  # (source_file, page_number) ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨

        # ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢çµæœã‹ã‚‰æŠ½å‡º
        for result in search_results.get("text", []):
            source_file = result.get("source_file", "")
            page_number = result.get("page_number", 0)

            # ãƒšãƒ¼ã‚¸è­˜åˆ¥å­
            page_id = (source_file, page_number)

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if page_id in seen_pages:
                continue

            # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’å–å¾—
            file_extension = Path(source_file).suffix.lower()

            # ãƒšãƒ¼ã‚¸æƒ…å ±ã‚’è¿½åŠ 
            top_pages.append({
                "source_file": source_file,
                "page_number": page_number,
                "score": result.get("rerank_score"),  # rerankingã‚¹ã‚³ã‚¢ï¼ˆãªã‘ã‚Œã°Noneï¼‰
                "content_preview": result.get("content", "")[:100],  # æœ€åˆã®100æ–‡å­—
                "file_extension": file_extension,  # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
            })

            seen_pages.add(page_id)

            # ç›®æ¨™æ•°ã«é”ã—ãŸã‚‰çµ‚äº†
            if len(top_pages) >= top_n:
                break

        logger.info(f"Extracted {len(top_pages)} unique pages from search results")
        return top_pages
