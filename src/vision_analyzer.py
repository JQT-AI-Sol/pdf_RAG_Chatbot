"""
Vision AI module for analyzing tables and graphs using GPT-5
"""

import logging
import os
import base64
import hashlib
import json
from typing import Dict, Any
from pathlib import Path
from datetime import datetime
from openai import OpenAI
from PIL import Image

# Langfuseçµ±åˆ
try:
    from langfuse import observe
    LANGFUSE_AVAILABLE = True
except ImportError:
    # ãƒ€ãƒŸãƒ¼ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼
    def observe(*args, **kwargs):
        def decorator(func):
            return func
        return decorator if not args else observe()(args[0])
    LANGFUSE_AVAILABLE = False


logger = logging.getLogger(__name__)


class VisionAnalyzer:
    """Vision AIã‚’ä½¿ç”¨ã—ã¦è¡¨ãƒ»ã‚°ãƒ©ãƒ•ã‚’è§£æã™ã‚‹ã‚¯ãƒ©ã‚¹ï¼ˆOpenAI GPT-5å¯¾å¿œï¼‰"""

    def __init__(self, config: dict):
        """
        åˆæœŸåŒ–

        Args:
            config: Visionè¨­å®š
        """
        self.config = config
        self.openai_config = config.get("openai", {})
        self.vision_config = config.get("vision", {})
        self.rag_config = config.get("rag", {})
        self.cache_config = config.get("cache", {}).get("vision", {})

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
        self.cache_dir = None
        if self.rag_config.get("enable_vision_cache", False) or self.cache_config.get("enabled", False):
            try:
                cache_dir_path = self.cache_config.get("directory", "./cache/vision_analysis")
                self.cache_dir = Path(cache_dir_path)
                self.cache_dir.mkdir(parents=True, exist_ok=True)
                logger.info(f"Vision cache enabled: {cache_dir_path}")
            except Exception as e:
                logger.error(f"Failed to initialize vision cache: {e}")
                logger.warning("Continuing without vision caching")

        # OpenAI APIã‚­ãƒ¼ã®ç¢ºèªã¨è¨­å®š
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.api_key_valid = bool(self.api_key)

        if not self.api_key:
            logger.warning("OPENAI_API_KEY environment variable is not set - vision analysis will be disabled")
            logger.warning("To enable vision analysis, please set OPENAI_API_KEY in your .env file")
            self.model_name = self.openai_config.get("model_vision", "gpt-5")
            self.client = None
        else:
            # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
            try:
                self.client = OpenAI(api_key=self.api_key)
                self.model_name = self.openai_config.get("model_vision", "gpt-5")
                logger.info(f"VisionAnalyzer initialized with model: {self.model_name}")
            except Exception as e:
                logger.error(f"Failed to initialize OpenAI: {e}")
                self.api_key_valid = False
                self.client = None

    def _encode_image_to_base64(self, image_path: str) -> str:
        """
        ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰

        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            str: base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
        """
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode("utf-8")
        except Exception as e:
            logger.error(f"Error encoding image {image_path}: {e}")
            raise

    def _get_image_hash(self, image_path: str) -> str:
        """
        ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®SHA256ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—

        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            str: SHA256ãƒãƒƒã‚·ãƒ¥å€¤
        """
        try:
            with open(image_path, 'rb') as f:
                return hashlib.sha256(f.read()).hexdigest()
        except Exception as e:
            logger.error(f"Error computing hash for {image_path}: {e}")
            raise

    @observe(name="vision_analysis")
    def analyze_image(self, image_path: str, content_type: str = "table") -> Dict[str, Any]:
        """
        ç”»åƒï¼ˆè¡¨ãƒ»ã‚°ãƒ©ãƒ•ï¼‰ã‚’è§£æï¼ˆOpenAI Vision APIä½¿ç”¨ï¼‰

        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            content_type: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ— ('table' or 'graph')

        Returns:
            dict: è§£æçµæœ

        Raises:
            FileNotFoundError: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            ValueError: APIå¿œç­”ãŒä¸æ­£ãªå ´åˆã€ã¾ãŸã¯APIã‚­ãƒ¼ãŒæœªè¨­å®šã®å ´åˆ
            Exception: ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
        """
        logger.info(f"Analyzing {content_type} image with GPT-5: {image_path}")

        # Langfuseã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆè©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ï¼‰
        if LANGFUSE_AVAILABLE:
            try:
                from langfuse.decorators import langfuse_context
            except ImportError:
                langfuse_context = None
        else:
            langfuse_context = None

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã®å‰ã«ï¼‰
        if self.cache_dir:
            try:
                # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
                if Path(image_path).exists():
                    image_hash = self._get_image_hash(image_path)
                    cache_key = f"{image_hash}_{content_type}"
                    cache_file = self.cache_dir / f"{cache_key}.json"

                    if cache_file.exists():
                        try:
                            with open(cache_file, 'r', encoding='utf-8') as f:
                                cached_data = json.load(f)
                            logger.info(f"Vision cache hit: {cache_key[:16]}... (skipping API call)")
                            return cached_data['result']
                        except Exception as e:
                            logger.warning(f"Failed to load vision cache: {e}")
            except Exception as e:
                logger.warning(f"Cache check failed: {e}")

        # APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
        if not self.api_key_valid or self.client is None:
            error_msg = "OPENAI_API_KEY is not set or invalid. Vision analysis is disabled. Please set OPENAI_API_KEY in your .env file."
            logger.error(error_msg)
            raise ValueError(error_msg)

        try:
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            if not Path(image_path).exists():
                error_msg = f"Image file not found: {image_path}"
                logger.error(error_msg)
                raise FileNotFoundError(error_msg)

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ
            if content_type in ["table", "full_page"]:
                # è¡¨ãŠã‚ˆã³ãƒšãƒ¼ã‚¸å…¨ä½“ã¯å¹³æ–‡ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§æŠ½å‡º
                prompt = self.vision_config.get("analysis_prompt_table", "")
            elif content_type == "graph":
                # ã‚°ãƒ©ãƒ•ã¯JSONå½¢å¼ã§æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                prompt = self.vision_config.get("analysis_prompt_graph", "")
            elif content_type == "ocr":
                # OCR: JSONå½¢å¼ã§åº§æ¨™ä»˜ããƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                prompt = self.vision_config.get("analysis_prompt_ocr", "")
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å¹³æ–‡ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼
                prompt = self.vision_config.get("analysis_prompt_table", "")

            if not prompt:
                error_msg = f"No prompt configured for content_type: {content_type}"
                logger.error(error_msg)
                raise ValueError(error_msg)

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€åˆã®100æ–‡å­—ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            logger.warning(f"[DEBUG] Using prompt (first 100 chars): {prompt[:100]}...")
            logger.warning(f"[DEBUG] Content type: {content_type}")

            # Langfuseã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©³ç´°ã‚’è¨˜éŒ²
            if langfuse_context:
                try:
                    langfuse_context.update_current_trace(
                        metadata={
                            "content_type": content_type,
                            "image_path": image_path,
                            "model": self.model_name,
                            "prompt_length": len(prompt)
                        }
                    )
                    langfuse_context.update_current_observation(
                        input=prompt,  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ã‚’Langfuseã«è¨˜éŒ²
                        metadata={
                            "image_path": image_path,
                            "content_type": content_type,
                            "prompt_first_100_chars": prompt[:100]
                        }
                    )
                except Exception as e:
                    logger.warning(f"Failed to update Langfuse context: {e}")

            # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            logger.debug(f"Encoding image: {image_path}")
            base64_image = self._encode_image_to_base64(image_path)

            # ç”»åƒã®æ‹¡å¼µå­ã‚’å–å¾—ã—ã¦MIMEã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š
            image_ext = Path(image_path).suffix.lower()
            mime_type = "image/png" if image_ext == ".png" else "image/jpeg"

            # OpenAI APIå‘¼ã³å‡ºã—
            try:
                logger.debug(f"Calling OpenAI with model: {self.model_name}")
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:{mime_type};base64,{base64_image}"
                                    }
                                }
                            ]
                        }
                    ],
                    max_completion_tokens=4096
                )

                if not response.choices or not response.choices[0].message.content:
                    error_msg = f"Empty response from OpenAI API for image: {image_path}"
                    logger.error(error_msg)
                    raise ValueError(error_msg)

                raw_response = response.choices[0].message.content
                logger.debug(f"OpenAI API response length: {len(raw_response)} characters")

                # Langfuseã«ç”Ÿå¿œç­”ã‚’è¨˜éŒ²
                has_json_block = "```json" in raw_response.lower()
                starts_with_brace = raw_response.strip().startswith("{")

                if langfuse_context:
                    try:
                        langfuse_context.update_current_observation(
                            output=raw_response,  # OpenAIã®ç”Ÿå¿œç­”
                            metadata={
                                "response_length": len(raw_response),
                                "has_json_block": has_json_block,
                                "starts_with_brace": starts_with_brace,
                                "response_first_200_chars": raw_response[:200]
                            }
                        )
                    except Exception as e:
                        logger.warning(f"Failed to update Langfuse with response: {e}")

                analysis_result = raw_response

            except Exception as e:
                error_msg = f"OpenAI API call failed for {image_path}: {type(e).__name__}: {str(e)}"
                logger.error(error_msg)
                raise

            # å¹³æ–‡ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ãŸå ´åˆã€ãƒ¢ãƒ‡ãƒ«ãŒå‹æ‰‹ã«JSONå½¢å¼ã§è¿”ã™ã“ã¨ãŒã‚ã‚‹ã®ã§ã€
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œå‡ºã—ã¦è­¦å‘Šã—ã€å¹³æ–‡ã«å¤‰æ›ã™ã‚‹
            json_removed = False
            if content_type in ["table", "full_page"]:
                if "```json" in analysis_result.lower() or analysis_result.strip().startswith("{"):
                    logger.warning(f"[ISSUE] OpenAI returned JSON format despite plain text prompt for {content_type}")
                    logger.warning(f"[ISSUE] Original response (first 200 chars): {analysis_result[:200]}")

                    # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ã—ã¦å¹³æ–‡ã«å¤‰æ›
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯
                    import re
                    cleaned = re.sub(r'```json.*?```', '', analysis_result, flags=re.DOTALL | re.IGNORECASE)
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ```...``` ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆè¨€èªæŒ‡å®šãªã—ï¼‰
                    cleaned = re.sub(r'```.*?```', '', cleaned, flags=re.DOTALL)
                    # å‰å¾Œã®èª¬æ˜æ–‡ã ã‘ã‚’æ®‹ã™
                    cleaned = cleaned.strip()

                    if cleaned and len(cleaned) > 50:
                        analysis_result = cleaned
                        json_removed = True
                        logger.warning(f"[FIX] Converted to plain text ({len(analysis_result)} chars)")
                    else:
                        logger.warning(f"[FIX] Could not extract plain text, keeping original")

            # Langfuseã«å¾Œå‡¦ç†çµæœã‚’è¨˜éŒ²
            if langfuse_context and json_removed:
                try:
                    langfuse_context.update_current_trace(
                        metadata={
                            "json_removed": True,
                            "original_length": len(raw_response),
                            "cleaned_length": len(analysis_result),
                            "final_result_first_200_chars": analysis_result[:200]
                        }
                    )
                except Exception as e:
                    logger.warning(f"Failed to update Langfuse with cleanup info: {e}")

            result = {
                "content_type": content_type,
                "description": analysis_result,
                "image_path": image_path,
                "model": self.model_name,
            }

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            if self.cache_dir:
                try:
                    image_hash = self._get_image_hash(image_path)
                    cache_key = f"{image_hash}_{content_type}"
                    cache_file = self.cache_dir / f"{cache_key}.json"

                    with open(cache_file, 'w', encoding='utf-8') as f:
                        json.dump({
                            'result': result,
                            'timestamp': datetime.now().isoformat(),
                            'content_type': content_type,
                            'image_hash': image_hash
                        }, f, ensure_ascii=False, indent=2)
                    logger.debug(f"Cached vision result: {cache_key[:16]}...")
                except Exception as e:
                    logger.warning(f"Failed to save vision cache: {e}")

            logger.info(f"Successfully analyzed {content_type} with GPT-5 (result: {len(analysis_result)} chars)")
            return result

        except Exception as e:
            logger.error(f"Error analyzing image {image_path}: {type(e).__name__}: {str(e)}")
            raise

    def analyze_table(self, image_path: str) -> Dict[str, Any]:
        """
        è¡¨ã‚’è§£æ

        Args:
            image_path: è¡¨ç”»åƒã®ãƒ‘ã‚¹

        Returns:
            dict: è§£æçµæœ
        """
        return self.analyze_image(image_path, content_type="table")

    def analyze_graph(self, image_path: str) -> Dict[str, Any]:
        """
        ã‚°ãƒ©ãƒ•ã‚’è§£æ

        Args:
            image_path: ã‚°ãƒ©ãƒ•ç”»åƒã®ãƒ‘ã‚¹

        Returns:
            dict: è§£æçµæœ
        """
        return self.analyze_image(image_path, content_type="graph")

    def ocr_page(self, image_path: str) -> Dict[str, Any]:
        """
        ã‚¹ã‚­ãƒ£ãƒ³PDFãƒšãƒ¼ã‚¸ã‹ã‚‰OCRã§ãƒ†ã‚­ã‚¹ãƒˆã¨åº§æ¨™ã‚’æŠ½å‡º

        Args:
            image_path: PDFç”»åƒã®ãƒ‘ã‚¹ï¼ˆPNG/JPEGï¼‰

        Returns:
            dict: OCRçµæœ
                {
                    "words": [{"text": str, "x0": float, "y0": float, "x1": float, "y1": float}],
                    "full_text": str,
                    "cached": bool
                }
        """
        logger.info(f"ğŸ” OCR analysis for: {image_path}")

        try:
            # analyze_image()ã‚’ä½¿ç”¨ã—ã¦OCRå®Ÿè¡Œ
            result = self.analyze_image(image_path, content_type="ocr")

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSONã‚’ãƒ‘ãƒ¼ã‚¹
            description = result.get("description", "")

            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            import re
            import json

            # ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ã™ï¼ˆã‚ˆã‚ŠæŸ”è»Ÿãªæ­£è¦è¡¨ç¾ï¼‰
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', description, re.DOTALL | re.IGNORECASE)
            if json_match:
                json_str = json_match.group(1).strip()
            else:
                # JSONãƒ–ãƒ­ãƒƒã‚¯ãªã—ã®å ´åˆã€å…¨ä½“ã‚’JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹è©¦è¡Œ
                json_str = description.strip()

            # ç©ºæ–‡å­—åˆ—ãƒã‚§ãƒƒã‚¯
            if not json_str:
                logger.error("âŒ OCR response is empty after extraction")
                return {"words": [], "full_text": "", "cached": False}

            ocr_data = json.loads(json_str)

            # pdfplumberå½¢å¼ã«å¤‰æ›
            words = []
            for word_data in ocr_data.get("words", []):
                bbox = word_data.get("bbox", {})
                words.append({
                    "text": word_data.get("text", ""),
                    "x0": bbox.get("x0", 0),
                    "top": bbox.get("y0", 0),  # pdfplumberã¯ "top" ã‚’ä½¿ç”¨
                    "x1": bbox.get("x1", 0),
                    "bottom": bbox.get("y1", 0),  # pdfplumberã¯ "bottom" ã‚’ä½¿ç”¨
                })

            logger.info(f"âœ… OCR extracted {len(words)} words from {image_path}")

            return {
                "words": words,
                "full_text": ocr_data.get("full_text", ""),
                "cached": False  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã¯analyze_image()å†…ã§åˆ¤å®šæ¸ˆã¿
            }

        except json.JSONDecodeError as e:
            logger.error(f"âŒ Failed to parse OCR JSON response: {e}")
            logger.error(f"Response was: {description[:500]}...")
            return {"words": [], "full_text": "", "cached": False}
        except Exception as e:
            logger.error(f"âŒ OCR analysis failed: {e}", exc_info=True)
            return {"words": [], "full_text": "", "cached": False}
