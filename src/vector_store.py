"""
Vector store module supporting both ChromaDB and Supabase
"""

import logging
import os
from typing import List, Dict, Any, Optional
import uuid
import hashlib

logger = logging.getLogger(__name__)


class VectorStore:
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚¯ãƒ©ã‚¹ï¼ˆChromaDB / Supabaseå¯¾å¿œï¼‰"""

    def __init__(self, config: dict):
        """
        åˆæœŸåŒ–

        Args:
            config: è¨­å®šè¾æ›¸
        """
        self.config = config
        self.vs_config = config.get('vector_store', {})
        self.provider = self.vs_config.get('provider', 'chromadb')

        if self.provider == 'supabase':
            self._init_supabase()
        else:
            self._init_chromadb()

        logger.info(f"Vector store initialized with provider: {self.provider} (v1.1)")

    def _init_supabase(self):
        """Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            from supabase import create_client, Client

            # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰æ¥ç¶šæƒ…å ±ã‚’å–å¾—
            supabase_url = os.environ.get('SUPABASE_URL')
            supabase_key = os.environ.get('SUPABASE_KEY')

            if not supabase_url or not supabase_key:
                raise ValueError("SUPABASE_URL and SUPABASE_KEY must be set in environment variables")

            self.client: Client = create_client(supabase_url, supabase_key)

            # ãƒ†ãƒ¼ãƒ–ãƒ«å
            supabase_config = self.vs_config.get('supabase', {})
            self.text_table = supabase_config.get('table_name_text', 'pdf_text_chunks')
            self.image_table = supabase_config.get('table_name_images', 'pdf_image_contents')
            self.pdf_table = supabase_config.get('table_name_pdfs', 'registered_pdfs')
            self.match_threshold = supabase_config.get('match_threshold', 0.7)
            self.storage_bucket = supabase_config.get('storage_bucket', 'pdf-images')
            self.pdf_storage_bucket = supabase_config.get('pdf_storage_bucket', 'pdf-files')

            logger.info(f"Supabase client initialized (URL: {supabase_url})")

            # Storageãƒã‚±ãƒƒãƒˆã®ç¢ºèªãƒ»ä½œæˆ
            try:
                # ãƒã‚±ãƒƒãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                buckets = self.client.storage.list_buckets()
                bucket_names = [b.name for b in buckets]

                # ç”»åƒç”¨ãƒã‚±ãƒƒãƒˆ
                if self.storage_bucket not in bucket_names:
                    # ãƒã‚±ãƒƒãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                    self.client.storage.create_bucket(
                        self.storage_bucket,
                        options={"public": False}  # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒã‚±ãƒƒãƒˆ
                    )
                    logger.info(f"Created Supabase Storage bucket: {self.storage_bucket}")
                else:
                    logger.info(f"Using existing Supabase Storage bucket: {self.storage_bucket}")

                # PDFç”¨ãƒã‚±ãƒƒãƒˆ
                if self.pdf_storage_bucket not in bucket_names:
                    self.client.storage.create_bucket(
                        self.pdf_storage_bucket,
                        options={"public": False}  # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒã‚±ãƒƒãƒˆ
                    )
                    logger.info(f"Created Supabase Storage bucket for PDFs: {self.pdf_storage_bucket}")
                else:
                    logger.info(f"Using existing Supabase Storage bucket for PDFs: {self.pdf_storage_bucket}")
            except Exception as e:
                logger.warning(f"Could not verify/create storage bucket: {e}. Continuing anyway...")

        except Exception as e:
            logger.error(f"Failed to initialize Supabase: {e}")
            raise

    def _init_chromadb(self):
        """ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        import chromadb

        chroma_config = self.vs_config.get('chromadb', {})

        # Streamlit Cloudç’°å¢ƒã‚’æ¤œå‡º
        is_streamlit_cloud = (
            os.environ.get('STREAMLIT_RUNTIME_ENV') == 'cloud' or
            os.path.exists('/mount/src') or
            'STREAMLIT_SHARING_MODE' in os.environ
        )

        if is_streamlit_cloud:
            persist_dir = '/tmp/chroma_db'
            logger.warning(f"Running on Streamlit Cloud - using PersistentClient with temporary directory: {persist_dir}")
            os.makedirs(persist_dir, exist_ok=True)
            self.client = chromadb.PersistentClient(path=persist_dir)
        else:
            self.client = chromadb.PersistentClient(
                path=chroma_config.get('persist_directory', './data/chroma_db')
            )

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
        self.text_collection_name = chroma_config.get('collection_name_text', 'pdf_text_chunks')
        self.image_collection_name = chroma_config.get('collection_name_images', 'pdf_image_contents')

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—ã¾ãŸã¯ä½œæˆ
        self.text_collection = self.client.get_or_create_collection(
            name=self.text_collection_name
        )
        self.image_collection = self.client.get_or_create_collection(
            name=self.image_collection_name
        )

    def add_text_chunks(self, chunks: List[Dict[str, Any]], embeddings: List[List[float]]):
        """
        ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ 

        Args:
            chunks: ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
            embeddings: å¯¾å¿œã™ã‚‹ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒªã‚¹ãƒˆ
        """
        if self.provider == 'supabase':
            self._add_text_chunks_supabase(chunks, embeddings)
        else:
            self._add_text_chunks_chromadb(chunks, embeddings)

    def _add_text_chunks_supabase(self, chunks: List[Dict[str, Any]], embeddings: List[List[float]]):
        """Supabaseã«ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ """
        try:
            # ãƒ‡ãƒãƒƒã‚°: Embeddingã‚µã‚¤ã‚ºã‚’ç¢ºèª
            if embeddings and len(embeddings) > 0:
                first_emb = embeddings[0]
                first_emb_dim = len(first_emb)
                logger.info(f"ğŸ” DEBUG: Saving {len(embeddings)} embeddings, first dimension: {first_emb_dim}")
                logger.info(f"ğŸ” DEBUG: Embedding type before save: {type(first_emb)}")
                logger.info(f"ğŸ” DEBUG: First 3 values: {first_emb[:3]}")
                if first_emb_dim != 3072:
                    logger.error(f"âŒ DEBUG: ABNORMAL embedding dimension before save! Expected 3072, got {first_emb_dim}")

            records = []
            for chunk, embedding in zip(chunks, embeddings):
                records.append({
                    'id': f"text_{uuid.uuid4().hex[:16]}",
                    'content': chunk['text'],
                    'embedding': embedding,  # List[float]ã®ã¾ã¾æ¸¡ã™ï¼ˆSupabaseãŒè‡ªå‹•å¤‰æ›ï¼‰
                    'source_file': chunk['source_file'],
                    'page_number': chunk['page_number'],
                    'category': chunk['category'],
                    'content_type': 'text'
                })

            self.client.table(self.text_table).insert(records).execute()
            logger.info(f"Added {len(chunks)} text chunks to Supabase")

        except Exception as e:
            logger.error(f"Error adding text chunks to Supabase: {e}")
            raise

    def _add_text_chunks_chromadb(self, chunks: List[Dict[str, Any]], embeddings: List[List[float]]):
        """ChromaDBã«ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ """
        try:
            ids = [f"text_{uuid.uuid4().hex[:16]}_{i}" for i in range(len(chunks))]
            documents = [chunk['text'] for chunk in chunks]
            metadatas = [
                {
                    'source_file': chunk['source_file'],
                    'page_number': chunk['page_number'],
                    'category': chunk['category'],
                    'content_type': 'text'
                }
                for chunk in chunks
            ]

            self.text_collection.add(
                ids=ids,
                embeddings=embeddings,
                documents=documents,
                metadatas=metadatas
            )

            logger.info(f"Added {len(chunks)} text chunks to ChromaDB")

        except Exception as e:
            logger.error(f"Error adding text chunks to ChromaDB: {e}")
            raise

    def add_image_contents_batch(self, image_data_list: List[Dict[str, Any]], embeddings: List[List[float]]):
        """
        è¤‡æ•°ã®ç”»åƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒãƒƒãƒã§ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ 

        Args:
            image_data_list: ç”»åƒãƒ‡ãƒ¼ã‚¿ã¨è§£æçµæœã®ãƒªã‚¹ãƒˆ
            embeddings: å¯¾å¿œã™ã‚‹ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒªã‚¹ãƒˆ
        """
        if not image_data_list or not embeddings:
            return

        if self.provider == 'supabase':
            self._add_image_contents_supabase(image_data_list, embeddings)
        else:
            self._add_image_contents_chromadb(image_data_list, embeddings)

    def _add_image_contents_supabase(self, image_data_list: List[Dict[str, Any]], embeddings: List[List[float]]):
        """Supabaseã«ç”»åƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½åŠ ï¼ˆç”»åƒã¯Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰"""
        try:
            from pathlib import Path

            # ãƒ‡ãƒãƒƒã‚°: Embeddingã‚µã‚¤ã‚ºã‚’ç¢ºèª
            if embeddings and len(embeddings) > 0:
                first_emb_dim = len(embeddings[0])
                logger.info(f"ğŸ” DEBUG: Saving {len(embeddings)} image embeddings, first dimension: {first_emb_dim}")
                if first_emb_dim != 3072:
                    logger.error(f"âŒ DEBUG: ABNORMAL image embedding dimension before save! Expected 3072, got {first_emb_dim}")

            records = []
            for img_data, embedding in zip(image_data_list, embeddings):
                image_id = f"image_{hashlib.md5(img_data['image_path'].encode()).hexdigest()}"

                # ç”»åƒã‚’Supabase Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                local_image_path = img_data['image_path']
                storage_path = None

                if Path(local_image_path).exists():
                    try:
                        # Storageãƒ‘ã‚¹ã‚’ç”Ÿæˆï¼ˆURL-safeå½¢å¼ï¼‰
                        # æ—¥æœ¬èªã‚’å«ã‚€ã‚«ãƒ†ã‚´ãƒªãƒ¼åãƒ»ãƒ•ã‚¡ã‚¤ãƒ«åã¯Supabase Storageã§ä½¿ãˆãªã„ãŸã‚ã€
                        # ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨
                        category = img_data.get('category', 'uncategorized')
                        filename = Path(local_image_path).name

                        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’URL-safeã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                        # ã•ã‚‰ã«ãƒãƒƒã‚·ãƒ¥ã‚’ä»˜ã‘ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯æ€§ã‚’ä¿è¨¼
                        category_hash = hashlib.md5(category.encode('utf-8')).hexdigest()[:8]
                        file_ext = Path(filename).suffix
                        file_hash = hashlib.md5(filename.encode('utf-8')).hexdigest()[:16]
                        storage_path = f"cat_{category_hash}/img_{file_hash}{file_ext}"

                        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                        with open(local_image_path, 'rb') as f:
                            image_bytes = f.read()

                        self.client.storage.from_(self.storage_bucket).upload(
                            storage_path,
                            image_bytes,
                            file_options={"content-type": "image/png", "upsert": "true"}
                        )
                        logger.debug(f"Uploaded image to Storage: {storage_path}")

                    except Exception as upload_error:
                        logger.warning(f"Failed to upload image {local_image_path} to Storage: {upload_error}")
                        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‚’ãã®ã¾ã¾ä½¿ç”¨
                        storage_path = local_image_path
                else:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‚’ãã®ã¾ã¾ä½¿ç”¨
                    logger.warning(f"Image file not found: {local_image_path}")
                    storage_path = local_image_path

                records.append({
                    'id': image_id,
                    'content': img_data.get('description', ''),
                    'embedding': embedding,  # List[float]ã®ã¾ã¾æ¸¡ã™ï¼ˆSupabaseãŒè‡ªå‹•å¤‰æ›ï¼‰
                    'source_file': img_data.get('source_file', ''),
                    'page_number': img_data.get('page_number', 0),
                    'category': img_data.get('category', ''),
                    'content_type': img_data.get('content_type', 'image'),
                    'image_path': storage_path  # Storage pathã‚’ä¿å­˜
                })

            # upsertã§on_conflictã‚’æ˜ç¤ºçš„ã«æŒ‡å®šï¼ˆä¸»ã‚­ãƒ¼idã§ç«¶åˆè§£æ±ºï¼‰
            self.client.table(self.image_table).upsert(
                records,
                on_conflict='id'
            ).execute()
            logger.info(f"Upserted {len(image_data_list)} image contents to Supabase")

        except Exception as e:
            logger.error(f"Error adding image contents to Supabase: {e}")
            raise

    def _add_image_contents_chromadb(self, image_data_list: List[Dict[str, Any]], embeddings: List[List[float]]):
        """ChromaDBã«ç”»åƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½åŠ """
        try:
            ids = [f"image_{hashlib.md5(img_data['image_path'].encode()).hexdigest()}" for img_data in image_data_list]
            documents = [img_data.get('description', '') for img_data in image_data_list]
            metadatas = [
                {
                    'source_file': img_data.get('source_file', ''),
                    'page_number': img_data.get('page_number', 0),
                    'category': img_data.get('category', ''),
                    'content_type': img_data.get('content_type', 'image'),
                    'image_path': img_data['image_path']
                }
                for img_data in image_data_list
            ]

            self.image_collection.add(
                ids=ids,
                embeddings=embeddings,
                documents=documents,
                metadatas=metadatas
            )

            logger.info(f"Added {len(image_data_list)} image contents to ChromaDB")

        except Exception as e:
            logger.error(f"Error adding image contents to ChromaDB: {e}")
            raise

    def search(self, query_embedding: List[float], category: Optional[str] = None,
               top_k: int = 5, search_type: str = 'both') -> Dict[str, List[Dict[str, Any]]]:
        """
        ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œ

        Args:
            query_embedding: ã‚¯ã‚¨ãƒªã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°
            category: æ¤œç´¢å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆNoneã®å ´åˆã¯å…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼‰
            top_k: å–å¾—ã™ã‚‹çµæœã®æ•°
            search_type: æ¤œç´¢ã‚¿ã‚¤ãƒ— ('text', 'image', 'both')

        Returns:
            dict: æ¤œç´¢çµæœï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒï¼‰
        """
        if self.provider == 'supabase':
            return self._search_supabase(query_embedding, category, top_k, search_type)
        else:
            return self._search_chromadb(query_embedding, category, top_k, search_type)

    def _search_supabase(self, query_embedding: List[float], category: Optional[str],
                        top_k: int, search_type: str) -> Dict[str, List[Dict[str, Any]]]:
        """Supabaseã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"""
        results = {'text': [], 'images': []}

        try:
            # ãƒ‡ãƒãƒƒã‚°: ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            if category:
                count_response = self.client.table(self.text_table)\
                    .select('id', count='exact')\
                    .eq('category', category)\
                    .execute()
                logger.info(f"ğŸ” DEBUG: Found {count_response.count} text chunks with category='{category}' in database")

            # ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢
            if search_type in ['text', 'both']:
                logger.info(f"Calling match_text_chunks with category={category}, top_k={top_k}, threshold={self.match_threshold}")
                # RPCãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æº–å‚™
                rpc_params = {
                    'query_embedding': query_embedding,  # List[float]ã®ã¾ã¾æ¸¡ã™ï¼ˆSupabaseãŒè‡ªå‹•å¤‰æ›ï¼‰
                    'match_threshold': self.match_threshold,
                    'match_count': top_k,
                    'filter_category': category
                }

                response = self.client.rpc('match_text_chunks', rpc_params).execute()

                logger.info(f"Text search response received: {len(response.data) if response.data else 0} results")

                if response.data and len(response.data) > 0:
                    logger.info(f"Supabase text result - Keys: {list(response.data[0].keys())}")
                    logger.info(f"Supabase text result - Sample data: source_file={response.data[0].get('source_file')}, page={response.data[0].get('page_number')}, category={response.data[0].get('category')}")

                if response.data:
                    results['text'] = [
                        {
                            'id': row.get('id', ''),
                            'content': row.get('content', ''),
                            'source_file': row.get('source_file', ''),
                            'page_number': row.get('page_number', 0),
                            'category': row.get('category', ''),
                            'content_type': 'text',  # ãƒ†ã‚­ã‚¹ãƒˆã¯å¸¸ã«'text'
                            'distance': row.get('distance', 1 - row.get('similarity', 0)),
                            'metadata': {
                                'source_file': row.get('source_file', ''),
                                'page_number': row.get('page_number', 0),
                                'category': row.get('category', ''),
                                'content_type': 'text'
                            }
                        }
                        for row in response.data
                    ]

            # ç”»åƒæ¤œç´¢
            if search_type in ['image', 'both']:
                # ãƒ‡ãƒãƒƒã‚°: ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                if category:
                    count_response = self.client.table(self.image_table)\
                        .select('id', count='exact')\
                        .eq('category', category)\
                        .execute()
                    logger.info(f"ğŸ” DEBUG: Found {count_response.count} image contents with category='{category}' in database")

                logger.info(f"Calling match_image_contents with category={category}, top_k={top_k}, threshold={self.match_threshold}")

                response = self.client.rpc(
                    'match_image_contents',
                    {
                        'query_embedding': query_embedding,  # List[float]ã®ã¾ã¾æ¸¡ã™ï¼ˆSupabaseãŒè‡ªå‹•å¤‰æ›ï¼‰
                        'match_threshold': self.match_threshold,
                        'match_count': top_k,
                        'filter_category': category
                    }
                ).execute()

                logger.info(f"Image search response received: {len(response.data) if response.data else 0} results")

                # ãƒ‡ãƒãƒƒã‚°: å®Ÿéš›ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç¢ºèª
                if response.data and len(response.data) > 0:
                    logger.info(f"Supabase image result - Keys: {list(response.data[0].keys())}")
                    logger.info(f"Supabase image result - Sample data: source_file={response.data[0].get('source_file')}, page={response.data[0].get('page_number')}, category={response.data[0].get('category')}")
                else:
                    logger.warning("No image results returned from Supabase RPC")

                if response.data:
                    results['images'] = [
                        {
                            'id': row.get('id', ''),
                            'description': row.get('content', ''),
                            'source_file': row.get('source_file', ''),
                            'page_number': row.get('page_number', 0),
                            'category': row.get('category', ''),
                            'content_type': row.get('content_type', 'image'),  # DBã‹ã‚‰å–å¾—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯'image'
                            'path': row.get('image_path', ''),
                            'distance': row.get('distance', 1 - row.get('similarity', 0)),
                            'metadata': {
                                'source_file': row.get('source_file', ''),
                                'page_number': row.get('page_number', 0),
                                'category': row.get('category', ''),
                                'content_type': row.get('content_type', 'image')
                            }
                        }
                        for row in response.data
                    ]

            logger.info(f"Search completed: {len(results['text'])} text, {len(results['images'])} images")

        except Exception as e:
            logger.error(f"Error during Supabase search: {e}")
            raise

        return results

    def _search_chromadb(self, query_embedding: List[float], category: Optional[str],
                        top_k: int, search_type: str) -> Dict[str, List[Dict[str, Any]]]:
        """ChromaDBã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"""
        results = {'text': [], 'images': []}

        try:
            where = {'category': category} if category else None

            if search_type in ['text', 'both']:
                text_results = self.text_collection.query(
                    query_embeddings=[query_embedding],
                    n_results=top_k,
                    where=where
                )
                results['text'] = self._format_chromadb_results(text_results)

            if search_type in ['image', 'both']:
                image_results = self.image_collection.query(
                    query_embeddings=[query_embedding],
                    n_results=top_k,
                    where=where
                )
                results['images'] = self._format_chromadb_results(image_results)

            logger.info(f"Search completed: {len(results['text'])} text, {len(results['images'])} images")

        except Exception as e:
            logger.error(f"Error during ChromaDB search: {e}")
            raise

        return results

    def _format_chromadb_results(self, raw_results: dict) -> List[Dict[str, Any]]:
        """ChromaDBæ¤œç´¢çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        formatted = []

        if not raw_results or not raw_results.get('ids'):
            return formatted

        for i in range(len(raw_results['ids'][0])):
            formatted.append({
                'id': raw_results['ids'][0][i],
                'document': raw_results['documents'][0][i],
                'metadata': raw_results['metadatas'][0][i],
                'distance': raw_results['distances'][0][i] if 'distances' in raw_results else None
            })

        return formatted

    def get_all_categories(self) -> List[str]:
        """
        ç™»éŒ²æ¸ˆã¿PDFã‹ã‚‰ä¸€æ„ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒªã‚¹ãƒˆã‚’å–å¾—

        Returns:
            list: ã‚«ãƒ†ã‚´ãƒªãƒ¼åã®ãƒªã‚¹ãƒˆï¼ˆé‡è¤‡ãªã—ã€ã‚½ãƒ¼ãƒˆæ¸ˆã¿ï¼‰
        """
        try:
            pdfs = self.get_registered_pdfs()
            categories = list(set(pdf['category'] for pdf in pdfs if pdf.get('category')))
            return sorted(categories)
        except Exception as e:
            logger.error(f"Error getting categories: {e}")
            return []

    def get_registered_pdfs(self) -> List[Dict[str, Any]]:
        """
        ç™»éŒ²æ¸ˆã¿PDFã®ãƒªã‚¹ãƒˆã‚’å–å¾—

        Returns:
            list: PDFãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®æƒ…å ±
        """
        if self.provider == 'supabase':
            return self._get_registered_pdfs_supabase()
        else:
            return self._get_registered_pdfs_chromadb()

    def _get_registered_pdfs_supabase(self) -> List[Dict[str, Any]]:
        """Supabaseã‹ã‚‰ç™»éŒ²æ¸ˆã¿PDFä¸€è¦§ã‚’å–å¾—"""
        try:
            # registered_pdfsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—
            response = self.client.table(self.pdf_table).select('*').execute()

            if not response.data:
                return []

            result = []
            for row in response.data:
                # ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ä»¶æ•°ã‚’é›†è¨ˆ
                text_count = self.client.table(self.text_table)\
                    .select('id', count='exact')\
                    .eq('source_file', row['filename'])\
                    .execute()

                image_count = self.client.table(self.image_table)\
                    .select('id', count='exact')\
                    .eq('source_file', row['filename'])\
                    .execute()

                result.append({
                    'source_file': row['filename'],
                    'category': row['category'],
                    'text_count': text_count.count if text_count else 0,
                    'image_count': image_count.count if image_count else 0,
                    'total_count': (text_count.count if text_count else 0) + (image_count.count if image_count else 0)
                })

            logger.info(f"Found {len(result)} registered PDFs")
            return result

        except Exception as e:
            logger.error(f"Error getting registered PDFs from Supabase: {e}")
            return []

    def _get_registered_pdfs_chromadb(self) -> List[Dict[str, Any]]:
        """ChromaDBã‹ã‚‰ç™»éŒ²æ¸ˆã¿PDFä¸€è¦§ã‚’å–å¾—"""
        try:
            pdf_info = {}

            text_data = self.text_collection.get()
            if text_data and text_data.get('metadatas'):
                for metadata in text_data['metadatas']:
                    source_file = metadata.get('source_file', '')
                    if source_file:
                        if source_file not in pdf_info:
                            pdf_info[source_file] = {
                                'source_file': source_file,
                                'category': metadata.get('category', ''),
                                'text_count': 0,
                                'image_count': 0
                            }
                        pdf_info[source_file]['text_count'] += 1

            image_data = self.image_collection.get()
            if image_data and image_data.get('metadatas'):
                for metadata in image_data['metadatas']:
                    source_file = metadata.get('source_file', '')
                    if source_file:
                        if source_file not in pdf_info:
                            pdf_info[source_file] = {
                                'source_file': source_file,
                                'category': metadata.get('category', ''),
                                'text_count': 0,
                                'image_count': 0
                            }
                        pdf_info[source_file]['image_count'] += 1

            result = []
            for pdf_data in pdf_info.values():
                pdf_data['total_count'] = pdf_data['text_count'] + pdf_data['image_count']
                result.append(pdf_data)

            result.sort(key=lambda x: x['source_file'])

            logger.info(f"Found {len(result)} registered PDFs")
            return result

        except Exception as e:
            logger.error(f"Error getting registered PDFs from ChromaDB: {e}")
            return []

    def delete_by_source_file(self, source_file: str) -> Dict[str, int]:
        """
        ç‰¹å®šã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢é€£ã™ã‚‹å…¨ã¦ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤

        Args:
            source_file: å‰Šé™¤å¯¾è±¡ã®PDFãƒ•ã‚¡ã‚¤ãƒ«å

        Returns:
            dict: å‰Šé™¤ä»¶æ•° {'text_deleted': int, 'image_deleted': int}
        """
        if self.provider == 'supabase':
            return self._delete_by_source_file_supabase(source_file)
        else:
            return self._delete_by_source_file_chromadb(source_file)

    def _delete_by_source_file_supabase(self, source_file: str) -> Dict[str, int]:
        """Supabaseã‹ã‚‰ç‰¹å®šPDFã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
        deleted_counts = {'text_deleted': 0, 'image_deleted': 0}

        try:
            # ãƒ†ã‚­ã‚¹ãƒˆå‰Šé™¤
            text_response = self.client.table(self.text_table)\
                .delete()\
                .eq('source_file', source_file)\
                .execute()
            deleted_counts['text_deleted'] = len(text_response.data) if text_response.data else 0

            # ç”»åƒå‰Šé™¤
            image_response = self.client.table(self.image_table)\
                .delete()\
                .eq('source_file', source_file)\
                .execute()
            deleted_counts['image_deleted'] = len(image_response.data) if image_response.data else 0

            # PDFç™»éŒ²æƒ…å ±å‰Šé™¤
            self.client.table(self.pdf_table)\
                .delete()\
                .eq('filename', source_file)\
                .execute()

            logger.info(f"Successfully deleted all data for {source_file} from Supabase")

        except Exception as e:
            logger.error(f"Error deleting data from Supabase for {source_file}: {e}")
            raise

        return deleted_counts

    def _delete_by_source_file_chromadb(self, source_file: str) -> Dict[str, int]:
        """ChromaDBã‹ã‚‰ç‰¹å®šPDFã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
        deleted_counts = {'text_deleted': 0, 'image_deleted': 0}

        try:
            text_data = self.text_collection.get(where={'source_file': source_file})
            if text_data and text_data.get('ids'):
                text_ids = text_data['ids']
                if text_ids:
                    self.text_collection.delete(ids=text_ids)
                    deleted_counts['text_deleted'] = len(text_ids)

            image_data = self.image_collection.get(where={'source_file': source_file})
            if image_data and image_data.get('ids'):
                image_ids = image_data['ids']
                if image_ids:
                    self.image_collection.delete(ids=image_ids)
                    deleted_counts['image_deleted'] = len(image_ids)

            logger.info(f"Successfully deleted all data for {source_file} from ChromaDB")

        except Exception as e:
            logger.error(f"Error deleting data from ChromaDB for {source_file}: {e}")
            raise

        return deleted_counts

    def register_pdf(self, filename: str, category: str, storage_path: Optional[str] = None):
        """
        PDFã‚’registered_pdfsãƒ†ãƒ¼ãƒ–ãƒ«ã«ç™»éŒ²

        Args:
            filename: PDFãƒ•ã‚¡ã‚¤ãƒ«å
            category: ã‚«ãƒ†ã‚´ãƒªãƒ¼
            storage_path: Supabase Storageãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        if self.provider == 'supabase':
            try:
                data = {
                    'filename': filename,
                    'category': category
                }
                if storage_path:
                    data['storage_path'] = storage_path

                self.client.table(self.pdf_table).upsert(data).execute()
                logger.info(f"Registered PDF in Supabase: {filename} (storage_path: {storage_path})")
            except Exception as e:
                logger.error(f"Error registering PDF in Supabase: {e}")
                raise

    def upload_pdf_to_storage(self, pdf_path: str, filename: str, category: str) -> str:
        """
        PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’Supabase Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

        Args:
            pdf_path: ãƒ­ãƒ¼ã‚«ãƒ«ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            filename: PDFãƒ•ã‚¡ã‚¤ãƒ«å
            category: ã‚«ãƒ†ã‚´ãƒªãƒ¼

        Returns:
            str: Storageãƒ‘ã‚¹
        """
        if self.provider != 'supabase':
            logger.warning("PDF upload to storage is only supported for Supabase provider")
            return ""

        try:
            from pathlib import Path
            import hashlib
            from datetime import datetime

            # Storageãƒ‘ã‚¹ã‚’ç”Ÿæˆï¼ˆæ—¥æœ¬èªã‚’é¿ã‘ã‚‹ãŸã‚ã€ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼‰
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨æ—¥æ™‚ã®ãƒãƒƒã‚·ãƒ¥ã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            category_hash = hashlib.md5(category.encode('utf-8')).hexdigest()[:8]
            timestamp = datetime.now().strftime("%Y%m%d")

            # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ‹¡å¼µå­ã‚’ä¿æŒ
            file_extension = Path(filename).suffix
            filename_hash = hashlib.md5(filename.encode('utf-8')).hexdigest()[:16]

            # è‹±æ•°å­—ã®ã¿ã®ãƒ‘ã‚¹ã‚’ç”Ÿæˆ: cat_{hash}/file_{hash}_{timestamp}.pdf
            storage_path = f"cat_{category_hash}/file_{filename_hash}_{timestamp}{file_extension}"

            # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with open(pdf_path, 'rb') as f:
                pdf_bytes = f.read()

            # Supabase Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            self.client.storage.from_(self.pdf_storage_bucket).upload(
                storage_path,
                pdf_bytes,
                file_options={"content-type": "application/pdf", "upsert": "true"}
            )
            logger.info(f"Uploaded PDF to Supabase Storage: {storage_path}")

            return storage_path

        except Exception as e:
            logger.error(f"Error uploading PDF to Supabase Storage: {e}")
            raise

    def get_pdf_url_from_storage(self, filename: str) -> Optional[str]:
        """
        Supabase Storageã‹ã‚‰PDFã®ç½²åä»˜ãURLã‚’å–å¾—

        Args:
            filename: PDFãƒ•ã‚¡ã‚¤ãƒ«å

        Returns:
            str: ç½²åä»˜ãURLï¼ˆæœ‰åŠ¹æœŸé™: 1æ™‚é–“ï¼‰ã€å–å¾—å¤±æ•—æ™‚ã¯None
        """
        if self.provider != 'supabase':
            return None

        try:
            # registered_pdfsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰storage_pathã‚’å–å¾—
            response = self.client.table(self.pdf_table)\
                .select('storage_path')\
                .eq('filename', filename)\
                .execute()

            if not response.data or len(response.data) == 0:
                logger.warning(f"PDF not found in database: {filename}")
                return None

            storage_path = response.data[0].get('storage_path')
            if not storage_path:
                logger.warning(f"No storage_path found for PDF: {filename}")
                return None

            # ç½²åä»˜ãURLã‚’ç”Ÿæˆï¼ˆæœ‰åŠ¹æœŸé™: 3600ç§’ = 1æ™‚é–“ï¼‰
            url_response = self.client.storage.from_(self.pdf_storage_bucket)\
                .create_signed_url(storage_path, 3600)

            if url_response and 'signedURL' in url_response:
                logger.info(f"Generated signed URL for PDF: {filename}")
                return url_response['signedURL']
            else:
                logger.error(f"Failed to generate signed URL for PDF: {filename}")
                return None

        except Exception as e:
            logger.error(f"Error getting PDF URL from Supabase Storage: {e}")
            return None

    def download_pdf_from_storage(self, filename: str, destination_path: str) -> bool:
        """
        Supabase Storageã‹ã‚‰PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

        Args:
            filename: PDFãƒ•ã‚¡ã‚¤ãƒ«å
            destination_path: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆãƒ‘ã‚¹

        Returns:
            bool: æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        if self.provider != 'supabase':
            return False

        try:
            # registered_pdfsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰storage_pathã‚’å–å¾—
            response = self.client.table(self.pdf_table)\
                .select('storage_path')\
                .eq('filename', filename)\
                .execute()

            if not response.data or len(response.data) == 0:
                logger.warning(f"PDF not found in database: {filename}")
                return False

            storage_path = response.data[0].get('storage_path')
            if not storage_path:
                logger.warning(f"No storage_path found for PDF: {filename}")
                return False

            # PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            pdf_bytes = self.client.storage.from_(self.pdf_storage_bucket)\
                .download(storage_path)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(destination_path, 'wb') as f:
                f.write(pdf_bytes)

            logger.info(f"Downloaded PDF from Supabase Storage: {filename} -> {destination_path}")
            return True

        except Exception as e:
            logger.error(f"Error downloading PDF from Supabase Storage: {e}")
            return False

    def debug_inspect_data(self, category: str, limit: int = 5) -> Dict[str, Any]:
        """
        ãƒ‡ãƒãƒƒã‚°ç”¨: ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª

        Args:
            category: ã‚«ãƒ†ã‚´ãƒªãƒ¼å
            limit: å–å¾—ã™ã‚‹ä»¶æ•°

        Returns:
            dict: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
        """
        if self.provider != 'supabase':
            logger.warning("debug_inspect_data is only supported for Supabase")
            return {}

        try:
            result = {
                'category': category,
                'text_chunks': [],
                'images': []
            }

            # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã®ã‚µãƒ³ãƒ—ãƒ«å–å¾—
            text_response = self.client.table(self.text_table)\
                .select('id, content, source_file, page_number, category')\
                .eq('category', category)\
                .limit(limit)\
                .execute()

            if text_response.data:
                result['text_chunks'] = text_response.data
                logger.info(f"ğŸ“Š DEBUG: Sample text chunks for '{category}':")
                for i, chunk in enumerate(text_response.data[:3], 1):
                    logger.info(f"  [{i}] {chunk['source_file']} (page {chunk['page_number']})")
                    logger.info(f"      Content preview: {chunk['content'][:100]}...")

            # ç”»åƒã®ã‚µãƒ³ãƒ—ãƒ«å–å¾—
            image_response = self.client.table(self.image_table)\
                .select('id, content, source_file, page_number, category, content_type')\
                .eq('category', category)\
                .limit(limit)\
                .execute()

            if image_response.data:
                result['images'] = image_response.data
                logger.info(f"ğŸ“Š DEBUG: Sample images for '{category}':")
                for i, img in enumerate(image_response.data[:3], 1):
                    logger.info(f"  [{i}] {img['source_file']} (page {img['page_number']}, type: {img.get('content_type', 'image')})")
                    logger.info(f"      Description preview: {img['content'][:100]}...")

            # embeddingãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            text_with_emb = self.client.table(self.text_table)\
                .select('id, embedding')\
                .eq('category', category)\
                .limit(1)\
                .execute()

            if text_with_emb.data and len(text_with_emb.data) > 0:
                embedding = text_with_emb.data[0].get('embedding')
                if embedding:
                    logger.info(f"âœ… DEBUG: Embedding exists, dimension: {len(embedding)}")
                    logger.info(f"ğŸ” DEBUG: Embedding type: {type(embedding)}")
                    logger.info(f"ğŸ” DEBUG: First 5 elements: {embedding[:5]}")

                    # ç•°å¸¸ãªæ¬¡å…ƒæ•°ã®å ´åˆã¯è­¦å‘Š
                    if len(embedding) != 3072:
                        logger.error(f"âŒ DEBUG: ABNORMAL embedding dimension! Expected 3072, got {len(embedding)}")
                        logger.error(f"   This will cause vector search to fail!")
                else:
                    logger.error(f"âŒ DEBUG: Embedding field is NULL!")

            return result

        except Exception as e:
            logger.error(f"Error inspecting data: {e}")
            return {}
