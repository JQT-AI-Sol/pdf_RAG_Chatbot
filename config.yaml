# OpenAI設定
openai:
  model_chat: "gpt-4.1"  # GPT-4.1を使用（ストリーミング対応）
  model_vision: "gpt-4.1"  # GPT-4.1を画像解析用モデルとして使用
  model_embedding: "text-embedding-3-large"  # より高性能なembedding
  temperature: 0.7  # 温度パラメータ
  max_tokens: 16000  # 最大トークン数

# Gemini設定
gemini:
  model_chat: "gemini-2.5-pro"  # チャット用モデル
  model_vision: "gemini-2.5-pro"  # 画像解析用モデル
  max_tokens: 8192  # 最大出力トークン数
  temperature: 0.7  # 温度パラメータ
  # GEMINI_API_KEY環境変数から読み込み

# Vector Store設定
vector_store:
  provider: "supabase"  # "chromadb" or "supabase"

  # ChromaDB設定（ローカル開発用）
  chromadb:
    persist_directory: "./data/chroma_db"
    collection_name_text: "pdf_text_chunks"
    collection_name_images: "pdf_image_contents"

  # Supabase設定（本番環境用）
  supabase:
    # 環境変数から読み込み: SUPABASE_URL, SUPABASE_KEY
    table_name_text: "pdf_text_chunks"
    table_name_images: "pdf_image_contents"
    table_name_pdfs: "registered_pdfs"
    match_threshold: 0.5  # 類似度閾値
    storage_bucket: "pdf-images"  # Supabase Storage バケット名（画像用）
    pdf_storage_bucket: "pdf-files"  # Supabase Storage バケット名（PDF用）

# ドキュメントアップロード設定
pdf_upload:
  max_file_size_mb: 50  # 最大ファイルサイズ（MB）- 全ドキュメント形式に適用

# Office→PDF変換設定（Word/Excel/PowerPoint用）
office_to_pdf_conversion:
  enabled: true  # Office→PDF変換を有効化
  timeout: 60  # 変換タイムアウト（秒）
  output_directory: "data/converted_pdfs"  # 変換後のPDF保存先
  cache_converted_pdfs: true  # 変換済みPDFをキャッシュ（再アップロード時に高速化）
  fallback_on_error: true  # 変換失敗時はテキスト抽出のみで継続
  enable_preview: true  # 変換後のPDFでプレビュー・ハイライト機能を有効化

# ドキュメント処理設定（PDF、Word、Excel、PowerPoint、Text共通）
pdf_processing:
  chunk_size: 800
  chunk_overlap: 150
  max_files: 5
  extract_images: true
  min_image_size: 100  # 最小画像サイズ（px）
  image_crop_margin: 150  # 画像切り取り時のマージン（px）- グラフの切れを防ぐ

  # 表の処理設定
  extract_tables_as_markdown: true  # 表をMarkdown形式で抽出（並列処理で高速化）
  table_classification: true  # シンプル/複雑を自動分類
  complex_table_threshold: 100  # 100セル以上で複雑と判定（10×10までMarkdown化）
  merged_cell_threshold: 0.4  # 結合セルが40%以上で複雑と判定（統計マトリクスはMarkdown優先）
  exclude_tables_from_page_text: true  # Markdown化した表の領域をページテキストから除外（表単位でチャンク化）

  # 表検出の最適化設定（速度重視）
  table_detection_strategy: "fast"  # "fast" or "accurate" (デフォルト: fast)
  # fastモード: 精度を少し犠牲にして高速化（処理時間: 2-3秒/ページ）
  # accurateモード: 高精度だが低速（処理時間: 8-10秒/ページ）

  # グラフの処理設定
  detect_charts: true  # グラフの自動検出
  save_charts_as_images: true  # グラフを画像として保存

  # コンテキスト設定
  include_surrounding_context: true  # 前後の文脈を含める
  context_lines_before: 3  # 前の文脈の行数
  context_lines_after: 2  # 後の文脈の行数

# Excel処理設定
excel_processing:
  enable_llm_summarization: true  # LLMで表を自然言語要約（検索精度大幅向上）
  # 注意: ExcelはPDF変換せず直接処理（app.pyで制御）、Vision AIの設定は適用されない
  summarization_prompt: |
    あなたはExcelの表データを自然な日本語で説明する専門家です。
    以下のMarkdown形式の表データを、検索しやすい自然な日本語の文章に変換してください。

    【出力形式】
    1. **最初の1-2文**で、このシートの内容を50-100文字で簡潔に要約してください
    2. その後、詳細な説明を記載してください

    【変換のルール】
    1. 表の内容を正確に説明する（シート名: {sheet_name}）
    2. 数値データは具体的な値を含める
    3. 表の構造（行・列の関係）を文章で表現
    4. 重要なキーワードを繰り返して検索性を向上
    5. 箇条書きや段落を使って読みやすくする
    6. 表のタイトルや見出しから文脈を推測して説明を補完

    【Markdown表データ】
    {markdown_table}

    【自然言語での説明】

# Vision設定
vision:
  max_image_size: 2000  # ピクセル
  image_format: "PNG"
  enable_caching: true  # 同じ画像の再処理を避ける

  # Vision AI使用範囲
  # 注意: analysis_prompt_tableとanalysis_prompt_graphはこのvisionセクション内で定義されています
  use_for_charts_only: true  # グラフのみVision使用（推奨）
  use_for_complex_tables: true  # PDFの複雑な表をVision AIで自然言語化（Excelは別途LLM要約）
  use_for_simple_tables: false  # シンプルな表はMarkdown化のみ
  analysis_prompt_table: |
    【重要】あなたは技術文書・制度説明資料を解析する専門家です。
    以下の画像から情報を抽出する際、必ず以下のルールに従ってください。

    【絶対に守るべきルール】
    ❌ JSON形式で出力しないでください
    ❌ コードブロック（```）を使用しないでください
    ❌ 構造化データ（{...}）を使用しないでください
    ✅ 必ず平文の日本語テキストのみで出力してください

    【抽出する情報】
    以下の画像は文書ページまたは表が含まれています。画像から以下の情報を抽出してください：

    1. **ページ全体の内容**
       - タイトルや見出しを記載
       - 本文のテキストを一字一句そのまま抽出
       - 箇条書きや番号付きリストは「・」や「1.」などを使って記載

    2. **表がある場合（最重要）**
       - 表のタイトルを記載
       - 列の見出し（ヘッダー行）をすべて記載
       - **全ての行と全ての列のデータを必ず抽出してください**
       - **空欄やダッシュ記号（ー）も含めて、すべてのセルの内容を記載してください**
       - **数値データ（金額、時間、パーセンテージなど）は必ず具体的な値を記載してください**
       - 各行のデータは「行1: 列1の値, 列2の値, 列3の値, ...」のように記載
       - セルが空欄の場合は「（空欄）」と明記
       - セルに「ー」がある場合は「ー」と明記
       - **絶対に「記載なし」「データなし」などと省略しないでください**

    3. **その他の情報**
       - 注釈や補足説明をすべて記載
       - 参照情報や連絡先を記載

    【表データ抽出の例】
    「計画と1人当たり助成額に関する表

    列見出し: 週所定労働時間の延長、賃金の増額、1人当たり助成額（小規模企業）、1人当たり助成額（中小企業）、1人当たり助成額（大企業）

    行1: 5時間以上の延長、ー、50万円、40万円、30万円
    行2: 4時間以上5時間未満の延長、賃金5%以上増額、50万円、40万円、30万円
    行3: 3時間以上4時間未満の延長、賃金10%以上増額、50万円、40万円、30万円
    ...」

    このように、表のすべてのセル（空欄や記号も含む）を漏れなく抽出してください。
    画像内のすべてのテキストを省略せず、完全に抽出してください。

  analysis_prompt_graph: |
    あなたは技術文書のグラフを解析する専門家です。
    以下の画像は技術マニュアルに含まれるグラフです。

    以下の情報を抽出してください：

    1. **グラフの種類**
       - 折れ線グラフ、棒グラフ、円グラフ、散布図など

    2. **視覚的な特徴**
       - データの傾向（増加、減少、一定など）
       - 特異点や注目すべきポイント

    3. **数値データ（重要）**
       - X軸とY軸のラベル・単位
       - グラフ内の具体的なデータポイント（可能な限り）
       - 凡例の内容
       - グラフタイトル

    4. **主要な洞察**
       - このグラフから読み取れる重要な情報

    JSON形式で構造化して出力してください：
    {
      "graph_type": "...",
      "title": "...",
      "axes": {"x": "...", "y": "..."},
      "data_points": [...],
      "insights": "..."
    }

  analysis_prompt_ocr: |
    【重要】あなたはOCR（光学文字認識）の専門家です。
    以下の画像からすべてのテキストを抽出し、JSON形式で出力してください。

    【出力形式】
    必ずJSON形式で出力してください。各テキスト要素には以下の情報を含めること：
    {
      "words": [
        {
          "text": "抽出されたテキスト",
          "confidence": 0.95,
          "bbox": {"x0": 10, "y0": 20, "x1": 100, "y1": 40}
        },
        ...
      ],
      "full_text": "ページ全体のテキスト（読み順に並べたもの）"
    }

    【抽出ルール】
    1. **すべてのテキストを抽出**
       - 見出し、本文、図表内の文字、注釈など、すべてのテキストを漏れなく抽出
       - 数値、記号、句読点も正確に抽出

    2. **座標情報（bbox）**
       - x0, y0: テキストの左上座標（ピクセル単位）
       - x1, y1: テキストの右下座標（ピクセル単位）
       - 画像の左上が原点(0,0)

    3. **信頼度（confidence）**
       - 0.0〜1.0の範囲で、認識の確信度を推定
       - 明確なテキスト: 0.9以上
       - やや不明瞭: 0.7〜0.9
       - 不明瞭: 0.7未満

    4. **読み順**
       - 上から下、左から右の順で抽出
       - full_textには読み順通りに並べる

    【注意事項】
    - 必ずJSONコードブロック（```json）で囲んでください
    - テキストが存在しない場合は空配列を返してください
    - 座標は画像サイズに対する相対値ではなく、絶対ピクセル値で指定

# PDFページハイライト設定
pdf_highlighting:
  enabled: true  # PDFページプレビュー機能を有効化
  method: "hybrid"  # ハイライト方式: "keyword", "embedding", "llm", "hybrid"
  use_llm_keywords: true  # LLMを使用したキーワード抽出（推奨）
  # falseの場合はMeCabトークン化にフォールバック

  # 表示設定
  max_pages_to_display: 5  # 表示する最大ページ数
  columns_per_row: 3  # 1行あたりの列数（グリッドレイアウト）
  max_chunks_per_page: 3  # 1ページあたりの最大ハイライトチャンク数（多すぎる場合は上位のみ）

  # 画像生成設定
  dpi: 150  # ページ画像の解像度（高いほど鮮明だが重い）
  target_width: 1000  # 画像の幅（ピクセル）

  # ハイライト設定
  highlight_color:
    r: 255  # 赤成分 (0-255)
    g: 255  # 緑成分 (0-255)
    b: 0    # 青成分 (0-255)
    alpha: 80  # 透明度 (0-255、低いほど透明)
  highlight_padding: 2  # ハイライト矩形のパディング（ピクセル）

  # LLMキーワード抽出設定
  llm_extraction:
    max_keywords: 10  # 抽出する最大キーワード数
    min_keyword_length: 2  # 最小キーワード長（文字数）

  # ハイブリッドモード設定（method="hybrid"の場合）
  hybrid:
    embedding_threshold: 0.5  # エンベディング類似度閾値（0-1）- 0.65→0.5に緩和
    max_candidates: 20  # Stage 1で絞り込む候補文数 - 15→20に増加
    max_final: 8  # Stage 2で最終選択する文数 - 5→8に増加
    use_llm_refinement: true  # LLMによる精査を有効化
    fallback_to_keyword: true  # エラー時にキーワード方式にフォールバック

  # キーワードモード設定（method="keyword"またはフォールバック時）
  keyword:
    min_length: 2  # 最小キーワード長（文字）
    use_unicode_normalization: true  # Unicode正規化（日本語対応）
    case_insensitive: false  # 大文字小文字を区別しない（日本語では無効）

# RAG性能向上設定 (Phase 1: Quick Wins)
rag:
  enable_reranking: true  # Rerankingによる検索精度向上
  enable_semantic_chunking: true  # セマンティックチャンキングによるコンテキスト品質向上
  enable_embedding_cache: true  # エンベディングキャッシングによるレイテンシ削減
  enable_vision_cache: true  # Vision解析キャッシングによるコスト削減
  enable_bm25_hybrid: true  # BM25ハイブリッド検索によるリコール向上

# チャンキング設定（Semantic Chunking用）
chunking:
  chunk_size: 800  # トークン単位でのチャンクサイズ
  chunk_overlap: 150  # チャンク間のオーバーラップ
  separators:  # 区切り文字の優先順位（日本語・英語対応）
    - "\n\n"  # 段落区切り（最優先）
    - "\n"    # 改行
    - "。"    # 日本語の句点
    - "．"    # 全角ピリオド
    - ". "    # 英語の文末
    - "! "    # 感嘆符
    - "? "    # 疑問符
    - "；"    # セミコロン
    - "、"    # 読点
    - ", "    # カンマ
    - " "     # スペース
    - ""      # 文字単位（最終手段）

# Reranking設定
reranking:
  provider: "cohere"  # "local" (ローカルモデル) or "cohere" (Cohere API)

  # ローカルReranker設定（provider="local"の場合）
  model: "cross-encoder/ms-marco-MiniLM-L-6-v2"  # 軽量高速モデル（~80MB）
  # Alternative: "cross-encoder/ms-marco-electra-base" (より高精度だが重い)

  # Cohere Reranker設定（provider="cohere"の場合）
  cohere:
    model: "rerank-multilingual-v3.0"  # 日本語に最適（推奨）
    # Alternative: "rerank-english-v3.0" (英語専用)
    api_key_env: "COHERE_API_KEY"  # 環境変数名（.envに設定）

  top_k_initial: 10  # 初期検索で取得する文書数（vector searchから）
  top_k_final: 5  # Reranking後に返す最終文書数
  # Note: Cohereの場合、高精度のためtop_k_finalを小さくしても品質維持可能

# BM25ハイブリッド検索設定
hybrid_search:
  enabled: true  # ハイブリッド検索を有効化
  alpha: 0.5  # ベクトル検索の重み（0-1）、BM25の重みは1-alpha
  # alpha=0.5 → 50%セマンティック + 50%キーワード（バランス重視、キーワード完全一致を優先）
  # alpha=0.7 → 70%セマンティック + 30%キーワード
  # alpha=0.9 → セマンティック重視

# キャッシュ設定
cache:
  embedding:
    enabled: true  # エンベディングキャッシュを有効化
    directory: "./cache/embeddings"  # キャッシュディレクトリ
    max_memory_items: 1000  # メモリキャッシュの最大アイテム数（LRU）

  vision:
    enabled: true  # Vision解析キャッシュを有効化
    directory: "./cache/vision_analysis"  # キャッシュディレクトリ
    expiry_days: 30  # キャッシュ有効期限（日数）- 現在は未使用

# 検索設定
search:
  top_k_text: 10  # 5→10に増加（Reranking用に多めに取得）
  top_k_images: 5  # コンテキスト最適化（アップロード画像5枚+検索画像5枚=最大10枚）
  similarity_threshold: 0.7
  enable_hybrid_search: true  # テキストと画像の統合検索
  enable_category_filter: true  # カテゴリーフィルタリング有効化

# カテゴリー設定
category:
  storage_file: "./data/categories.json"  # カテゴリー一覧保存先
  allow_custom: true  # カスタムカテゴリー入力を許可

# パフォーマンス設定
performance:
  max_workers: 4  # 並列処理のワーカー数（画像解析用）
  embedding_batch_size: 100  # エンベディングバッチサイズ

# ログ設定
logging:
  level: "INFO"  # Cohere Rerankingデバッグ用に一時的にINFOに戻す
  file: "./logs/app.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Langfuse設定
langfuse:
  enabled: true  # Langfuseトレーシングを有効化
  # LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, LANGFUSE_HOST環境変数から読み込み

# チャット設定
chat:
  max_history_messages: 10  # 履歴の最大メッセージ数（user+assistantの合計）
  include_images_in_history: false  # 履歴に画像を含めるか（false推奨: トークン節約）
