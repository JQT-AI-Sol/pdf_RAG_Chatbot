"""
Streamlit Application for PDF RAG System
"""

import streamlit as st
import logging
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

# src ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.utils import load_config, load_environment, ensure_directories, setup_logging, encode_pdf_to_base64
from src.document_processor import DocumentProcessor
from src.text_embedder import TextEmbedder
from src.vision_analyzer import VisionAnalyzer
from src.vector_store import VectorStore
from src.rag_engine import RAGEngine
from src.pdf_manager import PDFManager
from src.pdf_page_renderer import extract_page_as_image, extract_multiple_pages, extract_page_with_highlight, PDF2IMAGE_AVAILABLE, get_pdf_path, create_pdf_annotations_pymupdf

# streamlit-pdf-viewer ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from streamlit_pdf_viewer import pdf_viewer
    STREAMLIT_PDF_VIEWER_AVAILABLE = True
    logger.info("âœ… streamlit-pdf-viewer is available")
except ImportError:
    STREAMLIT_PDF_VIEWER_AVAILABLE = False
    logger.warning("âŒ streamlit-pdf-viewer not available - using fallback image display")

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="PDF RAG System",
    page_icon="ğŸ“š",
    layout="wide"
)


def initialize_app():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–"""
    # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
    load_environment()

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    ensure_directories()

    # è¨­å®šèª­ã¿è¾¼ã¿
    config = load_config()

    # ãƒ­ã‚°è¨­å®š
    logger = setup_logging(config)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        st.session_state.config = config
        st.session_state.document_processor = DocumentProcessor(config)
        st.session_state.embedder = TextEmbedder(config)
        st.session_state.vision_analyzer = VisionAnalyzer(config)
        st.session_state.vector_store = VectorStore(config)
        st.session_state.rag_engine = RAGEngine(
            config,
            st.session_state.vector_store,
            st.session_state.embedder
        )
        st.session_state.pdf_manager = PDFManager(
            st.session_state.vector_store,
            config
        )
        st.session_state.chat_history = []
        st.session_state.selected_category = "å…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼"
        st.session_state.selected_model = "openai"

        # Vision Analyzerã®çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
        if not st.session_state.vision_analyzer.api_key_valid:
            st.session_state.vision_disabled = True
            logger.warning("Vision analysis is disabled due to missing or invalid OPENAI_API_KEY")
        else:
            st.session_state.vision_disabled = False

    return config


def sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®UI"""
    st.sidebar.title("ğŸ“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†")

    # Vision Analyzerè­¦å‘Šè¡¨ç¤º
    if st.session_state.get('vision_disabled', False):
        st.sidebar.warning(
            "âš ï¸ ç”»åƒè§£ææ©Ÿèƒ½ãŒç„¡åŠ¹ã§ã™\n\n"
            "OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
            "ç”»åƒã‚„ã‚°ãƒ©ãƒ•ã®è§£æã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ã€.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )

    # PDF Page Previewè­¦å‘Šè¡¨ç¤º
    if not PDF2IMAGE_AVAILABLE:
        st.sidebar.info(
            "â„¹ï¸ PDFãƒšãƒ¼ã‚¸ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ãŒç„¡åŠ¹ã§ã™\n\n"
            "**ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼ˆWindowsï¼‰:**\n"
            "Popplerã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚\n"
            "`choco install poppler` ã¾ãŸã¯\n"
            "[æ‰‹å‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](https://github.com/oschwartz10612/poppler-windows/releases)\n\n"
            "**Streamlit Cloud:**\n"
            "è‡ªå‹•çš„ã«æœ‰åŠ¹ã«ãªã‚Šã¾ã™ï¼ˆpackages.txtå¯¾å¿œæ¸ˆã¿ï¼‰"
        )

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.sidebar.subheader("ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_files = st.sidebar.file_uploader(
        "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (PDF, Word, Excel, PowerPoint, Text)",
        type=['pdf', 'docx', 'doc', 'xlsx', 'xls', 'pptx', 'ppt', 'txt'],
        accept_multiple_files=True,
        help="å¯¾å¿œå½¢å¼: PDF, Word, Excel, PowerPoint, Text"
    )

    # ã‚«ãƒ†ã‚´ãƒªãƒ¼å…¥åŠ›
    category = st.sidebar.text_input(
        "ã‚«ãƒ†ã‚´ãƒªãƒ¼å",
        placeholder="ä¾‹: è£½å“ãƒãƒ‹ãƒ¥ã‚¢ãƒ«"
    )

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆãƒœã‚¿ãƒ³
    if st.sidebar.button("ğŸ“‘ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ", type="primary"):
        if uploaded_files and category:
            process_documents(uploaded_files, category)
        else:
            st.sidebar.error("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚«ãƒ†ã‚´ãƒªãƒ¼åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    # ç™»éŒ²æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªãƒ¼è¡¨ç¤º
    st.sidebar.subheader("ğŸ“‚ ç™»éŒ²æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªãƒ¼")
    try:
        categories = st.session_state.vector_store.get_all_categories()
        if categories:
            for cat in categories:
                st.sidebar.text(f"â€¢ {cat}")
        else:
            st.sidebar.info("ã¾ã ã‚«ãƒ†ã‚´ãƒªãƒ¼ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    except Exception as e:
        st.sidebar.error(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        categories = []

    # ç™»éŒ²æ¸ˆã¿PDFç®¡ç†
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“„ ç™»éŒ²æ¸ˆã¿PDFç®¡ç†")

    registered_pdfs = st.session_state.pdf_manager.get_registered_pdfs()
    if registered_pdfs:
        for pdf in registered_pdfs:
            with st.sidebar.expander(f"ğŸ“„ {pdf['source_file']}", expanded=False):
                st.write(f"**ã‚«ãƒ†ã‚´ãƒªãƒ¼**: {pdf['category']}")
                st.write(f"**ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿**: {pdf['text_count']} ä»¶")
                st.write(f"**ç”»åƒãƒ‡ãƒ¼ã‚¿**: {pdf['image_count']} ä»¶")
                st.write(f"**åˆè¨ˆ**: {pdf['total_count']} ä»¶")

                # ãƒœã‚¿ãƒ³ã‚’2åˆ—ã«é…ç½®
                col1, col2 = st.columns(2)

                with col1:
                    # é–²è¦§ãƒœã‚¿ãƒ³
                    pdf_path = Path("data/uploaded_pdfs") / pdf['source_file']
                    # Supabase Storageã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if st.session_state.vector_store.provider == 'supabase' or pdf_path.exists():
                        show_pdf_link(pdf_path, pdf['source_file'], key_suffix="sidebar")
                    else:
                        st.error(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pdf['source_file']}")

                with col2:
                    # å‰Šé™¤ãƒœã‚¿ãƒ³ï¼ˆã‚¢ã‚¤ã‚³ãƒ³ã®ã¿ï¼‰
                    delete_key = f"delete_{pdf['source_file']}"
                    if st.button("ğŸ—‘ï¸", key=delete_key, type="secondary", use_container_width=True, help="PDFã‚’å‰Šé™¤ã™ã‚‹"):
                        # å‰Šé™¤ç¢ºèªç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’è¨­å®š
                        st.session_state.delete_target = pdf['source_file']
                        st.session_state.show_delete_confirm = True
                        st.rerun()
    else:
        st.sidebar.info("ç™»éŒ²æ¸ˆã¿PDFãŒã‚ã‚Šã¾ã›ã‚“")

    # ãƒãƒ£ãƒƒãƒˆè¨­å®š
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ¤– ãƒãƒ£ãƒƒãƒˆè¨­å®š")

    # ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠ
    try:
        categories = ["å…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼"] + st.session_state.vector_store.get_all_categories()
    except Exception as e:
        st.sidebar.warning(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        categories = ["å…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼"]

    st.session_state.selected_category = st.sidebar.selectbox(
        "ğŸ” æ¤œç´¢å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªãƒ¼",
        categories,
        index=categories.index(st.session_state.selected_category) if st.session_state.selected_category in categories else 0,
        help="è³ªå•ã™ã‚‹å¯¾è±¡ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )

    # AIãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_options = {
        "GPT-4.1": "openai",
        "Gemini-2.5-Pro": "gemini"
    }
    current_model_display = [k for k, v in model_options.items() if v == st.session_state.selected_model][0]
    selected_model_display = st.sidebar.selectbox(
        "ğŸ¤– AIãƒ¢ãƒ‡ãƒ«",
        list(model_options.keys()),
        index=list(model_options.keys()).index(current_model_display),
        help="ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"
    )
    st.session_state.selected_model = model_options[selected_model_display]

    # ãƒãƒ£ãƒƒãƒˆãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ", type="secondary"):
        st.session_state.chat_history = []
        st.rerun()


def process_documents(uploaded_files, category):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPDFã€Wordã€Excelï¼‰ã‚’å‡¦ç†"""
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯Supabaseã®registered_pdfsãƒ†ãƒ¼ãƒ–ãƒ«ã«è‡ªå‹•ä¿å­˜ã•ã‚Œã‚‹ãŸã‚ã€
    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ä¿å­˜ã¯ä¸è¦

    progress_bar = st.sidebar.progress(0)
    status_text = st.sidebar.empty()

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ä¸Šé™ã‚’å–å¾—
    max_size_mb = st.session_state.config.get('pdf_upload', {}).get('max_file_size_mb', 50)

    for i, uploaded_file in enumerate(uploaded_files):
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            file_size_mb = len(uploaded_file.getbuffer()) / (1024 * 1024)
            if file_size_mb > max_size_mb:
                st.sidebar.error(f"{uploaded_file.name}: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒä¸Šé™ï¼ˆ{max_size_mb}MBï¼‰ã‚’è¶…ãˆã¦ã„ã¾ã™ï¼ˆ{file_size_mb:.1f}MBï¼‰")
                continue

            # 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜ï¼ˆdata/uploaded_pdfs/ ã¨ static/pdfs/ ã®ä¸¡æ–¹ï¼‰
            # æ³¨: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã¯PDFæ™‚ä»£ã®åæ®‹ã ãŒã€å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ã§ä½¿ç”¨
            status_text.text(f"å‡¦ç†ä¸­: {uploaded_file.name} (1/?) - ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
            doc_path = Path("data/uploaded_pdfs") / uploaded_file.name
            doc_path.parent.mkdir(parents=True, exist_ok=True)
            static_doc_path = Path("static/pdfs") / uploaded_file.name
            static_doc_path.parent.mkdir(parents=True, exist_ok=True)

            doc_bytes = uploaded_file.getbuffer()
            with open(doc_path, "wb") as f:
                f.write(doc_bytes)
            with open(static_doc_path, "wb") as f:
                f.write(doc_bytes)

            # 2. ãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒæŠ½å‡º
            status_text.text(f"å‡¦ç†ä¸­: {uploaded_file.name} (2/?) - ãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒæŠ½å‡ºä¸­...")
            try:
                logging.info(f"Starting document processing for {uploaded_file.name}")
                doc_result = st.session_state.document_processor.process_document(str(doc_path), category)
                logging.info(f"Document processing completed for {uploaded_file.name}: {len(doc_result.get('text_chunks', []))} text chunks, {len(doc_result.get('images', []))} images")
            except Exception as e:
                error_msg = f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                logging.error(error_msg, exc_info=True)
                st.sidebar.error(error_msg)
                continue

            # ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’æ±ºå®šï¼ˆç”»åƒãŒã‚ã‚Œã°5ã€ãªã‘ã‚Œã°4ï¼‰
            total_steps = 5 if doc_result['images'] else 4
            num_pages = doc_result.get('total_pages', '?')
            num_chunks = len(doc_result['text_chunks'])
            num_images = len(doc_result['images'])

            # 3. ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
            status_text.text(f"å‡¦ç†ä¸­: {uploaded_file.name} (3/{total_steps}) - ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¸­ï¼ˆ{num_chunks}ãƒãƒ£ãƒ³ã‚¯ï¼‰...")
            if doc_result['text_chunks']:
                # å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ã¾ã¨ã‚ã¦ãƒãƒƒãƒå‡¦ç†
                texts = [chunk['text'] for chunk in doc_result['text_chunks']]
                text_embeddings = st.session_state.embedder.embed_batch(texts)

                # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
                st.session_state.vector_store.add_text_chunks(
                    doc_result['text_chunks'],
                    text_embeddings
                )

            # 4. ç”»åƒã‚’Vision AIã§è§£æï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰- ç”»åƒãŒã‚ã‚‹å ´åˆã®ã¿
            analyzed_images = []
            failed_images = []

            if doc_result['images']:
                status_text.text(f"å‡¦ç†ä¸­: {uploaded_file.name} (4/{total_steps}) - ç”»åƒè§£æä¸­ï¼ˆ{num_images}æšï¼‰...")
                max_workers = st.session_state.config.get('performance', {}).get('max_workers', 4)

                # VisionAnalyzerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã«ä¿å­˜ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ï¼‰
                vision_analyzer = st.session_state.vision_analyzer

                # ç”»åƒè§£æã‚’ä¸¦åˆ—å‡¦ç†
                def analyze_single_image(image_data, analyzer):
                    try:
                        actual_content_type = image_data.get('content_type', 'image')
                        image_path = image_data['image_path']
                        logging.info(f"Starting analysis for {actual_content_type}: {image_path}")

                        analysis = analyzer.analyze_image(
                            image_path,
                            content_type=actual_content_type
                        )

                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
                        image_data.update({
                            'category': category,
                            'content_type': analysis.get('content_type', 'image'),
                            'description': analysis['description']
                        })

                        logging.info(f"Successfully analyzed {actual_content_type}: {image_path}")
                        return {'success': True, 'data': image_data}

                    except Exception as e:
                        error_msg = f"ç”»åƒè§£æå¤±æ•— ({image_data.get('image_path', 'unknown')}): {type(e).__name__}: {str(e)}"
                        logging.error(error_msg, exc_info=True)
                        return {
                            'success': False,
                            'data': image_data,
                            'error': str(e),
                            'error_type': type(e).__name__
                        }

                # ThreadPoolExecutorã§ä¸¦åˆ—å‡¦ç†
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    futures = {executor.submit(analyze_single_image, img, vision_analyzer): img for img in doc_result['images']}
                    for future in as_completed(futures):
                        result = future.result()
                        if result['success']:
                            analyzed_images.append(result['data'])
                        else:
                            failed_images.append(result)

                # è§£æçµæœã®é›†è¨ˆ
                success_count = len(analyzed_images)
                failed_count = len(failed_images)

                logging.info(f"Image analysis complete: {success_count} succeeded, {failed_count} failed")

                # å¤±æ•—ã—ãŸç”»åƒãŒã‚ã‚‹å ´åˆã€è­¦å‘Šã‚’è¡¨ç¤º
                if failed_images:
                    error_types = {}
                    for failure in failed_images:
                        error_type = failure.get('error_type', 'Unknown')
                        error_types[error_type] = error_types.get(error_type, 0) + 1

                    error_summary = ", ".join([f"{err_type}: {count}ä»¶" for err_type, count in error_types.items()])
                    warning_msg = f"âš ï¸ ç”»åƒè§£æã‚¨ãƒ©ãƒ¼: {failed_count}/{num_images}æšå¤±æ•— ({error_summary})"
                    st.sidebar.warning(warning_msg)
                    logging.warning(warning_msg)

                    # æœ€åˆã®ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
                    if failed_images:
                        first_error = failed_images[0]
                        logging.error(f"First error details: {first_error.get('error')}")

                # è§£æçµæœã‚’ãƒãƒƒãƒã§ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°
                if analyzed_images:
                    descriptions = [img['description'] for img in analyzed_images]
                    image_embeddings = st.session_state.embedder.embed_batch(descriptions)

                    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«ãƒãƒƒãƒã§è¿½åŠ 
                    st.session_state.vector_store.add_image_contents_batch(analyzed_images, image_embeddings)
                    logging.info(f"Added {len(analyzed_images)} images to vector store")

                    # Vision APIã§æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’text_chunksã¨ã—ã¦ã‚‚ä¿å­˜ï¼ˆæ¤œç´¢ç²¾åº¦å‘ä¸Šï¼‰
                    text_chunks_from_vision = []
                    for img in analyzed_images:
                        text_chunks_from_vision.append({
                            'text': img['description'],  # 'content'ã§ã¯ãªã'text'ã‚’ä½¿ç”¨
                            'page_number': img['page_number'],
                            'source_file': img['source_file'],
                            'category': img['category'],
                            'content_type': img.get('content_type', 'image')
                        })

                    if text_chunks_from_vision:
                        # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦ã‚‚ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
                        st.session_state.vector_store.add_text_chunks(text_chunks_from_vision, image_embeddings)
                        logging.info(f"Added {len(text_chunks_from_vision)} vision-extracted text chunks to vector store")
                else:
                    # å…¨ã¦ã®ç”»åƒè§£æãŒå¤±æ•—ã—ãŸå ´åˆ
                    error_msg = f"âŒ å…¨ã¦ã®ç”»åƒè§£æãŒå¤±æ•—ã—ã¾ã—ãŸ ({num_images}æš)"
                    st.sidebar.error(error_msg)
                    logging.error(error_msg)

            # PDFã‚’Supabase Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆSupabaseã®å ´åˆï¼‰
            storage_path = None
            if st.session_state.vector_store.provider == 'supabase':
                try:
                    storage_path = st.session_state.vector_store.upload_pdf_to_storage(
                        str(doc_path), uploaded_file.name, category
                    )
                    logging.info(f"Document uploaded to Supabase Storage: {storage_path}")
                except Exception as e:
                    logging.warning(f"Failed to upload PDF to Supabase Storage: {e}")
                    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—ã—ã¦ã‚‚ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚‹ã®ã§å‡¦ç†ç¶™ç¶š

            # PDFã‚’registered_pdfsãƒ†ãƒ¼ãƒ–ãƒ«ã«ç™»éŒ²ï¼ˆSupabaseã®å ´åˆï¼‰
            st.session_state.vector_store.register_pdf(uploaded_file.name, category, storage_path)

            # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
            completion_msg = f"âœ… {uploaded_file.name}: ãƒ†ã‚­ã‚¹ãƒˆ {len(doc_result['text_chunks'])}ä»¶"
            if doc_result['images']:
                if analyzed_images:
                    completion_msg += f", ç”»åƒ {len(analyzed_images)}/{num_images}ä»¶"
                else:
                    completion_msg += f", ç”»åƒ 0/{num_images}ä»¶ï¼ˆå…¨ã¦å¤±æ•—ï¼‰"
            status_text.text(completion_msg)
            progress_bar.progress((i + 1) / len(uploaded_files))

        except Exception as e:
            st.sidebar.error(f"ã‚¨ãƒ©ãƒ¼ ({uploaded_file.name}): {str(e)}")
            logging.error(f"Error processing {uploaded_file.name}: {e}", exc_info=True)
            continue

    status_text.success("âœ… ã™ã¹ã¦ã®PDFã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")


@st.dialog("PDFå‰Šé™¤ã®ç¢ºèª")
def confirm_delete_dialog():
    """PDFå‰Šé™¤ã®ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
    if 'delete_target' not in st.session_state:
        st.error("å‰Šé™¤å¯¾è±¡ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    target_file = st.session_state.delete_target
    pdf_info = st.session_state.pdf_manager.get_pdf_info(target_file)

    if pdf_info:
        st.warning(f"ä»¥ä¸‹ã®PDFã¨ãã®é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ")
        st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {pdf_info['source_file']}")
        st.write(f"**ã‚«ãƒ†ã‚´ãƒªãƒ¼**: {pdf_info['category']}")
        st.write(f"**å‰Šé™¤ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿**:")
        st.write(f"- ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {pdf_info['text_count']} ä»¶")
        st.write(f"- ç”»åƒãƒ‡ãƒ¼ã‚¿: {pdf_info['image_count']} ä»¶")
        st.write(f"- PDFãƒ•ã‚¡ã‚¤ãƒ«æœ¬ä½“")
        st.write(f"- æŠ½å‡ºã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… å‰Šé™¤ã™ã‚‹", type="primary", use_container_width=True):
                # å‰Šé™¤å®Ÿè¡Œ
                with st.spinner("å‰Šé™¤ä¸­..."):
                    result = st.session_state.pdf_manager.delete_pdf(target_file)

                if result['success']:
                    st.success(result['message'])
                    if result['category_deleted']:
                        st.info(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€Œ{pdf_info['category']}ã€ã‚‚å‰Šé™¤ã•ã‚Œã¾ã—ãŸï¼ˆä»–ã«PDFãŒãªã„ãŸã‚ï¼‰")

                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                    if 'delete_target' in st.session_state:
                        del st.session_state.delete_target
                    if 'show_delete_confirm' in st.session_state:
                        del st.session_state.show_delete_confirm

                    st.rerun()
                else:
                    st.error(result['message'])

        with col2:
            if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                if 'delete_target' in st.session_state:
                    del st.session_state.delete_target
                if 'show_delete_confirm' in st.session_state:
                    del st.session_state.show_delete_confirm
                st.rerun()
    else:
        st.error("PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def show_pdf_link(pdf_path: Path, target_file: str, key_suffix: str = ""):
    """PDFã‚’æ–°ã—ã„ã‚¿ãƒ–ã§é–‹ããƒªãƒ³ã‚¯ã‚’è¡¨ç¤ºï¼ˆSupabase Storageå¯¾å¿œï¼‰"""
    import os

    # Supabase Providerã§Storage URLãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
    if st.session_state.vector_store.provider == 'supabase':
        try:
            # Supabase Storageã‹ã‚‰PDFã®ç½²åä»˜ãURLã‚’å–å¾—
            pdf_url = st.session_state.vector_store.get_pdf_url_from_storage(target_file)

            if pdf_url:
                # ç½²åä»˜ãURLã‚’æ–°ã—ã„ã‚¿ãƒ–ã§é–‹ããƒªãƒ³ã‚¯ã¨ã—ã¦è¡¨ç¤º
                st.markdown(
                    f'<a href="{pdf_url}" target="_blank" rel="noopener noreferrer" style="'
                    f'display: inline-block; '
                    f'width: 100%; '
                    f'padding: 0.5rem 1rem; '
                    f'background-color: #ff4b4b; '
                    f'color: white; '
                    f'text-align: center; '
                    f'text-decoration: none; '
                    f'border-radius: 0.5rem; '
                    f'font-weight: 500; '
                    f'">ğŸ“– PDFã‚’é–‹ãï¼ˆæ–°ã—ã„ã‚¿ãƒ–ï¼‰</a>',
                    unsafe_allow_html=True
                )
                return
            else:
                logging.warning(f"No Supabase Storage URL found for {target_file}, falling back to local file")
        except Exception as e:
            logging.warning(f"Error getting PDF from Supabase Storage: {e}, falling back to local file")

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
    # Streamlit Cloudç’°å¢ƒã‚’æ¤œå‡º
    is_streamlit_cloud = (
        os.environ.get('STREAMLIT_RUNTIME_ENV') == 'cloud' or
        os.path.exists('/mount/src') or
        'STREAMLIT_SHARING_MODE' in os.environ
    )

    if is_streamlit_cloud:
        # Streamlit Cloudã§ã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
        if pdf_path.exists():
            with open(pdf_path, "rb") as pdf_file:
                pdf_bytes = pdf_file.read()
                st.download_button(
                    label="ğŸ“– PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=pdf_bytes,
                    file_name=target_file,
                    mime="application/pdf",
                    key=f"download_pdf_{key_suffix}_{target_file.replace('.', '_')}",
                    use_container_width=True
                )
        else:
            st.error(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target_file}")
    else:
        # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
        pdf_url = f"/app/static/pdfs/{target_file}"

        # æ–°ã—ã„ã‚¿ãƒ–ã§é–‹ããƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
        st.markdown(
            f'<a href="{pdf_url}" target="_blank" rel="noopener noreferrer" style="'
            f'display: inline-block; '
            f'width: 100%; '
            f'padding: 0.5rem 1rem; '
            f'background-color: #ff4b4b; '
            f'color: white; '
            f'text-align: center; '
            f'text-decoration: none; '
            f'border-radius: 0.5rem; '
            f'font-weight: 500; '
            f'">ğŸ“– PDFã‚’é–‹ãï¼ˆæ–°ã—ã„ã‚¿ãƒ–ï¼‰</a>',
            unsafe_allow_html=True
        )


def get_pdf_path_for_preview(source_file: str) -> Path:
    """
    PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®ãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆSupabase Storageã‹ã‚‰ä¸€æ™‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾å¿œï¼‰

    Args:
        source_file: PDFãƒ•ã‚¡ã‚¤ãƒ«å

    Returns:
        Path: PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    import tempfile
    import os

    pdf_path = Path("data/uploaded_pdfs") / source_file

    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
    if pdf_path.exists():
        return pdf_path

    # Supabase Storageã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’è©¦è¡Œ
    if st.session_state.vector_store.provider == 'supabase':
        try:
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            temp_dir = Path(tempfile.gettempdir()) / "pdf_preview_cache"
            temp_dir.mkdir(exist_ok=True)
            temp_pdf_path = temp_dir / source_file

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã™ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
            if temp_pdf_path.exists():
                return temp_pdf_path

            # Supabase Storageã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            success = st.session_state.vector_store.download_pdf_from_storage(
                source_file, str(temp_pdf_path)
            )

            if success:
                logging.info(f"Downloaded PDF from Supabase Storage for preview: {source_file}")
                return temp_pdf_path
            else:
                logging.warning(f"Failed to download PDF from Supabase Storage: {source_file}")
        except Exception as e:
            logging.error(f"Error downloading PDF from Supabase Storage: {e}")

    # ã©ã¡ã‚‰ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒ‘ã‚¹ã‚’è¿”ã™ï¼ˆå­˜åœ¨ã—ãªã„ãŒï¼‰
    return pdf_path


def main_area():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã®UI"""
    # å‰Šé™¤ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã®è¡¨ç¤º
    if st.session_state.get('show_delete_confirm', False):
        confirm_delete_dialog()

    st.title("ğŸ“š PDF RAG System")
    st.markdown("---")

    # ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰ï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰
    # ç™»éŒ²æ¸ˆã¿PDFãŒãªã„å ´åˆã¯è‡ªå‹•å±•é–‹
    registered_pdfs = st.session_state.pdf_manager.get_registered_pdfs()
    auto_expand = len(registered_pdfs) == 0

    with st.expander("ğŸ“– ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰", expanded=auto_expand):
        st.markdown("""
        ### åŸºæœ¬çš„ãªä½¿ã„æ–¹ã®æµã‚Œ

        ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è³ªå•ã«ç­”ãˆã‚‹RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

        #### **Step 1: PDFã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰** ğŸ“
        - å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒPDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã€ã‹ã‚‰ã€PDFæ–‡æ›¸ã‚’1ã¤ã¾ãŸã¯è¤‡æ•°é¸æŠã—ã¾ã™
        - æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 50MB/ãƒ•ã‚¡ã‚¤ãƒ«

        #### **Step 2: ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®è¨­å®š** ğŸ·ï¸
        - PDFã‚’åˆ†é¡ã™ã‚‹ãŸã‚ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼åã‚’å…¥åŠ›ã—ã¾ã™
        - ä¾‹: ã€Œè£½å“ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã€ã€ŒæŠ€è¡“ä»•æ§˜æ›¸ã€ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰ã€ãªã©
        - **åŒã˜ã‚«ãƒ†ã‚´ãƒªãƒ¼å**ã‚’ä½¿ã†ã“ã¨ã§ã€è¤‡æ•°ã®PDFã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã§ãã¾ã™

        #### **Step 3: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ** âš™ï¸
        - ã€ŒğŸ“‘ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™
        - ã‚·ã‚¹ãƒ†ãƒ ãŒPDFã‚’è§£æã—ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒãƒ»ã‚°ãƒ©ãƒ•ã‚’æŠ½å‡ºã—ã¾ã™
        - **å‡¦ç†æ™‚é–“ã®ç›®å®‰**: 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Š2-5ç§’ï¼ˆç”»åƒã®æ•°ã«ã‚ˆã‚Šå¤‰å‹•ï¼‰

        #### **Step 4: è³ªå•ã®å…¥åŠ›** ğŸ’¬
        - ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ŒğŸ” æ¤œç´¢å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€ã¨ã€ŒğŸ¤– AIãƒ¢ãƒ‡ãƒ«ã€ã‚’é¸æŠ
          - **æ¤œç´¢å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªãƒ¼**: ã€Œå…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€ã¾ãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¯„å›²ã‚’æŒ‡å®š
          - **GPT-4.1**: æœ€æ–°ã®OpenAIãƒ¢ãƒ‡ãƒ«ã€é«˜åº¦ãªæ¨è«–èƒ½åŠ›ã¨å®‰å®šã—ãŸå¿œç­”å“è³ª
          - **Gemini-2.5-Pro**: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã«å¼·ãã€ç”»åƒãƒ»ã‚°ãƒ©ãƒ•ãƒ»è¤‡é›‘ãªæ–‡æ›¸ã®ç†è§£ã«å„ªã‚Œã‚‹
        - æœ€ä¸‹éƒ¨ã®å…¥åŠ›æ¬„ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦Enterã‚­ãƒ¼ã¾ãŸã¯é€ä¿¡ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯

        #### **Step 5: å›ç­”ã®ç¢ºèª** âœ…
        - AIãŒé–¢é€£æƒ…å ±ã‚’å…ƒã«å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™
        - å„å›ç­”ã®ä¸‹ã«**å‚ç…§å…ƒPDFãƒ•ã‚¡ã‚¤ãƒ«**ãŒæŠ˜ã‚ŠãŸãŸã¾ã‚Œã¦è¡¨ç¤ºã•ã‚Œã¾ã™
        - å‚ç…§å…ƒã‚’å±•é–‹ã™ã‚‹ã¨ã€PDFãƒ•ã‚¡ã‚¤ãƒ«åã¨å‚ç…§ã—ãŸãƒšãƒ¼ã‚¸ç•ªå·ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
        - **ğŸ“– PDFã‚’é–‹ã**ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€ãƒ–ãƒ©ã‚¦ã‚¶ã®æ–°ã—ã„ã‚¿ãƒ–ã§PDFãŒé–‹ãã¾ã™

        ---

        ### ğŸ’¡ ä½¿ã„æ–¹ã®ã‚³ãƒ„

        - **ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†ã‘ã®æ¨å¥¨**: è£½å“ã”ã¨ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã«ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’åˆ†ã‘ã‚‹ã¨æ¤œç´¢ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™
        - **å…·ä½“çš„ãªè³ªå•**: ã€Œã€‡ã€‡ã®ä»•æ§˜ã¯ï¼Ÿã€ã€Œâ–³â–³ã®æ‰‹é †ã‚’æ•™ãˆã¦ã€ãªã©å…·ä½“çš„ã«è³ªå•ã™ã‚‹ã¨è‰¯ã„çµæœãŒå¾—ã‚‰ã‚Œã¾ã™
        - **ä¼šè©±ãƒ¡ãƒ¢ãƒªæ©Ÿèƒ½**: å‰ã®è³ªå•ã‚’è¸ã¾ãˆãŸè¿½åŠ è³ªå•ãŒå¯èƒ½ã§ã™ã€‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã®å…¨ã¦ã®ä¼šè©±å±¥æ­´ã‚’è¨˜æ†¶ã—ã¦å›ç­”ã—ã¾ã™

        ---

        ### âš ï¸ æ³¨æ„äº‹é …

        - **ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–**: Streamlit Cloudã§ã¯ã€ã‚¢ãƒ—ãƒªå†èµ·å‹•æ™‚ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã¯æ¶ˆå»ã•ã‚Œã¾ã™
        - **APIåˆ¶é™**: OpenAI/Gemini APIã®åˆ©ç”¨åˆ¶é™ã«ã”æ³¨æ„ãã ã•ã„
        - **ç”»åƒè§£æ**: GEMINI_API_KEYãŒæœªè¨­å®šã®å ´åˆã€ç”»åƒè§£ææ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™
        """)

    st.markdown("---")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
    for idx, chat in enumerate(st.session_state.chat_history):
        with st.chat_message(chat["role"]):
            st.markdown(chat["content"])

            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å›ç­”ã®å ´åˆã€å‚ç…§å…ƒã‚’è¡¨ç¤º
            if chat["role"] == "assistant" and "sources" in chat and chat["sources"]:
                sources = chat["sources"]
                # sourcesã¯è¾æ›¸å½¢å¼ {"text": [...], "images": [...]}
                text_sources = sources.get("text", [])
                image_sources = sources.get("images", [])
                total_sources = len(text_sources) + len(image_sources)

                if total_sources > 0:
                    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å‚ç…§æƒ…å ±ã‚’é›†ç´„
                    pdf_references = {}

                    # ãƒ†ã‚­ã‚¹ãƒˆå‚ç…§å…ƒã‚’é›†ç´„
                    for result in text_sources:
                        metadata = result.get("metadata", {})
                        source_file = metadata.get('source_file', 'Unknown')
                        page_number = metadata.get('page_number', 'Unknown')
                        category = metadata.get('category', 'Unknown')

                        if source_file not in pdf_references:
                            pdf_references[source_file] = {
                                'category': category,
                                'pages': set()
                            }
                        pdf_references[source_file]['pages'].add(page_number)

                    # ç”»åƒå‚ç…§å…ƒã‚’é›†ç´„
                    for result in image_sources:
                        metadata = result.get("metadata", {})
                        source_file = metadata.get('source_file', 'Unknown')
                        page_number = metadata.get('page_number', 'Unknown')
                        category = metadata.get('category', 'Unknown')

                        if source_file not in pdf_references:
                            pdf_references[source_file] = {
                                'category': category,
                                'pages': set()
                            }
                        pdf_references[source_file]['pages'].add(page_number)

                    # ğŸ“¸ å‚ç…§ãƒšãƒ¼ã‚¸ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä¸Šä½3-5ãƒšãƒ¼ã‚¸ï¼‰
                    top_pages = st.session_state.rag_engine.get_top_reference_pages(
                        sources,
                        top_n=5
                    )

                    if top_pages:
                        with st.expander(f"ğŸ“¸ å‚ç…§ãƒšãƒ¼ã‚¸ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ({len(top_pages)}ãƒšãƒ¼ã‚¸)", expanded=True):
                            st.caption("é–¢é€£åº¦ã®é«˜ã„é †ã«è¡¨ç¤ºã—ã¦ã„ã¾ã™ï¼ˆæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºï¼‰")

                            # å¯¾å¿œã™ã‚‹è³ªå•ã‚’å–å¾—ï¼ˆå±¥æ­´ã‹ã‚‰ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
                            user_query = ""
                            if idx > 0 and st.session_state.chat_history[idx - 1]["role"] == "user":
                                user_query = st.session_state.chat_history[idx - 1]["content"]

                            # ãƒšãƒ¼ã‚¸ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆPDFãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ï¼‰
                            pages_by_pdf = {}
                            for page_info in top_pages:
                                source_file = page_info['source_file']
                                if source_file not in pages_by_pdf:
                                    pages_by_pdf[source_file] = []
                                pages_by_pdf[source_file].append(page_info)

                            # PDFãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«1ãƒšãƒ¼ã‚¸ãšã¤è¡¨ç¤º
                            for source_file, pages in pages_by_pdf.items():
                                st.markdown(f"**ğŸ“„ {source_file}**")

                                if STREAMLIT_PDF_VIEWER_AVAILABLE:
                                    # pdf_viewerã‚’ä½¿ç”¨ã—ã¦å„ãƒšãƒ¼ã‚¸ã‚’å€‹åˆ¥ã«è¡¨ç¤º
                                    try:
                                        # PDFãƒ‘ã‚¹ã‚’å–å¾—
                                        pdf_path = get_pdf_path(source_file, st.session_state.vector_store)

                                        if pdf_path and pdf_path.exists():
                                            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆLLMä½¿ç”¨ï¼‰
                                            from src.pdf_page_renderer import extract_keywords_llm
                                            keywords = extract_keywords_llm(user_query, st.session_state.rag_engine)

                                            # æœ€å¤§3åˆ—ã§ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºï¼ˆã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç¶­æŒï¼‰
                                            cols_per_row = min(3, len(pages))
                                            for i in range(0, len(pages), cols_per_row):
                                                cols = st.columns(cols_per_row)
                                                for col_idx, page_info in enumerate(pages[i:i + cols_per_row]):
                                                    page_num = page_info['page_number']
                                                    score = page_info.get('score')

                                                    with cols[col_idx]:
                                                        # è©²å½“ãƒšãƒ¼ã‚¸ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿ç”Ÿæˆ
                                                        annotations = create_pdf_annotations_pymupdf(
                                                            pdf_path=pdf_path,
                                                            search_terms=keywords,
                                                            page_numbers=[page_num]  # 1ãƒšãƒ¼ã‚¸ã®ã¿
                                                        )

                                                        # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ä½œæˆ
                                                        caption = f"ãƒšãƒ¼ã‚¸ {page_num}"
                                                        if score is not None:
                                                            caption += f" (é–¢é€£åº¦: {score:.3f})"
                                                        st.markdown(f"**{caption}**")

                                                        # PDFãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ã§1ãƒšãƒ¼ã‚¸ã®ã¿è¡¨ç¤º
                                                        logger.info(f"ğŸ“„ [HISTORY] Displaying page {page_num} with {len(annotations)} annotations")
                                                        pdf_viewer(
                                                            str(pdf_path),
                                                            annotations=annotations,
                                                            pages_to_render=[page_num],  # è©²å½“ãƒšãƒ¼ã‚¸ã®ã¿
                                                            width=350,
                                                            height=500,
                                                            render_text=True
                                                        )

                                                        # å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                                                        with st.expander("ğŸ“ å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                                                            st.text(page_info.get('content_preview', ''))
                                        else:
                                            st.error(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_file}")

                                    except Exception as e:
                                        logger.error(f"PDF display error: {e}", exc_info=True)
                                        st.error(f"PDFã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

                                else:
                                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç”»åƒãƒ™ãƒ¼ã‚¹ã®è¡¨ç¤º
                                    st.warning("streamlit-pdf-viewerãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç”»åƒè¡¨ç¤ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")

                                    # æœ€å¤§3åˆ—ã§ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
                                    cols_per_row = min(3, len(pages))
                                    for i in range(0, len(pages), cols_per_row):
                                        cols = st.columns(cols_per_row)
                                        for col_idx, page_info in enumerate(pages[i:i + cols_per_row]):
                                            page_num = page_info['page_number']
                                            score = page_info.get('score')

                                            with cols[col_idx]:
                                                # ãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãç”»åƒã‚’å–å¾—
                                                logger.info(f"ğŸ“¸ [HISTORY] About to call extract_page_with_highlight: {source_file} page {page_num}")
                                                image = extract_page_with_highlight(
                                                    source_file=source_file,
                                                    page_number=page_num,
                                                    query=user_query,
                                                    _vector_store=st.session_state.vector_store,
                                                    _rag_engine=st.session_state.rag_engine,
                                                    _vision_analyzer=st.session_state.vision_analyzer,
                                                    dpi=150,
                                                    target_width=1000
                                                )
                                                logger.info(f"ğŸ“¸ [HISTORY] extract_page_with_highlight returned: {type(image).__name__ if image else 'None'}")

                                                if image:
                                                    # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ä½œæˆ
                                                    caption = f"ãƒšãƒ¼ã‚¸ {page_num}"
                                                    if score is not None:
                                                        caption += f" (é–¢é€£åº¦: {score:.3f})"

                                                    st.image(image, caption=caption, use_container_width=True)

                                                    # å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                                                with st.expander("ğŸ“ å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                                                    st.text(page_info.get('content_preview', ''))
                                            else:
                                                st.warning(f"ãƒšãƒ¼ã‚¸ {page_num} ã®ç”»åƒã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

                                st.markdown("---")

                    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«è¡¨ç¤º
                    with st.expander(f"ğŸ“„ å‚ç…§å…ƒPDFãƒ•ã‚¡ã‚¤ãƒ« ({len(pdf_references)}ä»¶)"):
                        for pdf_idx, (source_file, info) in enumerate(pdf_references.items(), 1):
                            pages_list = sorted(list(info['pages']))
                            pages_str = ', '.join(map(str, pages_list))

                            st.markdown(f"**{pdf_idx}. {source_file}**")
                            st.write(f"ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªãƒ¼: {info['category']}")
                            st.write(f"ğŸ“„ å‚ç…§ãƒšãƒ¼ã‚¸: {pages_str}")

                            # PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                            pdf_path = Path("data/uploaded_pdfs") / source_file
                            show_pdf_link(pdf_path, source_file, key_suffix=f"hist_{idx}_pdf_{pdf_idx}")

                            if pdf_idx < len(pdf_references):
                                st.markdown("---")

    # æ¨™æº–ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    question = st.chat_input("ğŸ’¬ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: ã“ã®è£½å“ã®ä¸»ãªç‰¹å¾´ã¯ä½•ã§ã™ã‹ï¼Ÿï¼‰")

    # è³ªå•ãŒé€ä¿¡ã•ã‚ŒãŸå ´åˆ
    if question:
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
        category_filter = None if st.session_state.selected_category == "å…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼" else st.session_state.selected_category

        # ãƒ¢ãƒ‡ãƒ«è¡¨ç¤ºåã‚’å–å¾—
        model_display_names = {
            "openai": "GPT-4.1",
            "gemini": "Gemini-2.5-Pro"
        }
        current_model_display = model_display_names.get(st.session_state.selected_model, "GPT-4.1")

        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¡¨ç¤º
            with st.chat_message("user"):
                st.markdown(question)

            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¿½åŠ 
            st.session_state.chat_history.append({
                "role": "user",
                "content": question
            })

            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å›ç­”ã‚’è¡¨ç¤º
            with st.chat_message("assistant"):
                answer_placeholder = st.empty()
                full_answer = ""
                result_data = None
                context_data = None

                try:
                    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
                    # æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é™¤ã„ãŸå±¥æ­´ã‚’æ¸¡ã™ï¼ˆç¾åœ¨ã®è³ªå•ã¯å«ã‚ãªã„ï¼‰
                    chat_history_for_query = [msg for msg in st.session_state.chat_history[:-1]]

                    for chunk_data in st.session_state.rag_engine.query_stream(
                        question,
                        category_filter,
                        model_type=st.session_state.selected_model,
                        chat_history=chat_history_for_query
                    ):
                        if chunk_data["type"] == "context":
                            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ä¿å­˜
                            context_data = chunk_data
                            logger.info(f"[DEBUG] Context data received: sources={len(chunk_data.get('sources', {}).get('text', []))} text, {len(chunk_data.get('sources', {}).get('images', []))} images")
                        elif chunk_data["type"] == "chunk":
                            full_answer += chunk_data["content"]
                            answer_placeholder.markdown(full_answer + "â–Œ")  # ã‚«ãƒ¼ã‚½ãƒ«è¡¨ç¤º

                    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†å¾Œã€æœ€çµ‚çš„ãªå›ç­”ã‚’è¡¨ç¤º
                    answer_placeholder.markdown(full_answer)

                    # çµæœãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
                    if context_data:
                        result_data = {
                            "answer": full_answer,
                            "sources": context_data.get("sources", {}),
                            "context": context_data.get("context", ""),
                            "images": context_data.get("images", [])
                        }
                        logger.info(f"[DEBUG] result_data constructed: sources={len(result_data.get('sources', {}).get('text', []))} text, {len(result_data.get('sources', {}).get('images', []))} images")
                    else:
                        logger.warning("[DEBUG] context_data is None - result_data remains None")

                except Exception as stream_error:
                    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼æ™‚ã¯é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    if "stream" in str(stream_error).lower() or "unsupported_value" in str(stream_error).lower():
                        st.warning("âš ï¸ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™...")
                        answer_placeholder.empty()
                        with st.spinner(f"å›ç­”ã‚’ç”Ÿæˆä¸­... ({current_model_display})"):
                            chat_history_for_query = [msg for msg in st.session_state.chat_history[:-1]]

                            result_data = st.session_state.rag_engine.query(
                                question,
                                category_filter,
                                model_type=st.session_state.selected_model,
                                chat_history=chat_history_for_query
                            )
                        answer_placeholder.markdown(result_data['answer'])
                    else:
                        raise stream_error

                # å‚ç…§å…ƒã‚’æŠ˜ã‚ŠãŸãŸã¿è¡¨ç¤º
                if result_data and result_data.get('sources'):
                    sources = result_data['sources']
                    # sourcesã¯è¾æ›¸å½¢å¼ {"text": [...], "images": [...]}
                    text_sources = sources.get("text", [])
                    image_sources = sources.get("images", [])
                    total_sources = len(text_sources) + len(image_sources)

                    if total_sources > 0:
                        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å‚ç…§æƒ…å ±ã‚’é›†ç´„
                        pdf_references = {}

                        # ãƒ†ã‚­ã‚¹ãƒˆå‚ç…§å…ƒã‚’é›†ç´„
                        for result in text_sources:
                            metadata = result.get("metadata", {})
                            source_file = metadata.get('source_file', 'Unknown')
                            page_number = metadata.get('page_number', 'Unknown')
                            category = metadata.get('category', 'Unknown')

                            if source_file not in pdf_references:
                                pdf_references[source_file] = {
                                    'category': category,
                                    'pages': set()
                                }
                            pdf_references[source_file]['pages'].add(page_number)

                        # ç”»åƒå‚ç…§å…ƒã‚’é›†ç´„
                        for result in image_sources:
                            metadata = result.get("metadata", {})
                            source_file = metadata.get('source_file', 'Unknown')
                            page_number = metadata.get('page_number', 'Unknown')
                            category = metadata.get('category', 'Unknown')

                            if source_file not in pdf_references:
                                pdf_references[source_file] = {
                                    'category': category,
                                    'pages': set()
                                }
                            pdf_references[source_file]['pages'].add(page_number)

                        # ğŸ“¸ å‚ç…§ãƒšãƒ¼ã‚¸ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä¸Šä½3-5ãƒšãƒ¼ã‚¸ï¼‰
                        logger.info(f"[DEBUG] Checking page preview condition: result_data={result_data is not None}, has_sources={result_data.get('sources') if result_data else None}")
                        if result_data and result_data.get('sources'):
                            logger.info(f"[DEBUG] Calling get_top_reference_pages with sources")
                            top_pages = st.session_state.rag_engine.get_top_reference_pages(
                                result_data['sources'],
                                top_n=5
                            )
                            logger.info(f"[DEBUG] get_top_reference_pages returned {len(top_pages)} pages")
                        else:
                            logger.warning("[DEBUG] Skipping page preview - result_data or sources missing")
                            top_pages = []

                        if top_pages:
                            with st.expander(f"ğŸ“¸ å‚ç…§ãƒšãƒ¼ã‚¸ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ({len(top_pages)}ãƒšãƒ¼ã‚¸)", expanded=True):
                                st.caption("é–¢é€£åº¦ã®é«˜ã„é †ã«è¡¨ç¤ºã—ã¦ã„ã¾ã™ï¼ˆæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºï¼‰")

                                # ãƒšãƒ¼ã‚¸ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆPDFãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ï¼‰
                                pages_by_pdf = {}
                                for page_info in top_pages:
                                    source_file = page_info['source_file']
                                    if source_file not in pages_by_pdf:
                                        pages_by_pdf[source_file] = []
                                    pages_by_pdf[source_file].append(page_info)

                                # PDFãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«1ãƒšãƒ¼ã‚¸ãšã¤è¡¨ç¤º
                                for source_file, pages in pages_by_pdf.items():
                                    st.markdown(f"**ğŸ“„ {source_file}**")

                                    if STREAMLIT_PDF_VIEWER_AVAILABLE:
                                        # pdf_viewerã‚’ä½¿ç”¨ã—ã¦å„ãƒšãƒ¼ã‚¸ã‚’å€‹åˆ¥ã«è¡¨ç¤º
                                        try:
                                            # PDFãƒ‘ã‚¹ã‚’å–å¾—
                                            pdf_path = get_pdf_path(source_file, st.session_state.vector_store)

                                            if pdf_path and pdf_path.exists():
                                                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆLLMä½¿ç”¨ï¼‰
                                                from src.pdf_page_renderer import extract_keywords_llm
                                                keywords = extract_keywords_llm(question, st.session_state.rag_engine)

                                                # æœ€å¤§3åˆ—ã§ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºï¼ˆã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç¶­æŒï¼‰
                                                cols_per_row = min(3, len(pages))
                                                for i in range(0, len(pages), cols_per_row):
                                                    cols = st.columns(cols_per_row)
                                                    for col_idx, page_info in enumerate(pages[i:i + cols_per_row]):
                                                        page_num = page_info['page_number']
                                                        score = page_info.get('score')

                                                        with cols[col_idx]:
                                                            # è©²å½“ãƒšãƒ¼ã‚¸ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿ç”Ÿæˆ
                                                            annotations = create_pdf_annotations_pymupdf(
                                                                pdf_path=pdf_path,
                                                                search_terms=keywords,
                                                                page_numbers=[page_num]  # 1ãƒšãƒ¼ã‚¸ã®ã¿
                                                            )

                                                            # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ä½œæˆ
                                                            caption = f"ãƒšãƒ¼ã‚¸ {page_num}"
                                                            if score is not None:
                                                                caption += f" (é–¢é€£åº¦: {score:.3f})"
                                                            st.markdown(f"**{caption}**")

                                                            # PDFãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ã§1ãƒšãƒ¼ã‚¸ã®ã¿è¡¨ç¤º
                                                            logger.info(f"ğŸ“„ [NEW ANSWER] Displaying page {page_num} with {len(annotations)} annotations")
                                                            pdf_viewer(
                                                                str(pdf_path),
                                                                annotations=annotations,
                                                                pages_to_render=[page_num],  # è©²å½“ãƒšãƒ¼ã‚¸ã®ã¿
                                                                width=350,
                                                                height=500,
                                                                render_text=True
                                                            )

                                                            # å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                                                            with st.expander("ğŸ“ å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                                                                st.text(page_info.get('content_preview', ''))
                                            else:
                                                st.error(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_file}")

                                        except Exception as e:
                                            logger.error(f"PDF display error: {e}", exc_info=True)
                                            st.error(f"PDFã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

                                    else:
                                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç”»åƒãƒ™ãƒ¼ã‚¹ã®è¡¨ç¤º
                                        st.warning("streamlit-pdf-viewerãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç”»åƒè¡¨ç¤ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")

                                        # æœ€å¤§3åˆ—ã§ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
                                        cols_per_row = min(3, len(pages))
                                        for i in range(0, len(pages), cols_per_row):
                                            cols = st.columns(cols_per_row)
                                            for col_idx, page_info in enumerate(pages[i:i + cols_per_row]):
                                                page_num = page_info['page_number']
                                                score = page_info.get('score')

                                                with cols[col_idx]:
                                                    # ãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãç”»åƒã‚’å–å¾—
                                                    logger.info(f"ğŸ“¸ [NEW ANSWER] About to call extract_page_with_highlight: {source_file} page {page_num}")
                                                    image = extract_page_with_highlight(
                                                        source_file=source_file,
                                                        page_number=page_num,
                                                        query=question,  # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
                                                        _vector_store=st.session_state.vector_store,
                                                        _rag_engine=st.session_state.rag_engine,
                                                        _vision_analyzer=st.session_state.vision_analyzer,
                                                        dpi=150,
                                                        target_width=1000
                                                    )
                                                    logger.info(f"ğŸ“¸ [NEW ANSWER] extract_page_with_highlight returned: {type(image).__name__ if image else 'None'}")

                                                    if image:
                                                        # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ä½œæˆ
                                                        caption = f"ãƒšãƒ¼ã‚¸ {page_num}"
                                                        if score is not None:
                                                            caption += f" (é–¢é€£åº¦: {score:.3f})"

                                                        st.image(image, caption=caption, use_container_width=True)

                                                        # å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                                                        with st.expander("ğŸ“ å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                                                            st.text(page_info.get('content_preview', ''))
                                                    else:
                                                        st.warning(f"ãƒšãƒ¼ã‚¸ {page_num} ã®ç”»åƒã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

                                    st.markdown("---")

                        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«è¡¨ç¤º
                        with st.expander(f"ğŸ“„ å‚ç…§å…ƒPDFãƒ•ã‚¡ã‚¤ãƒ« ({len(pdf_references)}ä»¶)"):
                            for pdf_idx, (source_file, info) in enumerate(pdf_references.items(), 1):
                                pages_list = sorted(list(info['pages']))
                                pages_str = ', '.join(map(str, pages_list))

                                st.markdown(f"**{pdf_idx}. {source_file}**")
                                st.write(f"ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªãƒ¼: {info['category']}")
                                st.write(f"ğŸ“„ å‚ç…§ãƒšãƒ¼ã‚¸: {pages_str}")

                                # PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                                pdf_path = Path("data/uploaded_pdfs") / source_file
                                show_pdf_link(pdf_path, source_file, key_suffix=f"new_pdf_{pdf_idx}")

                                if pdf_idx < len(pdf_references):
                                    st.markdown("---")

            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å›ç­”ã‚’è¿½åŠ ï¼ˆå‚ç…§å…ƒã‚‚å«ã‚€ï¼‰
            if result_data:
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": result_data['answer'],
                    "sources": result_data.get('sources', [])
                })

                # å†æç”»ã—ã¦å±¥æ­´ã‚’æ›´æ–°
                st.rerun()
            else:
                st.error("å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å±¥æ­´ã‹ã‚‰å‰Šé™¤
                st.session_state.chat_history.pop()

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            logging.error(f"Error during query: {e}", exc_info=True)
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å±¥æ­´ã‹ã‚‰å‰Šé™¤
            if st.session_state.chat_history and st.session_state.chat_history[-1]["role"] == "user":
                st.session_state.chat_history.pop()


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    # åˆæœŸåŒ–
    config = initialize_app()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    sidebar()

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    main_area()

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.caption("PDF RAG System v0.1.0 - PoC")


if __name__ == "__main__":
    main()
