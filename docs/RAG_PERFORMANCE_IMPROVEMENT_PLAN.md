# RAGæ€§èƒ½å‘ä¸Šè¨ˆç”»

**ä½œæˆæ—¥**: 2025-11-04
**å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ **: PDF RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆPoC_chatbotï¼‰
**å„ªå…ˆãƒ•ã‚§ãƒ¼ã‚º**: Phase 1 - Quick Winsï¼ˆ1é€±é–“ï¼‰
**æ”¹å–„ç›®æ¨™**: æ¤œç´¢ç²¾åº¦å‘ä¸Š + å¿œç­”é€Ÿåº¦æ”¹å–„

---

## ğŸ“Š ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€æ—¢å­˜ã®PDF RAGã‚·ã‚¹ãƒ†ãƒ ã®è©³ç´°åˆ†æã«åŸºã¥ãã€çŸ­æœŸé–“ï¼ˆ1é€±é–“ï¼‰ã§å®Ÿç¾å¯èƒ½ãªæ€§èƒ½å‘ä¸Šæ–½ç­–ã‚’ææ¡ˆã—ã¾ã™ã€‚

### æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ
- **æ¤œç´¢ç²¾åº¦**: 10-15%å‘ä¸Šï¼ˆNDCG@5: 0.85 â†’ 0.92ï¼‰
- **å¿œç­”é€Ÿåº¦**: 30-50%æ”¹å–„ï¼ˆæ¤œç´¢ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 200-500ms â†’ 100-300msï¼‰
- **ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“**: ã‚ˆã‚Šé–¢é€£æ€§ã®é«˜ã„å›ç­”ã€é«˜é€Ÿãªãƒ¬ã‚¹ãƒãƒ³ã‚¹

---

## ğŸ¯ ç¾çŠ¶åˆ†æ

### ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:
```
PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    â†“
PDFå‡¦ç†ï¼ˆä¸¦åˆ—åŒ–: æœ€å¤§4ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰
    â”œâ”€ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º â†’ ãƒãƒ£ãƒ³ã‚¯åŒ– â†’ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°
    â””â”€ ç”»åƒ/è¡¨/ã‚°ãƒ©ãƒ•æŠ½å‡º â†’ Vision AIè§£æ â†’ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°
    â†“
ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ï¼ˆSupabase pgvector / ChromaDBï¼‰
    â†“
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª â†’ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚° â†’ ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
    â†“
ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰ â†’ LLMï¼ˆGPT-4o/Geminiï¼‰ â†’ å›ç­”ç”Ÿæˆ
```

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯**:
- UI: Streamlit
- RAGãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: LangChain
- AI/LLM: OpenAI (GPT-4o, text-embedding-3-large), Google Gemini (gemini-2.5-pro)
- ãƒ™ã‚¯ãƒˆãƒ«DB: Supabase (pgvector) / ChromaDB
- PDFå‡¦ç†: pdfplumber
- å¯è¦³æ¸¬æ€§: Langfuse

### æ—¢å­˜ã®å¼·ã¿

âœ… **å®Ÿè£…æ¸ˆã¿ã®æœ€é©åŒ–**:
- ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒãƒƒãƒå‡¦ç†ï¼ˆ100ä»¶/ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
- PDFå‡¦ç†ã®ä¸¦åˆ—åŒ–ï¼ˆThreadPoolExecutorï¼‰
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œï¼ˆãƒ†ã‚­ã‚¹ãƒˆ + ç”»åƒ + è¡¨ + ã‚°ãƒ©ãƒ•ï¼‰
- Supabaseçµ±åˆã«ã‚ˆã‚‹æ°¸ç¶šåŒ–
- ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½
- Langfuseã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°

### ç‰¹å®šã•ã‚ŒãŸèª²é¡Œ

âš ï¸ **æ”¹å–„ãŒå¿…è¦ãªé ˜åŸŸ**:

1. **æ¤œç´¢ç²¾åº¦ã®é™ç•Œ**
   - å˜ç´”ãªãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ã¿ï¼ˆã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰
   - Rerankingãªã— â†’ ç²¾åº¦10-15%ã®æå¤±
   - å›ºå®šã®é¡ä¼¼åº¦é–¾å€¤ï¼ˆ0.5ï¼‰

2. **ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã®éæœ€é©æ€§**
   - å›ºå®šã‚µã‚¤ã‚ºãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ï¼ˆ800ãƒˆãƒ¼ã‚¯ãƒ³ã€150ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼‰
   - ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯å¢ƒç•Œã‚’ç„¡è¦– â†’ æ–‡è„ˆã®åˆ†æ–­

3. **ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã®ä¸è¶³**
   - ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã®é‡è¤‡
   - Visionè§£æçµæœã®å†åˆ©ç”¨ãªã—
   - APIã‚³ã‚¹ãƒˆã¨å¿œç­”æ™‚é–“ã®å¢—åŠ 

4. **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®æœªå®Ÿè£…**
   - ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ã¿ â†’ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒã®å¼±ã•
   - BM25ã¨ã®çµ„ã¿åˆã‚ã›ã§ç²¾åº¦å‘ä¸Šã®ä½™åœ°

---

## ğŸš€ Phase 1: Quick Winsï¼ˆ1é€±é–“å®Ÿè£…è¨ˆç”»ï¼‰

### ç›®æ¨™

| æŒ‡æ¨™ | ç¾çŠ¶ | ç›®æ¨™ | æ”¹å–„ç‡ |
|------|------|------|--------|
| æ¤œç´¢ç²¾åº¦ï¼ˆNDCG@5ï¼‰ | 0.85 | 0.92 | +8% |
| æ¤œç´¢ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | 200-500ms | 100-300ms | -50% |
| ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ | 0% | 60-70% | - |

---

### å®Ÿè£…ã‚¿ã‚¹ã‚¯

#### 1ï¸âƒ£ Rerankingå°å…¥ï¼ˆå„ªå…ˆåº¦: ğŸ”´ æœ€é«˜ï¼‰

**ç›®çš„**: æ¤œç´¢ç²¾åº¦ã‚’10-15%å‘ä¸Š

**å®Ÿè£…æ–¹æ³•**:
```python
# æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«: backend/src/reranker.py

from sentence_transformers import CrossEncoder
from typing import List, Tuple
import numpy as np

class Reranker:
    def __init__(self, model_name: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2'):
        """
        è»½é‡ã§ã‚ã‚ŠãªãŒã‚‰é«˜ç²¾åº¦ãªCross-Encoderãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: ~80MB
        æ¨è«–é€Ÿåº¦: ~50ms/queryï¼ˆTop-10ã‚’rerankï¼‰
        """
        self.model = CrossEncoder(model_name)

    def rerank(
        self,
        query: str,
        documents: List[str],
        top_k: int = 5
    ) -> List[Tuple[int, float]]:
        """
        ã‚¯ã‚¨ãƒªã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒšã‚¢ã‚’rerankã—ã€
        ã‚¹ã‚³ã‚¢ã®é«˜ã„é †ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã‚¹ã‚³ã‚¢ã‚’è¿”ã™
        """
        # ã‚¯ã‚¨ãƒª-ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒšã‚¢ã‚’ä½œæˆ
        pairs = [[query, doc] for doc in documents]

        # rerankã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        scores = self.model.predict(pairs)

        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        ranked_indices = np.argsort(scores)[::-1][:top_k]
        ranked_scores = scores[ranked_indices]

        return list(zip(ranked_indices.tolist(), ranked_scores.tolist()))
```

**çµ±åˆãƒã‚¤ãƒ³ãƒˆ** (`backend/src/rag_engine.py`):
```python
# RAGEngine._get_relevant_contexts()ãƒ¡ã‚½ãƒƒãƒ‰ã«è¿½åŠ 

# 1æ¬¡æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰ã§Top-10ã‚’å–å¾—
text_results = self.vector_store.similarity_search(
    query_embedding,
    k=10,  # rerankingã®ãŸã‚å¤šã‚ã«å–å¾—
    filter={"category": category} if category else None
)

# Rerankingã‚’é©ç”¨
reranker = Reranker()
documents = [r.page_content for r in text_results]
reranked_indices, scores = reranker.rerank(query, documents, top_k=5)

# ä¸Šä½5ä»¶ã‚’æœ€çµ‚çµæœã¨ã—ã¦ä½¿ç”¨
final_results = [text_results[idx] for idx in reranked_indices]
```

**ä¾å­˜é–¢ä¿‚**:
```bash
pip install sentence-transformers
```

**æ¨å®šåŠ¹æœ**:
- ç²¾åº¦å‘ä¸Š: +10-15%
- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å¢—åŠ : +50-100msï¼ˆè¨±å®¹ç¯„å›²å†…ï¼‰
- è¿½åŠ ã‚³ã‚¹ãƒˆ: ãªã—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æ¨è«–ï¼‰

---

#### 2ï¸âƒ£ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå„ªå…ˆåº¦: ğŸŸ  é«˜ï¼‰

**ç›®çš„**: æ–‡è„ˆã‚’ä¿æŒã—ãŸãƒãƒ£ãƒ³ã‚¯åŒ–ã§å›ç­”å“è³ªå‘ä¸Š

**å®Ÿè£…æ–¹æ³•**:
```python
# ä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«: backend/src/pdf_processor.py

from langchain.text_splitter import RecursiveCharacterTextSplitter

class PDFProcessor:
    def __init__(self, config):
        # ...æ—¢å­˜ã‚³ãƒ¼ãƒ‰...

        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚«ãƒ¼ã‚’åˆæœŸåŒ–
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=150,
            length_function=self._count_tokens,
            # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯å¢ƒç•Œã‚’å„ªå…ˆ
            separators=[
                "\n\n",      # æ®µè½åŒºåˆ‡ã‚Š
                "\n",        # æ”¹è¡Œ
                "ã€‚",        # æ—¥æœ¬èªæ–‡æœ«
                "ï¼",        # æ—¥æœ¬èªæ–‡æœ«ï¼ˆå…¨è§’ãƒ”ãƒªã‚ªãƒ‰ï¼‰
                ". ",        # è‹±èªæ–‡æœ«
                "! ",        # æ„Ÿå˜†ç¬¦
                "? ",        # ç–‘å•ç¬¦
                "ï¼›",        # ã‚»ãƒŸã‚³ãƒ­ãƒ³
                "ã€",        # èª­ç‚¹
                "ï¼Œ",        # ã‚«ãƒ³ãƒï¼ˆå…¨è§’ï¼‰
                ", ",        # ã‚«ãƒ³ãƒ
                " ",         # ã‚¹ãƒšãƒ¼ã‚¹
                ""           # æœ€å¾Œã®æ‰‹æ®µï¼ˆæ–‡å­—å˜ä½ï¼‰
            ],
            keep_separator=True  # åŒºåˆ‡ã‚Šæ–‡å­—ã‚’ä¿æŒ
        )

    def _chunk_text(self, text: str, page_num: int) -> List[Dict]:
        """
        ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯å¢ƒç•Œã‚’è€ƒæ…®ã—ãŸãƒãƒ£ãƒ³ã‚¯åŒ–
        """
        # è¡¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒã™ã‚‹ãŸã‚ã®å‰å‡¦ç†
        text = self._preserve_table_context(text)

        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°
        chunks = self.text_splitter.split_text(text)

        return [
            {
                "content": chunk,
                "page_number": page_num,
                "content_type": "text",
                "chunk_index": idx
            }
            for idx, chunk in enumerate(chunks)
        ]

    def _preserve_table_context(self, text: str) -> str:
        """
        è¡¨ã®å‰å¾Œã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ 
        ä¾‹: ã€Œä»¥ä¸‹ã¯ã€‡ã€‡è¡¨ã§ã™ã€â†’ è¡¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‰ã«æ®‹ã™
        """
        # å®Ÿè£…: æ­£è¦è¡¨ç¾ã§è¡¨ã®å‰ã®è¦‹å‡ºã—ã‚’æ¤œå‡ºã—ã€
        # ãƒãƒ£ãƒ³ã‚¯å¢ƒç•Œã‚’ã¾ãŸãŒãªã„ã‚ˆã†ã«ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—
        import re

        # è¡¨ã‚„å›³ã®å‚ç…§ã‚’æ¤œå‡º
        patterns = [
            r'(è¡¨\s*\d+[.:].*?)(\n)',
            r'(å›³\s*\d+[.:].*?)(\n)',
            r'(Table\s+\d+[.:].*?)(\n)',
            r'(Figure\s+\d+[.:].*?)(\n)',
        ]

        for pattern in patterns:
            text = re.sub(pattern, r'\1\n\n', text)  # æ®µè½åŒºåˆ‡ã‚Šã‚’å¼·åˆ¶

        return text
```

**æ¨å®šåŠ¹æœ**:
- å›ç­”ã®æ–‡è„ˆæ­£ç¢ºæ€§: +15-20%
- è¡¨ã‚„å›³ã®èª¬æ˜ã¨ã®ç´ä»˜ã‘æ”¹å–„
- å®Ÿè£…ã‚³ã‚¹ãƒˆ: æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®å°è¦æ¨¡ä¿®æ­£ã®ã¿

---

#### 3ï¸âƒ£ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ï¼ˆå„ªå…ˆåº¦: ğŸŸ¡ ä¸­ï¼‰

**ç›®çš„**: APIã‚³ã‚¹ãƒˆå‰Šæ¸› + å¿œç­”é€Ÿåº¦æ”¹å–„

**å®Ÿè£…æ–¹æ³•**:
```python
# æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«: backend/src/embedding_cache.py

import hashlib
import json
from typing import List, Optional
from pathlib import Path
import pickle

class EmbeddingCache:
    def __init__(self, cache_dir: str = "./cache/embeddings"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆLRUï¼‰
        from functools import lru_cache
        self._memory_cache = {}
        self._max_memory_items = 1000

    def _get_cache_key(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        return hashlib.sha256(text.encode('utf-8')).hexdigest()

    def get(self, text: str) -> Optional[List[float]]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—"""
        key = self._get_cache_key(text)

        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
        if key in self._memory_cache:
            return self._memory_cache[key]

        # ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
        cache_file = self.cache_dir / f"{key}.pkl"
        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                embedding = pickle.load(f)

            # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ 
            self._add_to_memory_cache(key, embedding)
            return embedding

        return None

    def set(self, text: str, embedding: List[float]):
        """åŸ‹ã‚è¾¼ã¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        key = self._get_cache_key(text)

        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ 
        self._add_to_memory_cache(key, embedding)

        # ãƒ‡ã‚£ã‚¹ã‚¯ã«æ°¸ç¶šåŒ–
        cache_file = self.cache_dir / f"{key}.pkl"
        with open(cache_file, 'wb') as f:
            pickle.dump(embedding, f)

    def _add_to_memory_cache(self, key: str, value: List[float]):
        """LRUæ–¹å¼ã§ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ """
        if len(self._memory_cache) >= self._max_memory_items:
            # æœ€ã‚‚å¤ã„ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‰Šé™¤
            oldest_key = next(iter(self._memory_cache))
            del self._memory_cache[oldest_key]

        self._memory_cache[key] = value
```

**çµ±åˆ** (`backend/src/text_embedder.py`):
```python
class TextEmbedder:
    def __init__(self, config: Dict[str, Any]):
        # ...æ—¢å­˜ã‚³ãƒ¼ãƒ‰...
        self.cache = EmbeddingCache()

    def embed_text(self, text: str) -> List[float]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
        cached = self.cache.get(text)
        if cached is not None:
            return cached

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹: APIå‘¼ã³å‡ºã—
        embedding = self._call_openai_api(text)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self.cache.set(text, embedding)

        return embedding

    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """ãƒãƒƒãƒå‡¦ç†ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨"""
        results = []
        uncached_texts = []
        uncached_indices = []

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ/ãƒŸã‚¹ã‚’åˆ¤å®š
        for idx, text in enumerate(texts):
            cached = self.cache.get(text)
            if cached is not None:
                results.append(cached)
            else:
                results.append(None)
                uncached_texts.append(text)
                uncached_indices.append(idx)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒƒãƒå‡¦ç†
        if uncached_texts:
            embeddings = self._call_openai_api_batch(uncached_texts)

            # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ & resultsé…åˆ—ã«æ ¼ç´
            for idx, text, embedding in zip(uncached_indices, uncached_texts, embeddings):
                self.cache.set(text, embedding)
                results[idx] = embedding

        return results
```

**æ¨å®šåŠ¹æœ**:
- APIã‚³ã‚¹ãƒˆå‰Šæ¸›: 60-70%ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã«ã‚ˆã‚‹ï¼‰
- ã‚¯ã‚¨ãƒªå¿œç­”é€Ÿåº¦: -100msï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ï¼‰
- ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡: ~10MB/1000åŸ‹ã‚è¾¼ã¿

---

#### 4ï¸âƒ£ Visionè§£æçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ï¼ˆå„ªå…ˆåº¦: ğŸŸ¡ ä¸­ï¼‰

**å®Ÿè£…æ–¹æ³•**:
```python
# ä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«: backend/src/vision_analyzer.py

class VisionAnalyzer:
    def __init__(self, config: Dict[str, Any]):
        # ...æ—¢å­˜ã‚³ãƒ¼ãƒ‰...
        self.cache_dir = Path("./cache/vision_analysis")
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _get_image_hash(self, image_path: str) -> str:
        """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
        with open(image_path, 'rb') as f:
            return hashlib.sha256(f.read()).hexdigest()

    def analyze_image(
        self,
        image_path: str,
        analysis_type: str
    ) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãç”»åƒè§£æ"""
        image_hash = self._get_image_hash(image_path)
        cache_key = f"{image_hash}_{analysis_type}"
        cache_file = self.cache_dir / f"{cache_key}.json"

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if cache_file.exists():
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)['result']

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹: Gemini APIå‘¼ã³å‡ºã—
        result = self._call_gemini_vision(image_path, analysis_type)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump({
                'result': result,
                'timestamp': datetime.now().isoformat(),
                'analysis_type': analysis_type
            }, f, ensure_ascii=False)

        return result
```

**æ¨å®šåŠ¹æœ**:
- Vision APIå‘¼ã³å‡ºã—å‰Šæ¸›: 80-90%ï¼ˆåŒã˜PDFã®å†å‡¦ç†æ™‚ï¼‰
- PDFå‡¦ç†æ™‚é–“: -30-50%ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ï¼‰

---

#### 5ï¸âƒ£ BM25ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆå„ªå…ˆåº¦: ğŸŸ¢ æ¨å¥¨ï¼‰

**ç›®çš„**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒã®å¼·åŒ–

**å®Ÿè£…æ–¹æ³•**:
```python
# æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«: backend/src/hybrid_search.py

from rank_bm25 import BM25Okapi
from typing import List, Dict, Tuple
import numpy as np

class HybridSearcher:
    def __init__(self, vector_store, bm25_index=None):
        self.vector_store = vector_store
        self.bm25_index = bm25_index
        self.bm25_docs = []

    def build_bm25_index(self, documents: List[str]):
        """BM25ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰"""
        # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        import MeCab
        mecab = MeCab.Tagger("-Owakati")

        tokenized_docs = [
            mecab.parse(doc).strip().split()
            for doc in documents
        ]

        self.bm25_docs = documents
        self.bm25_index = BM25Okapi(tokenized_docs)

    def hybrid_search(
        self,
        query: str,
        query_embedding: List[float],
        k: int = 5,
        alpha: float = 0.7  # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®é‡ã¿
    ) -> List[Tuple[str, float]]:
        """
        ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ« + BM25ï¼‰
        alpha: 1.0 = ãƒ™ã‚¯ãƒˆãƒ«ã®ã¿, 0.0 = BM25ã®ã¿
        """
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        vector_results = self.vector_store.similarity_search_with_score(
            query_embedding,
            k=k*2  # å¤šã‚ã«å–å¾—ã—ã¦èåˆ
        )

        # BM25æ¤œç´¢
        import MeCab
        mecab = MeCab.Tagger("-Owakati")
        tokenized_query = mecab.parse(query).strip().split()
        bm25_scores = self.bm25_index.get_scores(tokenized_query)

        # ã‚¹ã‚³ã‚¢æ­£è¦åŒ–
        vector_scores_norm = self._normalize_scores(
            [score for _, score in vector_results]
        )
        bm25_scores_norm = self._normalize_scores(bm25_scores)

        # èåˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆReciprocal Rank Fusionï¼‰
        combined_scores = {}

        for idx, (doc, vec_score) in enumerate(vector_results):
            doc_id = doc.metadata.get('id', idx)
            combined_scores[doc_id] = alpha * vector_scores_norm[idx]

        for idx, bm25_score in enumerate(bm25_scores_norm):
            if idx in combined_scores:
                combined_scores[idx] += (1 - alpha) * bm25_score
            else:
                combined_scores[idx] = (1 - alpha) * bm25_score

        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_results = sorted(
            combined_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )[:k]

        return [
            (self.bm25_docs[doc_id], score)
            for doc_id, score in sorted_results
        ]

    def _normalize_scores(self, scores: List[float]) -> List[float]:
        """Min-Maxæ­£è¦åŒ–"""
        scores = np.array(scores)
        min_score = scores.min()
        max_score = scores.max()

        if max_score - min_score == 0:
            return [1.0] * len(scores)

        return ((scores - min_score) / (max_score - min_score)).tolist()
```

**ä¾å­˜é–¢ä¿‚**:
```bash
pip install rank-bm25 mecab-python3
```

**çµ±åˆ** (`backend/src/rag_engine.py`):
```python
from hybrid_search import HybridSearcher

class RAGEngine:
    def __init__(self, config):
        # ...æ—¢å­˜ã‚³ãƒ¼ãƒ‰...
        self.hybrid_searcher = HybridSearcher(self.vector_store)

        # åˆå›èµ·å‹•æ™‚ã«BM25ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰
        self._build_bm25_index()

    def _build_bm25_index(self):
        """å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰BM25ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰"""
        # Supabaseã‹ã‚‰å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
        all_docs = self.vector_store.get_all_documents()
        documents = [doc.page_content for doc in all_docs]

        self.hybrid_searcher.build_bm25_index(documents)

    def _get_relevant_contexts(self, query: str, category: Optional[str] = None):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’ä½¿ç”¨"""
        query_embedding = self.embedder.embed_text(query)

        results = self.hybrid_searcher.hybrid_search(
            query,
            query_embedding,
            k=5,
            alpha=0.7  # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’é‡è¦–
        )

        return results
```

**æ¨å®šåŠ¹æœ**:
- å°‚é–€ç”¨èªæ¤œç´¢ç²¾åº¦: +20-30%
- å›ºæœ‰åè©ã®ãƒãƒƒãƒãƒ³ã‚°æ”¹å–„
- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å¢—åŠ : +20-50ms

---

### å®Ÿè£…é †åºï¼ˆæ¨å¥¨ï¼‰

**Day 1-2**:
1. âœ… Rerankingå°å…¥
2. âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°

**Day 3-4**:
3. âœ… ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°
4. âœ… Visionè§£æã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

**Day 5-7**:
5. âœ… BM25ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
6. âœ… çµ±åˆãƒ†ã‚¹ãƒˆ & ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š

---

## ğŸ“ å®Ÿè£…æ™‚ã®æ³¨æ„ç‚¹

### 1. å¾Œæ–¹äº’æ›æ€§
- æ—¢å­˜ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãƒ‡ãƒ¼ã‚¿ã¯å¤‰æ›´ä¸è¦
- æ–°è¦PDFå‡¦ç†æ™‚ã®ã¿æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯æˆ¦ç•¥ã‚’é©ç”¨
- `config.yaml`ã«æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ï¼š
  ```yaml
  rag:
    enable_reranking: true
    enable_semantic_chunking: true
    enable_embedding_cache: true
    enable_bm25_hybrid: true
  ```

### 2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- Rerankingå¤±æ•—æ™‚ã¯ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœã‚’ãã®ã¾ã¾ä½¿ç”¨
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯APIå‘¼ã³å‡ºã—ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- BM25ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰å¤±æ•—æ™‚ã¯ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ã¿ã§ç¶™ç¶š

### 3. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
- Langfuseã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚’è¿½è·¡
- æ¤œç´¢ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²ï¼ˆNDCG, MRRï¼‰
- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®åˆ†ä½æ•°ï¼ˆP50, P95, P99ï¼‰ã‚’ç›£è¦–

### 4. è¨­å®šã®èª¿æ•´
- Rerankingãƒ¢ãƒ‡ãƒ«: ç²¾åº¦ã¨ã‚¹ãƒ”ãƒ¼ãƒ‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•
  - è»½é‡: `cross-encoder/ms-marco-MiniLM-L-6-v2`
  - é«˜ç²¾åº¦: `cross-encoder/ms-marco-electra-base`
- ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®alphaå€¤: ã‚«ãƒ†ã‚´ãƒªãƒ¼ã”ã¨ã«èª¿æ•´å¯èƒ½
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º: ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã«å¿œã˜ã¦èª¿æ•´

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 1. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
- å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å˜ä½“ãƒ†ã‚¹ãƒˆ
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¿å­˜/èª­ã¿è¾¼ã¿
- Rerankingã‚¹ã‚³ã‚¢ã®æ­£å½“æ€§

### 2. çµ±åˆãƒ†ã‚¹ãƒˆ
- ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ã‚¯ã‚¨ãƒªå‡¦ç†
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ/ãƒŸã‚¹ã®ã‚·ãƒŠãƒªã‚ª
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¯ã‚¨ãƒªã‚»ãƒƒãƒˆï¼ˆ20-50ä»¶ï¼‰
- æ”¹å–„å‰å¾Œã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒ
- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®šï¼ˆè¤‡æ•°å›å®Ÿè¡Œã—ã¦å¹³å‡ï¼‰

### 4. A/Bãƒ†ã‚¹ãƒˆï¼ˆæ¨å¥¨ï¼‰
- æœ¬ç•ªç’°å¢ƒã§ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’åˆ†å‰²
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®åé›†
- å®¢è¦³çš„ãªç²¾åº¦è©•ä¾¡

---

## ğŸ“ˆ æˆåŠŸæŒ‡æ¨™ï¼ˆKPIï¼‰

### å®šé‡çš„æŒ‡æ¨™

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | æ¸¬å®šæ–¹æ³• | ç›®æ¨™å€¤ |
|-----------|---------|--------|
| NDCG@5 | è©•ä¾¡ã‚»ãƒƒãƒˆã§æ¸¬å®š | 0.85 â†’ 0.92 |
| æ¤œç´¢ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼ˆP50ï¼‰ | Langfuseãƒˆãƒ¬ãƒ¼ã‚¹ | 200ms â†’ 100ms |
| ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ | ãƒ­ã‚°åˆ†æ | 60-70% |
| APIã‚³ã‚¹ãƒˆå‰Šæ¸› | OpenAIä½¿ç”¨é‡ | -30-40% |

### å®šæ€§çš„æŒ‡æ¨™
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å›ç­”å“è³ªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
- è¤‡é›‘ãªè³ªå•ã¸ã®å¯¾å¿œæ”¹å–„
- å°‚é–€ç”¨èªæ¤œç´¢ã®ç²¾åº¦

---

## ğŸ”„ Phase 2ä»¥é™ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼

Phase 1å®Œäº†å¾Œã€ä»¥ä¸‹ã®æ–½ç­–ã‚’æ¤œè¨ï¼š

### Phase 2: æ¤œç´¢ç²¾åº¦å‘ä¸Šï¼ˆ2-3é€±é–“ï¼‰
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆFew-shot learningï¼‰
- å‹•çš„ãªé¡ä¼¼åº¦é–¾å€¤èª¿æ•´
- ã‚¯ã‚¨ãƒªæ‹¡å¼µï¼ˆQuery expansionï¼‰

### Phase 3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼ˆ1ãƒ¶æœˆï¼‰
- Supabase pgvectorã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®èª¿æ•´
- éåŒæœŸå‡¦ç†ã®å°å…¥ï¼ˆCeleryï¼‰
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆCLIPï¼‰

### Phase 4: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ï¼ˆ2-3ãƒ¶æœˆï¼‰
- åˆ†æ•£å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
- ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–
- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ï¼‰

---

## ğŸ“š å‚è€ƒè³‡æ–™

### æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [LangChain Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/)
- [Sentence Transformers - Cross-Encoders](https://www.sbert.net/examples/applications/cross-encoder/README.html)
- [Rank BM25](https://github.com/dorianbrown/rank_bm25)
- [Supabase Vector Guide](https://supabase.com/docs/guides/ai/vector-columns)

### RAGæœ€é©åŒ–ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
- [Advanced RAG Techniques](https://www.anthropic.com/research/retrieval-augmented-generation)
- [Hybrid Search in Production](https://www.pinecone.io/learn/hybrid-search-intro/)

---

## ğŸ¤ ã‚µãƒãƒ¼ãƒˆ

è³ªå•ã‚„å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆ:
1. Langfuseãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ç¢ºèª
2. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`backend/logs/`ï¼‰ã‚’ç¢ºèª
3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`config.yaml`ï¼‰ã®ç¢ºèª
4. å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆ`RAG_IMPROVEMENT_CHECKLIST.md`ï¼‰ã‚’å‚ç…§

---

**æœ€çµ‚æ›´æ–°**: 2025-11-04
**æ¬¡å›ãƒ¬ãƒ“ãƒ¥ãƒ¼**: Phase 1å®Œäº†å¾Œï¼ˆ1é€±é–“å¾Œï¼‰
