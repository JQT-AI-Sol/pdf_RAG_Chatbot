# RAGシステム要件定義書（PoC版）
## Officeドキュメント由来の表・グラフ対応版

## 1. プロジェクト概要

### 1.1 目的
技術文書・マニュアルのPDFから情報を検索・抽出できるRAG（Retrieval-Augmented Generation）システムのPoC開発。特にExcel/PowerPoint由来の表やグラフを含むPDFに対応。

### 1.2 スコープ
- PoC（Proof of Concept）としての簡易実装
- **表・グラフを含むPDFに対応したハイブリッド検索機能**
- ローカル環境での動作確認

### 1.3 特徴的な要件
- Officeで作成された表やグラフが20-40%のページに含まれる
- **GPT-5の統合Vision機能で表・グラフを解析**
- グラフからは視覚的説明と数値データを抽出
- テキストと画像コンテンツの統合検索
- **ドキュメントカテゴリー機能による検索範囲の限定**

---

## 2. 機能要件

### 2.1 PDFアップロード機能
- **FR-001**: ユーザーがStreamlit UIからPDFファイルをアップロードできる
- **FR-002**: 複数のPDFファイルを一括アップロード可能（最大5ファイル推奨）
- **FR-003**: **アップロード時にドキュメントカテゴリーをテキスト入力で指定できる**（例：製品マニュアル、技術仕様書、運用手順書など）
- **FR-004**: アップロードされたPDFのファイル名、ページ数、カテゴリー、概要情報を表示
- **FR-005**: アップロード後、処理進捗をリアルタイム表示

### 2.2 PDF前処理機能

#### 2.2.1 テキスト抽出
- **FR-006**: pdfplumberを使用してPDFからテキストを抽出
- **FR-007**: テキスト部分をチャンク分割（チャンクサイズ: 500-1000トークン、オーバーラップ: 100-200トークン）
- **FR-008**: ページ単位でテキスト量を確認し、テキストが少ないページは画像主体と判定
- **FR-009**: **抽出したテキストチャンクにドキュメントカテゴリー情報を付与**

#### 2.2.2 画像・表・グラフ抽出
- **FR-010**: pdfplumberで画像領域を検出し、個別に画像を抽出
- **FR-011**: 表やグラフが含まれるページを特定（レイアウト解析）
- **FR-012**: 抽出した画像を適切な解像度（最大2000px）でPNG保存
- **FR-013**: 各画像にメタデータ（ページ番号、位置情報、推定コンテンツタイプ、**ドキュメントカテゴリー**）を付与

### 2.3 ハイブリッド検索機能

#### 2.3.1 テキストエンベディング
- **FR-014**: OpenAI Embedding API（text-embedding-3-small）を使用
- **FR-015**: テキストチャンクをベクトル化してChromaDBに保存
- **FR-016**: ベクトル類似度検索でTop-K件（K=5）を取得

#### 2.3.2 GPT-5による表・グラフ解析
- **FR-017**: **GPT-5の統合Vision機能**を使用して表・グラフを解析
- **FR-018**: 表に対する解析内容：
  - 表の構造説明（行数、列数、ヘッダー情報）
  - 表内の主要なデータポイント
  - 表の目的・意味の説明
- **FR-019**: グラフに対する解析内容：
  - グラフの種類（折れ線、棒、円など）
  - 視覚的な傾向・特徴の説明
  - **可能な範囲で具体的な数値データの抽出**（軸ラベル、データポイント、凡例）
- **FR-020**: GPT-5の解析結果をテキスト化してエンベディング
- **FR-021**: 画像データ（表・グラフ）もChromaDBに保存（画像参照パス、**カテゴリー情報**を含む）

#### 2.3.3 統合検索
- **FR-022**: テキストチャンクと画像コンテンツの両方を横断検索
- **FR-023**: 関連性スコアでランキング表示
- **FR-024**: **カテゴリーでフィルタリングした検索が可能**

### 2.4 カテゴリー管理機能
- **FR-025**: **既存のカテゴリー一覧を管理・表示できる**
- **FR-026**: **カテゴリーは自由入力で追加できる**（プリセット不要、柔軟な運用）
- **FR-027**: **登録済みカテゴリーの一覧を確認できる**

### 2.5 質問応答機能
- **FR-028**: ユーザーが自然言語で質問を入力
- **FR-029**: **質問前にドロップダウンから対象カテゴリーを選択できる**（登録済みカテゴリー + "全カテゴリー"）
- **FR-030**: 選択されたカテゴリーのドキュメントのみを検索対象とする
- **FR-031**: 質問をエンベディング化し、ChromaDBから関連情報を検索
- **FR-032**: LangChain + GPT-5で回答を生成
- **FR-033**: 回答生成時のコンテキストに、テキストとVision解析結果を含める
- **FR-034**: 回答と共に参照元（ファイル名、ページ番号、**カテゴリー**）を表示
- **FR-035**: **関連する表・グラフ画像を回答と共に表示**
- **FR-036**: グラフの数値データが抽出された場合、それも回答に含める

### 2.6 UI/UX要件
- **FR-037**: Streamlitで直感的なUIを提供
- **FR-038**: サイドバーでPDFアップロード、**カテゴリー入力**、インデックス作成を管理
- **FR-039**: **質問エリア上部にカテゴリー選択ドロップダウンを配置**
- **FR-040**: メインエリアでチャット形式の質問応答インターフェース
- **FR-041**: 処理状況をプログレスバーとステータスメッセージで表示
- **FR-042**: 回答エリアに画像（表・グラフ）をインライン表示
- **FR-043**: 画像クリックで拡大表示機能
- **FR-044**: **現在選択中のカテゴリーを視覚的に表示**

---

## 3. 非機能要件

### 3.1 性能要件
- **NFR-001**: PDFアップロード〜インデックス作成完了まで：
  - テキストのみのページ: 5秒/ページ
  - 表・グラフ含むページ: 15-20秒/ページ（Vision解析含む）
- **NFR-002**: 質問に対する回答生成は15秒以内（画像検索含む）
- **NFR-003**: 同時処理はシングルユーザーのみ（PoC要件）

### 3.2 セキュリティ要件
- **NFR-004**: アップロードされたPDFはローカルストレージに一時保存
- **NFR-005**: 抽出された画像もローカルに保存（data/extracted_images/）
- **NFR-006**: OpenAI APIキーは環境変数（.env）で管理
- **NFR-007**: 認証機能は実装しない（ローカル環境のみ）

### 3.3 拡張性・保守性
- **NFR-008**: モジュール構成で実装し、将来的な機能追加に対応
- **NFR-009**: ログ出力機能を実装（処理時間、API呼び出し回数、エラー情報など）
- **NFR-010**: 設定ファイル（config.yaml）で主要パラメータを管理
- **NFR-011**: Vision解析処理のキャッシング機能（同じ画像を再処理しない）

### 3.4 互換性
- **NFR-012**: Python 3.10以上で動作
- **NFR-013**: Windows/Mac/Linuxのローカル環境で動作

---

## 4. 技術スタック

### 4.1 フロントエンド
- **Streamlit**: UIフレームワーク

### 4.2 バックエンド/処理エンジン
- **Python 3.10+**: 開発言語
- **LangChain**: RAGパイプライン構築
- **pdfplumber**: PDF解析（テキスト・画像領域検出・抽出）
- **Pillow (PIL)**: 画像処理・リサイズ

### 4.3 AI/ML
- **OpenAI API**:
  - **GPT-5**: 質問応答、表・グラフの画像解析（統合Vision機能）
  - **text-embedding-3-small**: テキストエンベディング（1536次元）
- **ChromaDB**: ベクトルデータベース

### 4.4 その他ライブラリ
- **python-dotenv**: 環境変数管理
- **tiktoken**: トークン計算
- **PyYAML**: 設定ファイル管理
- **base64**: 画像のbase64エンコード（Vision機能用）

---

## 5. システムアーキテクチャ

### 5.1 処理フロー

```
[ユーザー]
   ↓
[Streamlit UI] → [PDFアップロード + カテゴリー入力]
   ↓
[pdfplumber解析]
   ├─→ [テキスト抽出] → [チャンク分割] → [OpenAI Embedding]
   │                                              ↓
   │                                       [ChromaDB保存（カテゴリー付き）]
   │
   └─→ [画像領域検出] → [画像抽出（表・グラフ）]
                              ↓
                       [GPT-5 (Vision統合)]
                       - 表の構造・内容解析
                       - グラフの視覚的説明
                       - グラフの数値データ抽出
                              ↓
                       [解析結果テキスト化]
                              ↓
                       [OpenAI Embedding]
                              ↓
                       [ChromaDB保存（画像パス + カテゴリー付き）]

─────────────── 検索・回答フェーズ ───────────────

[カテゴリー選択（ドロップダウン）] → [質問入力] → [質問エンベディング]
                                                           ↓
                                                 [ChromaDB検索]
                                                 - カテゴリーでフィルタリング
                                                 - テキストチャンク取得
                                                 - 画像コンテンツ取得
                                                           ↓
                                                 [コンテキスト構築]
                                                 - テキスト情報
                                                 - 表・グラフの解析結果
                                                 - 数値データ
                                                           ↓
                                                 [LangChain + GPT-5]
                                                           ↓
                                                 [回答生成]
                                                           ↓
                                          [Streamlit UI表示]
                                          - 回答テキスト
                                          - 参照元情報（カテゴリー含む）
                                          - 関連画像（表・グラフ）表示
```

### 5.2 ディレクトリ構成

```
PoC_chatbot/
├── app.py                          # Streamlitメインアプリ
├── requirements.txt                # 依存パッケージ
├── .env                            # 環境変数（APIキー等）
├── .env.example                    # 環境変数テンプレート
├── config.yaml                     # 設定ファイル
├── README.md                       # プロジェクト説明
├── requirements_definition.md      # 本要件定義書
│
├── src/
│   ├── __init__.py
│   ├── pdf_processor.py            # PDF処理（テキスト・画像抽出）
│   ├── text_embedder.py            # テキストエンベディング処理
│   ├── vision_analyzer.py          # GPT-5 Vision処理（表・グラフ解析）
│   ├── vector_store.py             # ChromaDB操作
│   ├── rag_engine.py               # RAGエンジン（検索・回答生成）
│   ├── category_manager.py         # カテゴリー管理
│   ├── prompt_templates.py         # プロンプトテンプレート
│   └── utils.py                    # ユーティリティ関数
│
├── data/                           # データ保存用
│   ├── uploaded_pdfs/              # アップロードされたPDF
│   ├── extracted_images/           # 抽出された表・グラフ画像
│   │   └── [pdf_name]/            # PDF毎にディレクトリ分け
│   │       ├── page_1_img_0.png
│   │       └── page_2_img_0.png
│   ├── chroma_db/                  # ChromaDBデータ
│   └── categories.json             # カテゴリー一覧（動的に管理）
│
├── logs/                           # ログファイル
│   └── app.log
│
└── tests/                          # テストコード（将来用）
    └── test_vision_analyzer.py
```

---

## 6. データモデル

### 6.1 ChromaDB コレクション構造

#### テキストチャンクコレクション
```python
{
    "id": "doc_001_page_1_chunk_0",
    "embedding": [0.123, 0.456, ...],  # 1536次元ベクトル
    "metadata": {
        "source_file": "technical_manual.pdf",
        "page_number": 1,
        "chunk_index": 0,
        "content_type": "text",
        "category": "製品マニュアル",  # ドキュメントカテゴリー
        "created_at": "2025-01-17T12:00:00"
    },
    "document": "チャンクのテキスト内容..."
}
```

#### 画像コンテンツコレクション（表・グラフ）
```python
{
    "id": "doc_001_page_3_table_0",
    "embedding": [0.789, 0.012, ...],  # Vision解析結果のベクトル
    "metadata": {
        "source_file": "technical_manual.pdf",
        "page_number": 3,
        "image_index": 0,
        "content_type": "table",  # or "chart", "graph", "figure"
        "category": "製品マニュアル",  # ドキュメントカテゴリー
        "image_path": "data/extracted_images/technical_manual/page_3_img_0.png",
        "vision_description": "この表は製品仕様を示しており、3行5列の構造...",
        "extracted_data": {
            "table_rows": 3,
            "table_cols": 5,
            "key_values": ["製品A: 100kg", "製品B: 150kg"],
            "graph_type": null,  # グラフの場合は "line", "bar", "pie" など
            "data_points": null   # グラフの数値データ
        },
        "created_at": "2025-01-17T12:00:00"
    },
    "document": "製品仕様表。製品A: 重量100kg、サイズ50x30cm..."
}
```

#### グラフ用の例
```python
{
    "id": "doc_002_page_5_graph_0",
    "embedding": [...],
    "metadata": {
        "source_file": "performance_report.pdf",
        "page_number": 5,
        "image_index": 0,
        "content_type": "graph",
        "category": "運用レポート",  # ドキュメントカテゴリー
        "image_path": "data/extracted_images/performance_report/page_5_img_0.png",
        "vision_description": "2023-2024年の売上推移を示す折れ線グラフ。右肩上がりの傾向...",
        "extracted_data": {
            "table_rows": null,
            "table_cols": null,
            "key_values": null,
            "graph_type": "line_chart",
            "data_points": [
                {"period": "2023 Q1", "value": "120万円"},
                {"period": "2023 Q2", "value": "145万円"},
                {"period": "2023 Q3", "value": "160万円"},
                {"period": "2023 Q4", "value": "180万円"}
            ]
        },
        "created_at": "2025-01-17T12:00:00"
    },
    "document": "売上推移グラフ。2023 Q1: 120万円から2023 Q4: 180万円まで増加..."
}
```

---

## 7. 設定パラメータ（config.yaml）

```yaml
# OpenAI設定
openai:
  model_chat: "gpt-5"  # GPT-5（Vision統合）
  model_embedding: "text-embedding-3-small"
  temperature: 0.7
  max_tokens: 1500

# ChromaDB設定
chromadb:
  persist_directory: "./data/chroma_db"
  collection_name_text: "pdf_text_chunks"
  collection_name_images: "pdf_image_contents"

# PDF処理設定
pdf_processing:
  chunk_size: 800
  chunk_overlap: 150
  max_files: 5
  extract_images: true
  min_image_size: 100  # 最小画像サイズ（px）

# Vision設定（GPT-5）
vision:
  max_image_size: 2000  # ピクセル
  image_format: "PNG"
  enable_caching: true  # 同じ画像の再処理を避ける
  analysis_prompt_table: |
    この画像は技術文書内の表です。以下を分析してください：
    1. 表の構造（行数、列数、ヘッダー）
    2. 表内の主要なデータ
    3. この表が示す情報の意味
  analysis_prompt_graph: |
    この画像は技術文書内のグラフです。以下を分析してください：
    1. グラフの種類（折れ線、棒、円など）
    2. 視覚的な傾向や特徴
    3. 可能な限り具体的な数値データ（軸ラベル、データポイント、凡例）
    4. グラフが示す主要な洞察

# 検索設定
search:
  top_k_text: 5
  top_k_images: 3
  similarity_threshold: 0.7
  enable_hybrid_search: true  # テキストと画像の統合検索
  enable_category_filter: true  # カテゴリーフィルタリング有効化

# カテゴリー設定
category:
  storage_file: "./data/categories.json"  # カテゴリー一覧保存先
  allow_custom: true  # カスタムカテゴリー入力を許可

# ログ設定
logging:
  level: "INFO"
  file: "./logs/app.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
```

---

## 8. GPT-5 Vision プロンプト戦略

### 8.1 表解析用プロンプト

```
あなたは技術文書の表を解析する専門家です。
以下の画像は技術マニュアルに含まれる表です。

以下の情報を抽出してください：

1. **表の構造**
   - 行数と列数
   - ヘッダー行の内容
   - 表のタイトル（あれば）

2. **表の内容**
   - 各セルの主要なデータ
   - 数値データがあれば具体的な値
   - 単位があれば記載

3. **表の意味**
   - この表が示している情報は何か
   - 主要なデータポイントや傾向

検索可能なテキスト形式で出力してください。
```

### 8.2 グラフ解析用プロンプト

```
あなたは技術文書のグラフを解析する専門家です。
以下の画像は技術マニュアルに含まれるグラフです。

以下の情報を抽出してください：

1. **グラフの種類**
   - 折れ線グラフ、棒グラフ、円グラフ、散布図など

2. **視覚的な特徴**
   - データの傾向（増加、減少、一定など）
   - 特異点や注目すべきポイント

3. **数値データ（重要）**
   - X軸とY軸のラベル・単位
   - グラフ内の具体的なデータポイント（可能な限り）
   - 凡例の内容
   - グラフタイトル

4. **主要な洞察**
   - このグラフから読み取れる重要な情報

JSON形式で構造化して出力してください：
{
  "graph_type": "...",
  "title": "...",
  "axes": {"x": "...", "y": "..."},
  "data_points": [...],
  "insights": "..."
}
```

---

## 9. API仕様

### 9.1 OpenAI API使用

#### Embedding API
- **エンドポイント**: `https://api.openai.com/v1/embeddings`
- **モデル**: `text-embedding-3-small` (1536次元)
- **想定使用量**:
  - 10ページPDF、テキスト主体: 約50-100回
  - 表・グラフ含む10ページ: 約70-120回（Vision解析結果も含む）

#### Chat Completion API（GPT-5）
- **エンドポイント**: `https://api.openai.com/v1/chat/completions`
- **モデル**: `gpt-5`
- **Vision機能**: base64エンコード画像を送信（GPT-5に統合）
- **想定使用量**:
  - インデックス作成: 1回/画像（表・グラフ）
  - 質問応答: 1回/質問

#### コスト試算（10ページPDF、3つの表・グラフ含む）
※GPT-5の価格は未確定のため、GPT-4o相当として試算
- Embedding: $0.01-0.02
- Vision解析: $0.15-0.30（3画像）
- 質問応答（10質問）: $0.20-0.50
- **合計**: 約$0.36-0.82/ドキュメント

---

## 10. 実装フェーズ

### Phase 1: 基本インフラ（1日）
- プロジェクトセットアップ
- 環境構築（依存パッケージインストール）
- Streamlit基本UI作成
- ディレクトリ構造作成

### Phase 2: PDF処理（2日）
- pdfplumberによるテキスト抽出
- 画像領域検出・抽出
- チャンク分割実装
- メタデータ管理

### Phase 3: GPT-5 Vision統合（2-3日）
- **GPT-5 API統合**
- **表解析プロンプト開発**
- **グラフ解析プロンプト開発（数値データ抽出含む）**
- 解析結果の構造化
- キャッシング機能実装

### Phase 4: エンベディングとベクトルDB（1-2日）
- OpenAI Embedding統合
- ChromaDB設定
- テキスト・画像コンテンツの保存
- ハイブリッド検索実装

### Phase 5: RAGエンジン（2日）
- LangChainパイプライン構築
- 質問応答機能実装
- コンテキスト構築（テキスト+画像）
- プロンプトエンジニアリング

### Phase 6: UI/UX改善（1-2日）
- 画像表示機能
- プログレスバー・ステータス表示
- エラーハンドリング
- レスポンシブデザイン調整

### Phase 7: テストと調整（1-2日）
- 統合テスト
- Vision解析精度チューニング
- パフォーマンス最適化

**総開発期間**: 10-14日（PoC版）

---

## 11. リスクと対策

### 11.1 技術リスク

| リスク | 影響 | 対策 |
|--------|------|------|
| GPT-5 APIの利用可能性・仕様変更 | 高 | GPT-4oへのフォールバック機能実装 |
| Vision解析精度（特に数値データ） | 高 | プロンプト最適化、複数回試行、構造化出力 |
| APIのコスト超過 | 中 | 画像サイズ最適化、キャッシング、監視 |
| レート制限 | 中 | リトライロジック、バッチ処理間隔調整 |
| 表・グラフの検出精度 | 中 | pdfplumberパラメータ調整 |

### 11.2 データ品質リスク

| リスク | 影響 | 対策 |
|--------|------|------|
| 複雑な表の構造崩れ | 中 | GPT-5で柔軟に対応、人手検証 |
| グラフ数値の読み取りエラー | 中 | 信頼度スコア表示、複数解析の平均 |
| 画像品質の低下 | 低 | 高解像度抽出 |

---

## 12. 成功基準

### PoC成功の定義
1. ✅ 表・グラフを含む技術文書PDFをアップロードし、インデックス化できる
2. ✅ **PDFアップロード時にカテゴリーを指定できる**
3. ✅ **質問時にカテゴリーを選択し、特定カテゴリーのみから検索できる**
4. ✅ テキストと画像（表・グラフ）の両方から関連情報を検索できる
5. ✅ 質問に対して正確な回答と参照元（画像、**カテゴリー**含む）を表示できる
6. ✅ グラフから数値データを抽出し、回答に含められる
7. ✅ 表の内容を理解し、適切に検索・回答できる
8. ✅ ローカル環境で安定動作する

### 評価指標

#### 精度評価
- **テキスト回答精度**: 10件のテキストベース質問で85%以上の正答率
- **表検索精度**: 5件の表関連質問で80%以上の適切な表を検索
- **グラフ数値抽出精度**: 5件のグラフから70%以上の正確な数値抽出

#### 性能評価
- **インデックス作成速度**: 20秒/ページ以内（画像含む）
- **回答生成速度**: 15秒以内
- **画像表示**: 2秒以内

#### UX評価
- ユーザーテストで「使いやすい」評価を80%以上獲得
- 画像表示が「有用」と評価される

---

## 13. テストシナリオ例

### 13.1 テキスト検索テスト
- **質問**: "この製品の主な特徴は何ですか？"
- **期待**: テキストチャンクから適切な回答を生成

### 13.2 表検索テスト
- **質問**: "製品Aと製品Bの仕様比較を教えてください"
- **期待**: 仕様比較表を検索し、表画像と共に回答表示

### 13.3 グラフ検索・数値抽出テスト
- **質問**: "2023年の売上推移はどうでしたか？"
- **期待**:
  - グラフを検索
  - "2023 Q1: 120万円、Q2: 145万円..."のような数値データを含む回答
  - グラフ画像を表示

### 13.4 ハイブリッド検索テスト
- **質問**: "最新の性能データと改善傾向を教えてください"
- **期待**: テキスト説明とグラフの両方を検索し、統合した回答

### 13.5 カテゴリーフィルタリングテスト
- **前提**: 2つのカテゴリー（「製品マニュアル」「運用レポート」）のドキュメントが登録済み
- **操作**: カテゴリードロップダウンで「製品マニュアル」を選択
- **質問**: "製品の仕様は？"
- **期待**:
  - 「製品マニュアル」カテゴリーのドキュメントのみから回答
  - 参照元に「製品マニュアル」カテゴリーが表示される
  - 「運用レポート」カテゴリーのドキュメントは検索対象外

### 13.6 カテゴリー登録テスト
- **操作**: 新しいPDFをアップロード時に「技術仕様書」というカテゴリーを入力
- **期待**:
  - カテゴリーが新規登録される
  - 次回以降のドロップダウンに「技術仕様書」が表示される
  - アップロードされたPDFに正しくカテゴリーが紐付けられる

---

## 14. 今後の拡張案（本番化に向けて）

### 機能拡張
- OCR統合（画像内テキストの直接抽出）
- 表データのCSVエクスポート機能
- グラフの再描画機能（抽出データから）
- マルチモーダル検索の高度化

### インフラ拡張
- マルチユーザー対応（認証機能追加）
- クラウドデプロイ（AWS/GCP）
- スケーラブルなベクトルDB（Pinecone等）
- API エンドポイント化

### データ対応拡張
- Word、PowerPoint直接対応
- Excel ファイル対応
- 動画・音声ファイル対応

---

## 15. 依存パッケージ（requirements.txt 想定）

```txt
streamlit>=1.32.0
langchain>=0.1.0
langchain-openai>=0.0.5
openai>=1.12.0
chromadb>=0.4.22
pdfplumber>=0.10.3
Pillow>=10.2.0
python-dotenv>=1.0.0
tiktoken>=0.6.0
PyYAML>=6.0.1
```

---

## 付録

### A. 参考ドキュメント
- [LangChain公式ドキュメント](https://python.langchain.com/)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [pdfplumber GitHub](https://github.com/jsvine/pdfplumber)

### B. 用語集
- **RAG**: Retrieval-Augmented Generation（検索拡張生成）
- **エンベディング**: テキストをベクトル化する処理
- **チャンク**: 分割されたテキストの単位
- **ハイブリッド検索**: テキストと画像コンテンツの統合検索
- **PoC**: Proof of Concept（概念実証）

---

**作成日**: 2025年1月17日
**最終更新日**: 2025年1月17日
**バージョン**: 1.3（GPT-5統合 + カテゴリー機能追加版）
**対象**: 技術文書・マニュアル（Officeドキュメント由来の表・グラフ含む）
**ステータス**: Draft
